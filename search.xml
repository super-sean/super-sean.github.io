<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[JVM G1垃圾收集器]]></title>
    <url>%2F2020%2F05%2F26%2FJVM-G1%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%2F</url>
    <content type="text"><![CDATA[背景 最近公司在大力推动服务容器化，而默认配套的JVM 垃圾收集器是G1，故此整理一下G1相关的知识点。 基础知识 主要步骤 初始标记(Initial Marking) 并发标记(Concurrent Marking) 最终标记(Final Marking) 筛选回收(Live Data Counting and Evacuation) 运行流程大致如下 对比下CMS流程的流程 基本特性 G1在hotspot开发团队的定位就是替换CMS的收集器，与其它收集器相比，G1有如下特点： 并行与并发 并行：多线程执行垃圾回收操作。 并发：在执行GC运作时，仍然可以通过并发的方式让java程序继续执行。 分代收集 年轻代与老年垃圾回收都可以由G1管理 空间整合 G1是基于标记-整理算法，与CMS标记-清除不同。是基于Region的概念管理内存空间，从局部来看会有点像复制算法。不用纠结于概念，最终都是意味着G1运作期间不会产生内存空间碎片，收集后能提供规整的可用内存。G1的这个特性，分配大对象时在总内存空间足够前提下，不会因为无法找到连续内存空间而触发下一次GC。 可预测的停顿 G1的一大优势，G1除了追求低停顿外，相比CMS还建立了可预测的停顿时间模型，能让使用者明确指定在一个长度为M毫秒的时间片段内，消耗在垃圾收集上的时间不得超过n毫秒。 Region内存管理 上面提到Region，在G1之前其它收集器的范围都是整个新生代或者老年代，而对于G1将整个java堆划分为多个大小不相等的独立区域(Region)，虽然还保留着新告一段落和老年代的概念，但是新生代和老年代不再是物理隔离，都是一部分Region（不需要连续）的集合。 以往的垃圾回收器从物理划分上的模型如下: 基于region，G1在堆内存的模型可以理解如下: G1之所以能建立停顿时间模型，是因为它跟踪各个Region里面的垃圾堆积的价值大小（回收所获得的空间大小以及回收所需时间的经验值），在后台维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的Region，保证了G1在有限时间内可以获取尽可能高的收集效率。 G1的Region之间的对象引用以及其它收集器中的新生代和老年代之间的对象引用，jvm都是使用RememberedSet来避免全堆扫描的。G1每个Region都有一个与之对应的RememberedSet，虚拟机发现程序在对Reference类型的数据进行写操作时，会产生一个Write Barrier暂时中断写操作，检查Reference引用的对象是否处于不同的Region中（拿其它收集器的分代来说就是检查是否老年代中的对象引用了新生代中的对象），如果是，便通过CardTable把相关引用信息记录到被引用对象所属的Region的RememberedSet中。当内存回收时，在GC根节点的枚举范围中加入RememberedSet即可保证不对全堆扫描，也不会有遗漏。 分区模型 参考文章 G1对内存的使用以分区(Region)为单位，而对对象的分配则以卡片(Card)为单位。 巨型对象 Humongous Region 一个大小达到甚至超过分区大小一半的对象称为巨型对象(Humongous Object)。当线程为巨型分配空间时，不能简单在TLAB进行分配，因为巨型对象的移动成本很高，而且有可能一个分区不能容纳巨型对象。因此，巨型对象会直接在老年代分配，所占用的连续空间称为巨型分区(Humongous Region)。G1内部做了一个优化，一旦发现没有引用指向巨型对象，则可直接在年轻代收集周期中被回收。 巨型对象会独占一个、或多个连续分区，其中第一个分区被标记为开始巨型(StartsHumongous)，相邻连续分区被标记为连续巨型(ContinuesHumongous)。由于无法享受Lab带来的优化，并且确定一片连续的内存空间需要扫描整堆，因此确定巨型对象开始位置的成本非常高，如果可以，应用程序应避免生成巨型对象。 已记忆集合 Remember Set (RSet) 在串行和并行收集器中，GC通过整堆扫描，来确定对象是否处于可达路径中。然而G1为了避免STW式的整堆扫描，在每个分区记录了一个已记忆集合(RSet)，内部类似一个反向指针，记录引用分区内对象的卡片索引。当要回收该分区时，通过扫描分区的RSet，来确定引用本分区内的对象是否存活，进而确定本分区内的对象存活情况。 事实上，并非所有的引用都需要记录在RSet中，如果一个分区确定需要扫描，那么无需RSet也可以无遗漏的得到引用关系。那么引用源自本分区的对象，当然不用落入RSet中；同时，G1 GC每次都会对年轻代进行整体收集，因此引用源自年轻代的对象，也不需要在RSet中记录。最后只有老年代的分区可能会有RSet记录，这些分区称为拥有RSet分区(an RSet’s owning region)。 Per Region Table (PRT) RSet在内部使用Per Region Table(PRT)记录分区的引用情况。由于RSet的记录要占用分区的空间，如果一个分区非常&quot;受欢迎&quot;，那么RSet占用的空间会上升，从而降低分区的可用空间。G1应对这个问题采用了改变RSet的密度的方式，在PRT中将会以三种模式记录引用： 稀少：直接记录引用对象的卡片索引 细粒度：记录引用对象的分区索引 粗粒度：只记录引用情况，每个分区对应一个比特位 由上可知，粗粒度的PRT只是记录了引用数量，需要通过整堆扫描才能找出所有引用，因此扫描速度也是最慢的。 收集集合 CSet 收集集合(CSet)代表每次GC暂停时回收的一系列目标分区。在任意一次收集暂停中，CSet所有分区都会被释放，内部存活的对象都会被转移到分配的空闲分区中。因此无论是年轻代收集，还是混合收集，工作的机制都是一致的。年轻代收集CSet只容纳年轻代分区，而混合收集会通过启发式算法，在老年代候选回收分区中，筛选出回收收益最高的分区添加到CSet中。 候选老年代分区的CSet准入条件，可以通过活跃度阈值-XX:G1MixedGCLiveThresholdPercent(默认85%)进行设置，从而拦截那些回收开销巨大的对象；同时，每次混合收集可以包含候选老年代分区，可根据CSet对堆的总大小占比-XX:G1OldCSetRegionThresholdPercent(默认10%)设置数量上限。 由上述可知，G1的收集都是根据CSet进行操作的，年轻代收集与混合收集没有明显的不同，最大的区别在于两种收集的触发条件。 年轻代收集集合 CSet of Young Collection 应用线程不断活动后，年轻代空间会被逐渐填满。当JVM分配对象到Eden区域失败(Eden区已满)时，便会触发一次STW式的年轻代收集。在年轻代收集中，Eden分区存活的对象将被拷贝到Survivor分区；原有Survivor分区存活的对象，将根据任期阈值(tenuring threshold)分别晋升到PLAB中，新的survivor分区和老年代分区。而原有的年轻代分区将被整体回收掉。 同时，年轻代收集还负责维护对象的年龄(存活次数)，辅助判断老化(tenuring)对象晋升的时候是到Survivor分区还是到老年代分区。年轻代收集首先先将晋升对象尺寸总和、对象年龄信息维护到年龄表中，再根据年龄表、Survivor尺寸、Survivor填充容量-XX:TargetSurvivorRatio(默认50%)、最大任期阈值-XX:MaxTenuringThreshold(默认15)，计算出一个恰当的任期阈值，凡是超过任期阈值的对象都会被晋升到老年代。 混合收集集合 CSet of Mixed Collection 年轻代收集不断活动后，老年代的空间也会被逐渐填充。当老年代占用空间超过整堆比IHOP阈值-XX:InitiatingHeapOccupancyPercent(默认45%)时，G1就会启动一次混合垃圾收集周期。为了满足暂停目标，G1可能不能一口气将所有的候选分区收集掉，因此G1可能会产生连续多次的混合收集与应用线程交替执行，每次STW的混合收集与年轻代收集过程相类似。 为了确定包含到年轻代收集集合CSet的老年代分区，JVM通过参数混合周期的最大总次数-XX:G1MixedGCCountTarget(默认8)、堆废物百分比-XX:G1HeapWastePercent(默认5%)。通过候选老年代分区总数与混合周期最大总次数，确定每次包含到CSet的最小分区数量；根据堆废物百分比，当收集达到参数时，不再启动新的混合收集。而每次添加到CSet的分区，则通过计算得到的GC效率进行安排。 SoftReference 、 WeakReference 和 PhantomReference的区别 讲GC日志前需要行了解引用类型的相关知识 参考文章 直接搬过来了 java.lang.ref包 FinalReference（强引用） 平时编程最长用到的是强引用如 1Object o=new Object(); Object o1=o; 第一句是在heap堆中创建新的Object对象通过o引用这个对象，第二句是通过o建立o1到new Object()这个heap堆中的对象的引用，这两个引用都是强引用. JVM 系统采用 Finalizer 来管理每个强引用对象 , 并将其被标记要清理时加入 ReferenceQueue, 并逐一调用该对象的 finalize() 方法。 但是如果通过 1o=null; o1=null; 显式地设置o和o1为null，或超出范围，则gc认为该对象不存在引用，这时就可以收集它了。可以收集并不等于就一会被收集，什么时候收集这要取决于gc的算法，这要就带来很多不确定性。例如你就想指定一个对象，希望下次gc运行时把它收集了，那就没办法了，有了其他的三种引用就可以做到了。其他三种引用在不妨碍gc收集的情况下，可以做简单的交互。 heap中对象有强可及对象、软可及对象、弱可及对象、虚可及对象和不可到达对象。应用的强弱顺序是强、软、弱、和虚。对于对象是属于哪种可及的对象，由他的最强的引用决定。如下： 12345String abc=new String(&quot;abc&quot;); //1 SoftReference&lt;String&gt; abcSoftRef=new SoftReference&lt;String&gt;(abc); //2 WeakReference&lt;String&gt; abcWeakRef = new WeakReference&lt;String&gt;(abc); //3 abc=null; //4 abcSoftRef.clear();//5 上面的代码中： 第一行在heap对中创建内容为“abc”的对象，并建立abc到该对象的强引用,该对象是强可及的。 第二行和第三行分别建立对heap中对象的软引用和弱引用，此时heap中的对象仍是强可及的。 第四行之后heap中对象不再是强可及的，变成软可及的。同样第五行执行之后变成弱可及的。 SoftReference(软引用) 软引用是主要用于内存敏感的高速缓存。在jvm报告内存不足之前会清除所有的软引用，这样以来gc就有可能收集软可及的对象，可能解决内存吃紧问题，避免内存溢出。什么时候会被收集取决于gc的算法和gc运行时可用内存的大小。当gc决定要收集软引用是执行以下过程,以上面的abcSoftRef为例： 首先将abcSoftRef的referent设置为null，不再引用heap中的new String(“abc”)对象。 将heap中的new String(“abc”)对象设置为可结束的(finalizable)。 当heap中的new String(“abc”)对象的finalize()方法被运行而且该对象占用的内存被释放， abcSoftRef被添加到它的ReferenceQueue中。 注:对ReferenceQueue软引用和弱引用可有可无，但是虚引用必须有，参见： 1Reference(T paramT, ReferenceQueue&lt;? super T&gt;paramReferenceQueue) 被 Soft Reference 指到的对象，即使没有任何 Direct Reference，也不会被清除。一直要到 JVM 内存不足且没有 Direct Reference 时才会清除，SoftReference 是适合用来设计 object-cache 之用的。如此一来SoftReference 不但可以把对象 cache 起来，也不会造成内存不足的错误 （OutOfMemoryError）。 SR( Soft Reference)用于object-cache是非常低效率的.运行时缺少信息去决定哪些引用被清理或保持。仅适用于实现简单的对象cache。 123456789A obj = new A();SoftRefenrence sr = new SoftReference(obj);//引用时if(sr!=null)&#123; obj = sr.get();&#125;else&#123; obj = new A(); sr = new SoftReference(obj);&#125; WeakReference（弱引用） 1234567String abc=new String(&quot;abc&quot;); WeakReference&lt;String&gt; abcWeakRef = new WeakReference&lt;String&gt;(abc); abc=null;System.out.println(&quot;before gc: &quot;+abcWeakRef.get()); System.gc(); System.out.println(&quot;after gc: &quot;+abcWeakRef.get()); 运行结果: before gc: abc after gc: null gc收集弱可及对象的执行过程和软可及一样，只是gc不会根据内存情况来决定是不是收集该对象。 如果你希望能随时取得某对象的信息，但又不想影响此对象的垃圾收集，那么你应该用 Weak Reference 来记住此对象，而不是用一般的 reference。 1234567891011A obj = new A();WeakReference wr = new WeakReference(obj);obj = null;//等待一段时间，obj对象就会被垃圾回收...if (wr.get()==null) &#123; System.out.println(&quot;obj 已经被清除了 &quot;);&#125; else &#123; System.out.println(&quot;obj 尚未被清除，其信息是 &quot;+obj.toString());&#125;... PhantomReference（虚引用） 虚顾名思义就是没有的意思，建立虚引用之后通过get方法返回结果始终为null,通过源代码你会发现,虚引用通向会把引用的对象写进referent,只是get方法返回结果为null.先看一下和gc交互的过程在说一下他的作用. 不把referent设置为null, 直接把heap中的new String(“abc”)对象设置为可结束的(finalizable). * 与软引用和弱引用不同, 先把PhantomRefrence对象添加到它的ReferenceQueue中.然后在释放虚可及的 对象. 你会发现在收集heap中的new String(“abc”)对象之前,你就可以做一些其他的事情.通过以下代码可以了解他的作用。一般作用在于跟踪垃圾回收过程。 123456789101112131415161718192021222324252627282930313233 String abc = new String(&quot;abc&quot;); System.out.println(abc.getClass() + &quot;@&quot; + abc.hashCode()); final ReferenceQueue referenceQueue = new ReferenceQueue&lt;String&gt;(); new Thread() &#123; public void run() &#123; while (isRun) &#123; Object o = referenceQueue.poll(); if (o != null) &#123; try &#123; Field rereferent = Reference.class.getDeclaredField(&quot;referent&quot;); rereferent.setAccessible(true); Object result = rereferent.get(o); System.out.println(&quot;gc will collect:&quot; + result.getClass() + &quot;@&quot; + result.hashCode()); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; &#125;.start(); PhantomReference&lt;String&gt; abcWeakRef = new PhantomReference&lt;String&gt;(abc, referenceQueue); abc = null; Thread.currentThread().sleep(3000); System.gc(); Thread.currentThread().sleep(3000); isRun = false; 结果为class java.lang.String@96354 gc will collect:class java.lang.String@96354 JNI Weak Reference Jni/NDK 中弱全局引用，不会阻止GC,/跨线程，跨方法使用 jclass g_weak_cls 123456JNIEXPORT jstring JNICALL Java_com_createWeakRef(JNIEnv * env, jobject jobj) &#123; jclass cls_string = (*env)-&gt;FindClass(env, &quot;java/lang/String&quot;); g_weak_cls = (*env)-&gt;NewWeakGlobalRef(env, cls_string); return g_weak_cls;&#125; 日志分析 参考文章1 参考文章2 123G1 GC uses a marking algorithm called Snapshot-At-The-Beginning (SATB) that takes a logical snapshot of the set of live objects in the heap at the ‘beginning’ of the marking cycle. This algorithm uses a pre-write barrier to record and mark the objects that are a part of the logical snapshot 第一行日志会有几种情况 12020-05-26T21:17:08.926+0800: 27.749:[GC pause (young), 0.15877971 secs] 最常见的，27.749是jvm进程启动后经历的时间，标明了 GC pause (young)，一次清理停顿（Evacuation Pause）开始时间及消耗时间，只会清理eden和survivor相关的region 12020-05-26T21:17:08.926+0800: 27.749:[GC pause (mixed), 0.32714353 secs] 清理停顿（Evacuation Pause）有时也会是Mix类型，mix类型的话是会把老年代相关的region也包含进来进行处理。 12020-05-26T21:17:08.926+0800: 27.749: [GC pause (young) (initial-mark) (initial-mark) 说明是发生在Young GC，初始标记阶段 123452020-05-26T21:17:08.966+0800: 27.789: [SoftReference, 0 refs, 0.1215730 secs]2020-05-26T21:17:09.087+0800: 27.911: [WeakReference, 80 refs, 0.0008870 secs]2020-05-26T21:17:09.088+0800: 27.912: [FinalReference, 2394 refs, 0.0032540 secs]2020-05-26T21:17:09.091+0800: 27.915: [PhantomReference, 6 refs, 0.0010320 secs]2020-05-26T21:17:09.092+0800: 27.916: [JNI Weak Reference, 0.0008020 secs], 0.1689180 secs] SoftReference/WeakReference/FinalReference/PhantomReference/JNI Weak Reference 对应的是各种引用的数量，以及清理所用的时长，是参数 -XX:+PrintReferenceGC 的结果 看下这环节的相关子任务情况 123[Parallel Time: 37.6 ms, GC Workers: 12] [GC Worker Start (ms): 27749.2 27749.3 27749.3 27749.3 27749.3 27749.4 27749.4 27749.4 27749.4 27749.4 27749.5 27749.5 Min: 27749.2, Avg: 27749.4, Max: 27749.5, Diff: 0.3] Parallel Time – 是并行GC worker线程运行消耗的整体时间 GC WORKERS - GC worker线程个数 Worker Start – 并行GC的各个工作线程(workers)启动时的时间戳(Timestamp)，距离程序启动来说 日志是根据 thread id 排序,并且每条记录都是一致的. 12[Ext Root Scanning (ms): 26.2 26.6 3.6 25.7 25.8 3.8 26.4 27.1 27.1 2.0 3.7 25.1 Min: 2.0, Avg: 18.6, Max: 27.1, Diff: 25.1, Sum: 223.1] External root scanning - 扫描外部根花费的时间，包括globals，registers,线程栈和虚拟机数据结构 ， 12[Code Root Marking (ms): 0.0 0.0 0.0 0.9 0.2 0.4 0.0 0.0 0.0 0.0 0.0 0.0 Min: 0.0, Avg: 0.1, Max: 0.9, Diff: 0.9, Sum: 1.5] 还未找到资料 按字面理解应该是代码根路径标识。code root指的是经过JIT编译后的代码里，引用了heap中的对象。引用关系保存在RSet中。 12[Update RS (ms): 0.0 0.8 0.3 1.3 1.6 1.0 1.0 0.3 0.6 2.2 0.0 1.4 Min: 0.0, Avg: 0.9, Max: 2.2, Diff: 2.2, Sum: 10.6] Update Remembered Set - rs是用于保存访问堆region的指针的引用轨迹的数据结构。赋值线程保持更新对象图因此可以保持引用指向指定的region。堆通常可以使用对象图（object graph）的方式来描述，它一般是一个有向图（directed graph），图的节点（node）是堆中的对象，有向边是对象之间的引用。用于保存这些引用变化的缓冲区叫更新缓冲区（Update Buffers）。Update RS 子任务主要是会访问这些更新缓冲区（不支持并发访问），并更新所有region相应的RS 12[Processed Buffers: 1 8 2 5 1 10 3 3 1 1 0 3 Min: 0, Avg: 3.2, Max: 10, Diff: 10, Sum: 38] 每个worker线程处理的Update Buffers的数量 12[Scan RS (ms): 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.2] 每个线程查找指向 Remembered Set 的指针(pointers)的时间。RS中保存着指向region的引用指针集合称为卡片(cards)，这个阶段就是扫描卡片，卡片寻找所有Region集合(all the regions of the collection set)的指针引用 12[Code Root Scanning (ms): 0.0 0.1 0.0 0.0 0.0 0.1 0.0 0.0 0.0 0.0 0.0 0.0 Min: 0.0, Avg: 0.0, Max: 0.1, Diff: 0.1, Sum: 0.2] 扫描code root耗时。code root指的是经过JIT编译后的代码里，引用了heap中的对象。引用关系保存在RSet中。 12[Object Copy (ms): 10.9 9.7 33.3 9.2 9.5 31.7 9.7 9.7 9.3 32.8 33.3 10.4 Min: 9.2, Avg: 17.5, Max: 33.3, Diff: 24.2, Sum: 209.4] Object copy – 每个独立的线程在拷贝和转移对象时所消耗的时间. 1234[Termination (ms): 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.2] [Termination Attempts: 1 1 1 1 1 1 1 1 1 1 1 1 Min: 1, Avg: 1.0, Max: 1, Diff: 0, Sum: 12] Termination time - 当worker线程完成了自己那部分对象的复制和扫描,就进入终止协议(termination protocol)。它查找未完成的工作(looks for work to steal), 一旦它完成就会再进入终止协议。 终止尝试记录(Termination attempt counts)所有查找工作的尝试次数(attempts to steal work). 12[GC Worker Other (ms): 0.1 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.1 0.0 0.0 0.0 Min: 0.0, Avg: 0.0, Max: 0.1, Diff: 0.1, Sum: 0.5] GC worker other – 每个GC线程中不能归属到之前列出的worker阶段的其他时间. 这个值应该很低. 有可能会有很高的值,是由于JVM的其他部分的瓶颈引起的(例如在分层[Tiered]代码缓存[Code Cache]占有率的增加)。 12[GC Worker Total (ms): 37.4 37.2 37.2 37.2 37.2 37.1 37.1 37.1 37.2 37.0 37.0 37.0 Min: 37.0, Avg: 37.1, Max: 37.4, Diff: 0.4, Sum: 445.7] 每个GC worker线程耗时总时长 12[GC Worker End (ms): 27786.6 27786.5 27786.5 27786.5 27786.5 27786.5 27786.5 27786.5 27786.6 27786.5 27786.5 27786.5 Min: 27786.5, Avg: 27786.5, Max: 27786.6, Diff: 0.1] GC worker end time – 独立的 GC worker 停止时的时间戳. 12[Code Root Fixup: 0.2 ms] [Code Root Migration: 0.2 ms] 清理用于管理并行处理的相关数据及其它过程相关数据的阶段，这个阶段一般都得比较短，得接近于0才比较正常 1[Clear CT: 0.4 ms] 清理 RSet 关联的 Card Table(CT)的GC worker相关线程扫描元数据所耗费的时间 12345678[Other: 130.5 ms] [Choose CSet: 0.0 ms] [Ref Proc: 129.6 ms] [Ref Enq: 0.3 ms] [Redirty Cards: 0.1 ms] [Humongous Register: 0.0 ms] [Humongous Reclaim: 0.0 ms] [Free CSet: 0.1 ms] Choose CSet（Choose Collection Set） - 垃圾回收周期中，在CSet中回收Region集合的阶段（the sets of regions in the CSet）.这个阶段会暂停相关CSet中所有存活数据的回收/迁移动作。这里的时间是指停止添加相关region集合到CSet所耗费的时间。 Ref Proc（Reference Processing）- 优先回收阶段对上面所提的引用不包括强引用的处理（排列前置处理） Ref Enq（Reference En-queuing） - 在引用列表中排列引用 Redirty Cards：重新脏化卡片。排队引用可能会更新RSet，所以需要对关联的Card重新脏化(Redirty Cards)。 Humongous Register、Reclaim 主要是对巨型对象回收的信息，youngGC阶段会对RSet中有引用的短命的巨型对象进行回收，巨型对象会直接回收而不需要进行转移（转移代价巨大，也没必要） Free CSet - 释放刚刚回收的Region集合的空间，包括它们的RSet 12 [Eden: 112.0M(112.0M)-&gt;0.0B(84.0M) Survivors: 20.0M-&gt;20.0M Heap: 204.6M(256.0M)-&gt;123.0M(256.0M)][Times: user=0.25 sys=0.03, real=0.17 secs] Eden: 使用量(eden区总量)-&gt;回收后使用量(eden区总量) Survivors: 回收前使用量-&gt;回收后使用量 Heap: 回收前使用量(Heap总量)-&gt;回收后使用量(Heap总量)，可以看出这个Heap 总量就是配置的量,Times三个指标的概念在另外一篇文章已经讲过了 ** initial mark 阶段主要是标识 相关roots，会stw ** 122020-05-26T21:17:09.095+0800: 27.918: [GC concurrent-root-region-scan-start]2020-05-26T21:17:09.102+0800: 27.926: [GC concurrent-root-region-scan-end, 0.0074660 secs] region根扫描，如果标识是young，会将initial mark扫描出来的survivor相关的region的内容转移到老年代，这个阶段是并行的，在下次年代代回收开始前会保证这个阶段先完成。 122020-05-26T21:17:09.102+0800: 27.926: [GC concurrent-mark-start]2020-05-26T21:17:09.157+0800: 27.980: [GC concurrent-mark-end, 0.0544330 secs] 扫描堆中可触达的存活对象。这个阶段是可被中断的。 123456782020-05-26T21:17:09.157+0800: 27.981: [GC remark 2020-05-26T21:17:09.158+0800: 27.982: [GC ref-proc 2020-05-26T21:17:09.158+0800: 27.982: [SoftReference, 0 refs, 0.0086570 secs] 2020-05-26T21:17:09.167+0800: 27.990: [WeakReference, 24 refs, 0.0024750 secs] 2020-05-26T21:17:09.169+0800: 27.993: [FinalReference, 1 refs, 0.0037370 secs] 2020-05-26T21:17:09.173+0800: 27.997: [PhantomReference, 1 refs, 0.0025040 secs] 2020-05-26T21:17:09.176+0800: 27.999: [JNI Weak Reference, 0.0029650 secs], 0.0209600 secs], 0.0293260 secs] [Times: user=0.14 sys=0.00, real=0.03 secs] remark阶段，stw，将SATB 还存留的缓冲区清理干净，追踪还没访问到的存活对象，也处理相关引用对象。 12342020-05-26T21:17:09.187+0800: 28.010: [GC cleanup 124M-&gt;80M(256M), 0.0015900 secs] [Times: user=0.00 sys=0.01, real=0.00 secs] 2020-05-26T21:17:09.189+0800: 28.012: [GC concurrent-cleanup-start]2020-05-26T21:17:09.189+0800: 28.012: [GC concurrent-cleanup-end, 0.0001930 secs] cleanup阶段，部分stw，当进行存活对象统计和清除RSet时会stw。部分并发，当G1 GC重置及返回空的region给空闲列表时为并发的。 参数 核心参数 -XX:+UseG1GC 使用 G1 (Garbage First) 垃圾收集器 -XX:G1ReservePercent=n 设置堆内存保留为假天花板的总量,以降低提升失败的可能性. 默认值是 10. -XX:G1HeapRegionSize=n 此参数可以指定每个region的大小. 默认值将根据 heap size 算出最优解. 最小值为 1Mb, 最大值为 32Mb. -XX:G1NewSizePercent 新生代最小值，默认值5% -XX:G1MaxNewSizePercent 新生代最大值，默认值60% -XX:G1MixedGCLiveThresholdPercent 候选老年代分区的CSet准入条件,分区模型有说，拦截那些回收开销巨大的对象，默认85% -XX:G1OldCSetRegionThresholdPercent 每次混合收集可以包含候选老年代分区，可根据CSet对堆的总大小占比，默认10% 分区模型有说 -XX:G1MixedGCCountTarget JVM通过参数混合周期的最大总次数，默认8 分区模型有说 -XX:G1HeapWastePercent 堆废物百分比，默认5% 分区模型有说 从网上抄了比较全的参数列表下来，虽然之前CMS GC调优的时候也整理过，貌似不是很很全，配合着看.GC问题解决的那些套路 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152-server 指定是server 模式-XX:+UseG1GC 使用 G1 (Garbage First) 垃圾收集器-XX:MaxGCPauseMillis=n 设置最大GC停顿时间(GC pause time)指标(target)。这是一个软性指标(soft goal), JVM 会尽量去达成这个目标.-XX:+PrintGC 输出GC日志-XX:+PrintGCDetails 输出GC的详细日志-XX:+PrintGCTimeStamps 输出GC的时间戳（以基准时间的形式）-XX:+PrintGCDateStamps 输出GC的时间戳（以日期的形式，如 2013-05-04T21:53:59.234+0800）-XX:+PrintHeapAtGC 在进行GC的前后打印出堆的信息-Xloggc:/home/jamin/logs/gc.log 日志文件的输出路径-XX:+HeapDumpOnOutOfMemoryError 如果出现OutOfMemoryError 打印堆的快照-XX:TargetSurvivorRatio Survivor填充容量，默认50%-XX:MaxTenuringThreshold=n 提升年老代的最大临界值(tenuring threshold). 默认值为 15.-XX:ParallelGCThreads=n 设置垃圾收集器在并行阶段使用的线程数,默认值随JVM运行的平台不同而不同.-XX:ConcGCThreads=n 并发垃圾收集器使用的线程数量. 默认值随JVM运行的平台不同而不同.-XX:G1ReservePercent=n 设置堆内存保留为假天花板的总量,以降低提升失败的可能性. 默认值是 10.-XX:G1HeapRegionSize=n 此参数可以指定每个region的大小. 默认值将根据 heap size 算出最优解. 最小值为 1Mb, 最大值为 32Mb.-XX:G1NewSizePercent 新生代最小值，默认值5%-XX:G1MaxNewSizePercent 新生代最大值，默认值60%-XX:InitiatingHeapOccupancyPercent=n启动并发GC周期时的堆内存占用百分比. G1垃圾收集器用它来触发并发GC周期,基于整个堆的使用率,而不只是某一代内存的使用比. 值为 0 则表示&quot;一直执行GC循环&quot;. 默认值为 45.-XX:+AlwaysPreTouch 系统不会真正分配内存给jvm，而是在使用的时候才分配，设置此参数后JVM就会先访问所有分配给它的内存,让操作系统把内存真正的分配给JVM.后续JVM就可以顺畅的访问内存了。-XX:GCLogFileSize=31457280 GC log 文件大小-XX:+UseGCLogFileRotation 打开或关闭GC日志滚动记录功能，要求必须设置 -Xloggc参数-XX:NumberOfGCLogFiles=5 设置滚动日志文件的个数，必须大于1。日志文件命名策略是，&lt;filename&gt;.0, &lt;filename&gt;.1, ..., &lt;filename&gt;.n-1，其中n是该参数的值-XX:InitialHeapSize=268435456 初始堆大小-XX:MaxDirectMemorySize=16106127360 使用直接内存大小-XX:MaxHeapSize=268435456 最大堆大小 -XX:MaxNewSize=134217728 新生代最大大小-XX:NewSize=134217728 新生代初始大小-XX:-OmitStackTraceInFastThrow 强制要求JVM始终抛出含堆栈的异常，编译优化后抛出的异常是没有堆栈信息的。（注意前面是 - 号）-XX:+PrintAdaptiveSizePolicy 打印自适应收集的大小。默认关闭。-XX:+PrintGCApplicationStoppedTime 打印gc一共停顿了多长时间。-XX:SoftRefLRUPolicyMSPerMB=0 软连接对象并且可达，在最后一次被引用后将保持存活一段时间。默认值是堆中每空闲兆字节生存期的一秒钟-XX:-UseBiasedLocking 禁用偏向锁（存在大量锁对象的创建并高度并发的环境下禁用偏向锁能够带来一定的性能优化）-XX:LargePageSizeInBytes=10m 内存分页大小调整-XX:-UseLargePages 启用大内存页支持（JDK是在1.5 update5以前的需要加这个参数）-XX:+UseCompressedClassPointers 启用压缩类的指针-XX:+UseCompressedOops 启用压缩普通对象指针（Oop=普通对象指针,64位机器指针会比32位占用的多，因为寻址更宽了） 可以让跑在64位平台下的JVM，不需要因为更宽的寻址，而付出Heap容量损失的代价。不过，它的实现方式是在机器码中植入压缩与解压指令，可能会给JVM增加额外的开销。 G1 GC调优 参考之前写的文章GC问题解决的那些套路 对比CMS GC的优化来看G1 GC调优注意点。 参考oracle官网、文章 年轻代调优 因为G1 GC是启发式算法，会动态调整年轻代的空间大小。目标也就是为了达到接近预期的暂停时间。年轻代调优中比较重要的就是对暂停时间的处理。一般都是根据MaxGCPauseMillis以及年轻代占比G1NewSizePercent、G1MaxNewSizePercent，结合应用的特点和GC数据进行接近期望pause time的调整。为了能观察到详细的暂停时间信息，可以添加调试的启动参数 -XX:+PrintAdaptiveSizePolicy 。 123456726.139: [GC pause (G1 Evacuation Pause) (young) 26.139: [G1Ergonomics (CSet Construction) start choosing CSet, _pending_cards: 3484, predicted base time: 5.51 ms, remaining time: 194.49 ms, target pause time: 200.00 ms] 26.139: [G1Ergonomics (CSet Construction) add young regions to CSet, eden: 54 regions, survivors: 9 regions, predicted young region time: 5.98 ms] 26.139: [G1Ergonomics (CSet Construction) finish choosing CSet, eden: 54 regions, survivors: 9 regions, old: 0 regions, predicted pause time: 11.49 ms, target pause time: 200.00 ms], 0.0163685 secs] target也即目标是200ms,实际的pause time是16ms。远远小于目标暂停时间。并且再CSet中的分区数是“eden: 54 regions, survivors: 9 regions”，可以适当增加CSet中的年轻代分区,也可以适当缩短暂停时间，让实际值和期望值不断接近。 并发标记和MixGC 调优 InitiatingHeapOccupancyPercent就是触发并发标记的一个决定阀值。当Java堆空间占用到45%便开启并发周期。并发标记的初始标记阶段伴随着一次YoungGC的暂停。会看到如下log记录: 12018-05-26T19:50:57.256-0800: 78.480: [GC pause (G1 Evacuation Pause) (young) (initial-mark), 0.0076560 secs] IHOP如果阀值设置过高，可能会遇到转移失败的风险，比如对象进行转移时空间不足。如果阀值设置过低，就会使标记周期运行过于频繁，并且有可能混合收集期回收不到空间。 IHOP值如果设置合理，但是在并发周期时间过长时，可以尝试增加并发线程数，调高ConcGCThreads。 引用处理 G1 GC对于虚引用、弱引用、软引用的处理会比一般对象多一些收集任务。如果在引用处理占用了很长时间，需要更进一步排查。-XX:+PrintReferenceGC打印更详细的引用计数信息。一般在Ref Proc时间超过GC暂停时间的10%时就要关注。 如果SoftReference过多，会有频繁的老年代收集。-XX:SoftRefLRUPolicyMSPerMB参数，可以指定每兆堆空闲空间的软引用的存活时间，默认值是1000，也就是1秒。可以调低这个参数来触发更早的回收软引用。如果调高的话会有更多的存活数据，可能在GC后堆占用空间比会增加。 对于软引用，还是建议尽量少用，会增加存活数据量，增加GC的处理时间。 其它 RSet的处理 UpdateRS:更新RSet的时间信息。-XX:MaxGCPauseMill is参数是限制G1的暂停之间，一般RSet更新的时间小于10%的目标暂停时间是比较可取的。如果花费在RSetUpdate的时间过长，可以修改其占用总暂停时间的百分比-XX:G1RSetUpdatingPauseTimePercent。这个参数的默认值是10。 如果观察到RS的处理时间较长，可以使用-XX:+G1SummarizeRSetStats参数，在GC结束后打印RSet的详细信息。一般在debug环境排查用。还有一个辅助参数G1SummarizeRSetStatsPeriod=0用来控制第几次GC后统计一次RSet信息。 Object Copy 该任务主要是对CSet中存活对象进行转移（复制）。对象拷贝的时间一般占用暂停时间的主要部分。如果拷贝时间和”预测暂停时间“有相差很大，也可以调整年轻代尺寸大小。 Full GC 曾经有同事问我G1有没有Full GC，目前所知没有不存在支持不Full gc垃圾回收器的jdk版本。详见以下资料。 oracle - Observing Full Garbage Collections 网友对G1源码分析]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>java基础</tag>
        <tag>JVM</tag>
        <tag>内存</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一次服务分离的经历]]></title>
    <url>%2F2020%2F05%2F19%2F%E4%B8%80%E6%AC%A1%E6%9C%8D%E5%8A%A1%E5%88%86%E7%A6%BB%E7%9A%84%E7%BB%8F%E5%8E%86%2F</url>
    <content type="text"><![CDATA[自从那次的迭代做完后（抽象优化交易服务的那个项目），公司刚好有个比较大型的服务分离项目需要支持，刚好业务上没那么忙，爱折腾的我义无反顾就加入了。一搞就搞了一个月有多，作为这个项目的一线执行角色回过头来总结一下自己所学习到的内容。 背景 一家公司旗下经常会有多个APP的情况，除去中台、基础服务等，一般业务服务在理想的情况下都应该是根据APP服务分离的，但是往往公司在全新子业务的验证上想要快，在技术上可能会做出一些让步，比如两个团队共用项目，一些两个app都能用的功能就共用，需要区分的业务的时候在代码里面硬编码逻辑分支。刚好这次接触的项目是这种情况，涉及的规模比较大，有80个左右服务需要处理及一些旧服务处理，总的来说超过百个相关服务。 主业务就是核心业务应用APP，子业务就是独立子APP，接入器可以简单理解为对外网关服务（我们公司用的长链，自研接入层）。两个环境通信通过自研内部网关服务。 这样的架构会存在以下问题: 服务质量问题，整条链路某个环节一出问题便互相两个app，不管是哪方出的问题。 业务发展相互制约，多个团队多个需求难免会有冲突的时候，在迭代过程需要考虑的成本较大。 代码膨胀问题，由于两边的业务特性不同，会有很多硬编码的情况存在。 渐进式还是一刀切？ 其实一般来说，从稳健推进的角度来说，可能会很多人想选择渐进式迁移，但是我们这个项目最终决策者选择了一刀切，经过了解，主要理由有如下： 业务一边快速发展，一边迁移的话基本很难操作，有可能会分离的不干净 ，返工机率可能也会比较大。 时间线会被拉得很长，而来自团队内外的压力，要求着得快速根本的解决存在的问题。 解决方案 三个环境 可以看到增加多一个全新的子业务环境，这样做的目的主要是减少迁移工作对正在进行的子业务迭代的影响，迁移工作可以独立的进行，不影响子业务正常迭代。 独立环境相关工作 独立外部网关及协议梳理和web入口域名梳理 fork业务项目代码并按规则修改项目名 新项目代码改造 接口服务限定名改造，上游调用者改造（cat） 消息消费链路改造,生产者及消费者(grafana) 修改相关启动脚本 移除会对主业务有影响的但是对子业务无用的相关模块，比如quartz定时任务 配置分离（apollo配置中心） 存储分离 （统一修改数据源相关元数据） redis mysql memcached xxl-job任务迁移 主业务服务调用子业务服务调用链的清理（cat） 推进过程核心问题 测试环境问题 按环境来讲，我们推进的节奏是 预发-&gt; 线上-&gt;开发。直接使用预发环境进行子业务的测试回归，主要是因为我们公司的开发环境是自研的一套持续集成的管理平台，对接有一定成本，在相关的压力下，最终选择了这样的节奏。 上线前子业务是否要将旧环境停服 为了避免对数据层的影响以及避免消息重复消费问题，决定还是得把旧环境的服务都停掉 存储层操作节奏 存储第一次同步（将旧环境相应服务的相关存储同步一份到新的存储层） 断开同步 进行新环境预发测试及线上测试 将新环境预发及线上服务全部关停 清除所有数据重新同步 同步完成之后，在新环境未正式上线前保持增量同步 新环境正式上线后断开增量同步 基础服务配合问题 关于基础服务调用业务相关接口的情况，在预发环境测试过程没有大的问题，可当我们需要在线上回归测试时，这个时候得要基础服务上线才能测，可基础服务上线生产环境的流量是不能调用新环境的服务。使用了流量开关加白名单的方式来处理，基础服务及业务服务双方都针对性的加上。 测试阶段开关打开，只放行测试流量到新环境，其它流量都走原来的通道。 上线阶段开关关闭，基础服务区分主/子业务流量，子业务流量全部走新环境。 开关详细逻辑如下: 主业务服务对子业务旧环境的调用链处理 梳理 由于我们公司rpc框架是基于dubbo做的二次开发，跨环境调用都是通过内部网关服务，有日志可追踪，可以看到调用provider的全限定名，然后通过cat二次开发的cross功能进行上游排查，再通过机器ip所属环境及代码定位判断是否有区分业务流量调用，没有的需要补上。 移除 主业务对子业务服务的依赖链路，能去掉得尽量去掉，必要时候业务需要做出一定的牺牲。 保留及改造 去不掉的调用，存在两个问题 调整环境访问顺序 主业务环境对子业务服务的请求，假设子业务服务不改服务限定名的情况下，会在子业务新旧环境乱窜，所以需要处理环境调用优先级问题。所幸，我们公司对基于dubbo封装的rpc框架上支持这样的特性，针对项目级别的可配置。其实主要是利用了dubbo provider的前缀来与网关访问的环境绑定。大体流程如下： 停服的兼容处理 子业务旧环境上线时需要停服，针对无法移除的大流量接口需要添加流量屏蔽开关，并在停服前打开，上线完成后关闭。 消息通信改造 我们公司业务上大多用的kafka进行消息通信，在迁移的项目中，我们需要去梳理使用到的内外部流程的topic，内部流程的topic一律改名字重新开通，外部流程topic（旧环境的服务也一样会监听）修改group，一样加开关及白名单进行测试避免重复消费，涉及基础服务的也是改topic，区分逻辑处理，也是加开关和白名单进行消费，具体见 基础服务配合问题 的流程。 补充 把不确定项尽早确定 在开始的阶段，其实项目负责人是给不出具体的计划的，直到我们梳理出跨环境调用链，kafka消息改造，需要迁移的存储列表、涉及的网关协议及域名列表等才能确定最终的计划。当然这些事项每一项单独拎出来都是需要一定的时间去梳理的。团队的兄弟们确实也给力。 繁杂的跟进事项 事情很多，而且涉及人员很多，基本上我们做的每个环节都在一个在线文档进行统一的备注跟进，每个tab是单独一个文档，每个文档基本上都有很多内容，但是梳理清楚，分清楚负责人，大家做起事情来都有条不紊。 减少变化的风险 前期工作做得比较充分，其实在过程紧急的变化项并不多，基本上项目进度都比较健康。 注重细节 比较佩服项目负责人的一点是，把计划细节都梳理很清晰。比如说我们因为要停服，是凌晨上线的，需要通宵，那么他会安排前一天休息，上完线后的排班人员，另外给通宵的成员争取一天调休，整体上线前后的细节考虑得很周到。 Arthas 我在这个项目中推动了项目成员使用arthas，也算是第一次在项目中比较频繁及较深入的使用解决问题，效果很不错，最近打算学习一下arthas源码，后面再出写一个arthas的源码解读。]]></content>
      <categories>
        <category>设计</category>
      </categories>
      <tags>
        <tag>架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[通用交易服务架构设计]]></title>
    <url>%2F2020%2F03%2F31%2F%E9%80%9A%E7%94%A8%E4%BA%A4%E6%98%93%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%2F</url>
    <content type="text"><![CDATA[自从年前写了商业化、serverless和活动通用模板设计，又是几个月没写文章了，对不起自己。 刚好年后一复工就来一个比较大的项目，忙到3月下旬才算是竣工。btw，活动通用模板被坑了应该是没后续了， 后来经过了解，是有现成服务可对接的，之前听产品说不适合就没多加了解，还是万事留个心，多了解一下。 背景 在开始做商业化需求实现时，发现APP内有不少其它交易场景，刚好部门商业化业务刚起步，后期肯定会有越来越多的交易场景。故此，统一交易流程，降低开发及维护成本，是很有必要去推进的事情。 愿景 可以快速支持买家购买卖家商品新的支付场景，大量减少业务开发及维护成本。 项目职能 将公司支付平台视为第三方服务进行封装，提供通用支付场景支撑，包括商品管理、支付流程管理、订单生命周期管理、自动对账、数据分析五个核心板块。以下为具体职能 商品 创建 针对商品支付方式，收益分成规则，基本的销售属性（如打包销售数量等）等内容进行初始化。 更新 针对商品基本属性进行更改。 下架 商品数据不能物理删除，只能下架。 营销 可以给商品添加通用的营销属性，比如是否支持优惠券扣减，是否打折，是否特价等 套餐 业务往往需要在商品之上有套餐的概念，便于运营维护。套餐的概念其实是多个商品基本信息的模板，便于业务服务在把商品信息跟业务实体绑定时进行使用。 支付 安全 统一支付流程，使用预下单环节生成验证参数，在进行真正支付时检验 支付方式 针对不同的支付渠道，如虚拟币/微信/支付宝等，提供便捷的API服务，包括支付及第三方签约。支持自动续费等支付场景，业务无需自己实现。 用户侧资金流水格式 买家及卖家流水统一管理，业务不需要进行维护。 收益分成 结合商品分成属性，对业务研发透明。 退款流程 统一业务退款流程管理。 订单 生命周期 支持订单查询，根据支付流程，将订单状态划分为预下单（创建）、未支付、已完成、进行中（待确认、不确定是否已扣费）、异常（因各种系统原因未支付成功）、超时（已支付在指定时间范围内没有进行业务操作）、待补偿（不确定是否支付成功的订单）、人工关单（运营人员操作） 自动补偿 支付结果未最终确定 支付流程异常时，未确认支付结果的订单，统一定时扫描结果通知业务 业务操作未成功 交易服务支持统一管理订单的业务操作状态，业务可选择接入，会定时通知业务处理不成功的订单给业务 订单流水 订单的每一步操作都会记录下来，通过流水可以看到一张订单经过了哪些环节，包括异常情况及补偿的记录 对账 报表及明细数据 提供通用统计报表及明细数据给运营人员及财务人员进行对账 自动对账 与上游平台（支付平台）进行定时自动进行数据比对，将比对结果及异常情况通知相关人员。 数据分析 商业化通用分析指标 基于通用商品及订单数据结构，数据分析人员在进行数据处理时的数据指标可以应用于所有接入的业务，无需额外开发。可以让数分人员把重点放在分析模型的提升上。 核心设计 商品 商品这块其实也比较简单，就增查改，需要注意的主要是苹果商品，我们的做法是一个业务一个价位共用一个IAP商品id，来关联多个业务商品。kylin是上游的交易服务，可以当成第三方支付服务来看。商品的分成模式管理，在业务对接时确定是按固定比例还是每个商品个性化定义，为固定比例时，业务调用相关接口可以忽略分成数量的相关设置，反之，就必须设置，否则接口返回参数错误。 商品管理 商品营销属性/套餐属性新增 支付 普通接口就不详细介绍了，根据业务常见场景抽象实现即可。主要聊一下高级接口，通过对外提供的接口包，实现提供一个接口，多个功能的实现，包括幂等/异常锁定不可重复支付/支付/业务处理状态透明管理。 用法 提供的服务类类名为TradeCoinFlow。 创建xxxTradeManager继承并实现TradeCoinFlow，继承该类构造方法，并添加@Inject声明，注入TradeService实例。 创建xxxTradeHandler实现PayByCoinHandler接口并实现orderBizOpt(ResponsePayByCoin payByCoin)方法。 业务流程中在调用预下单接口之后，调用xxxTradeManager.payByCoin(PreOrder preOrder, PayByCoinHandler payByCoinHandler) 进行金币扣费 针对返回状态码进行结果处理 交互流程 交易过程会针对 用户-商品 进行加锁，默认半小时，正常交易完之后解除，若交易异常，会针对不需要补偿的情况解锁，需要补偿的订单会在订单模块的监听实现业务补偿完成之后自动解锁。 订单 订单是在预下单中生成（防刷接了风控），并在支付时验证更新状态。针对订单模块主要想讲的是关于订单监听及补偿订单监听的相关内容。 其实主要思想还是把补偿的逻辑实现放到通用服务，让业务使用更简单舒服。 心得 技术方案 除了面向业务开发，更要面向领域及能力开发 需求初期就做通用服务有可能会比较痛苦，但是一开始不做，后面基本也不会做，除非是外部压力。 迭代优化 时间往往有限，需要多留意以下方面 数据结构的设计 接口协议的设计 明确职能，高内聚，慎重引入外部依赖 持续优化 尽可能完善服务领域的能力 留意迭代中遗留下的性能风险 业务大局观 清晰认知自己所在业务的大模块，挑选某个模块进行深入思考研究，稳定之后再慢慢转移其它模块 尝试预估业务走向，多些与产品交流及多方争取资源，合理的事情大家都会支持及认可。 技术债 由于在迭代中跟随业务需求节奏，总会有为了时间在技术方案上让步的时候，所以需要清晰到底有哪些技术点没做好，以便新的迭代来临时评估是否可以带上 流程规范以外的发挥空间 别让工具成为限制能力的绊脚石 不是说工具/流程规范不好，而是说不要因为现有团队有这些东西，就限制对外提供的能力。举个例子，我们对外提供接口包使用的是一个叫autoapi的工具，你把pb文件定义好，就能自动生成接口包的接口及协议结构体，是非常好用的工具，但是也因此很多人不会在接口包上再思考太多，像上面提供的TradeCoinFlow和监听回调的类，其实就是对基本接口的及配置的封装，如锁、kafka的group和topic分配等，对外提供一个流程的完整交互，而对接方只需要关心他自己的业务实现，其它都他来说都是透明的，这样对接方就会非常舒服。 项目以外 个人由于业务发展问题，接下来会去参与支持公司直播版块的内容，期望能学习更多内容，更多积累。原本负责的商业化的内容也会持续关注跟进。]]></content>
      <categories>
        <category>设计</category>
      </categories>
      <tags>
        <tag>架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[赛程-活动-榜单模板实现方案(一)]]></title>
    <url>%2F2019%2F12%2F22%2F%E8%B5%9B%E7%A8%8B-%E6%B4%BB%E5%8A%A8-%E6%A6%9C%E5%8D%95%E6%A8%A1%E6%9D%BF%E5%AE%9E%E7%8E%B0%E6%96%B9%E6%A1%88-%E4%B8%80%2F</url>
    <content type="text"><![CDATA[前言继商业化产品架构及技术规划后续，与团队及部门各方大佬探讨都得到高度认可，接下来便是如何落地。由于身在业务部门，不可能本末倒置，在业务能够按计划发展的同时进行技术沉淀是最好的方向。个人的思路是很多事情都不是一蹴而就，模块先划分好，每个模块贴合业务迭代进行技术迭代。 背景其实无论商业化还是普通平台都比较大机率会有赛程/活动/榜单的运营需求，以往本人所在的团队有这种需求的时候有两种运作方式，一种是定向开发，来一个做一个，做完就丢，一种是使用另外一个部门的公共活动模板。这其中定向开发的自然不用说有什么问题，使用公共活动模板本身没什么问题，但是问题是跨团队跨部门，当运营有超出公共活动模板本身能力需求的时候，就会满足不了，跨部门进行支持的话还会带来几个问题，主要是后期维护及责任边界问题，还有服务升级的问题对原有的功能影响，故此决定着手做适合自己部门特性的模板服务。 契机刚好是在有年底活动需求，评估需求定向开发工作量及模板开发工作量相关不会太多，决定于这个项目落地第一期的设计。 实体划分由于个人所在公司是做媒体UGC平台，当然模板本身的设计不会受这个影响，只是举例方面我会用平台特性来讲解。 根据特性，先抽象成赛制/活动/榜单三种实体，赛制一对多活动，活动一对多榜单，榜单可脱离赛制/活动独立存在，活动可脱离赛制。活动有模块概念，一个活动模块可以有多种类型，其中一种榜单，本次主要也是先实现榜单类型。 榜单属性说明展示类型根据本次需求有pk榜/普通排行榜，其实只要是榜单，都是普通排行榜+不同的展示形式，pk榜便是多了pk组及PK指标信息。 元数据结构榜单是本次项目的承载核心，主要包括基本信息、指标等元数据。 榜单基本信息表1234567891011121314151617CREATE TABLE `ranking_list` ( `id` bigint(20) NOT NULL COMMENT &apos;榜单id&apos;, `biz_type` smallint(6) NOT NULL DEFAULT &apos;0&apos; COMMENT &apos;业务类型&apos;, `biz_name` varchar(50) NOT NULL DEFAULT &apos;&apos; COMMENT &apos;业务名称&apos;, `name` varchar(50) NOT NULL DEFAULT &apos;&apos; COMMENT &apos;榜单名称&apos;, `rank_type` smallint(6) NOT NULL DEFAULT &apos;0&apos; COMMENT &apos;0:列表榜单,1:PK榜&apos;, `start_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &apos;开始时间&apos;, `end_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &apos;结束时间&apos;, `opt_type` bit(10) NOT NULL DEFAULT &apos;0&apos; COMMENT &apos;数值操作类型，低位第一位表示是否需要自动淘汰，第二表示是否业务结算&apos;, `opt_time_type` int(2) NOT NULL DEFAULT &apos;0&apos; COMMENT &apos;数值按操作类型执行频率类型，0为不指定，1为每小时，2为每天，3为每周，4为每月，5为每年，6为指定时间（最小粒度小时）&apos;, `status` smallint(1) NOT NULL DEFAULT &apos;1&apos; COMMENT &apos;状态：0-正常 1-下架 2-系统结算中 3-业务结算中&apos;, `extra` varchar(1000) NOT NULL DEFAULT &apos;&apos; COMMENT &apos;扩展参数，json格式存储，比如自动淘汰相关参数，榜单分块展示信息等&apos;, `create_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &apos;创建时间&apos;, `last_update_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT &apos;最后更新时间&apos;, `last_operator_id` bigint(20) NOT NULL COMMENT &apos;最后更新人id&apos;, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT=&apos;通用排行榜&apos;; 指标信息 1234567891011121314151617CREATE TABLE `activity_indicator` ( `id` bigint(20) NOT NULL COMMENT &apos;指标id&apos;, `biz_type` smallint(6) NOT NULL DEFAULT &apos;0&apos; COMMENT &apos;业务类型&apos;, `sub_biz_type` smallint(6) NOT NULL DEFAULT 0 COMMENT &apos;业务子类型，用来区分具体的指标类型&apos; `biz_name` varchar(50) NOT NULL DEFAULT &apos;&apos; COMMENT &apos;业务名称&apos;, `item_id` bigint(20) NOT NULL COMMENT &apos;元素id，如榜单id&apos;, `name` varchar(50) NOT NULL DEFAULT &apos;&apos; COMMENT &apos;指标名称&apos;, `prefix_unit_name` varchar(20) NOT NULL DEFAULT &apos;&apos; COMMENT &apos;前置指标单位&apos;, `suffix_unit_name` varchar(20) NOT NULL DEFAULT &apos;&apos; COMMENT &apos;后置置指标单位&apos;, `status` smallint(1) NOT NULL DEFAULT &apos;1&apos; COMMENT &apos;状态：0-正常 1-下架&apos;, `seq` smallint(3) NOT NULL DEFAULT &apos;0&apos; COMMENT &apos;序号&apos;, `create_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &apos;创建时间&apos;, `last_update_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT &apos;最后更新时间&apos;, `last_operator_id` bigint(20) NOT NULL COMMENT &apos;最后更新人id&apos;, PRIMARY KEY (`id`), KEY `idx_item` (`item_id`) USING BTREE,) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT=&apos;通用活动指标&apos;; 指标来源123456789101112CREATE TABLE `activity_indicator_source` ( `id` bigint(20) NOT NULL COMMENT &apos;来源id&apos;, `indicator_id` bigint(20) NOT NULL COMMENT &apos;记录id&apos;, `source_type` int(10) NOT NULL DEFAULT &apos;0&apos; COMMENT &apos;指标来源类型，1表示xxx，2表示xxx，3表示xxx&apos;, `extra` varchar(500) NOT NULL DEFAULT &apos;&apos; COMMENT &apos;扩展参数，json格式存储，比如来源的计算规则&apos;, `status` smallint(1) NOT NULL DEFAULT &apos;1&apos; COMMENT &apos;状态：0-正常 1-下架&apos;, `create_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &apos;创建时间&apos;, `last_update_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT &apos;最后更新时间&apos;, `last_operator_id` bigint(20) NOT NULL COMMENT &apos;最后更新人id&apos;, PRIMARY KEY (`id`), INDEX `idx_indicator_id_source_type`(`indicator_id`, `source_type`) USING BTREE) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT=&apos;通用活动指标来源&apos;; PK分组元信息1234567891011121314CREATE TABLE `ranking_list_pk_group_info` ( `id` bigint(20) NOT NULL COMMENT &apos;分组id&apos;, `biz_type` smallint(6) NOT NULL DEFAULT &apos;0&apos; COMMENT &apos;业务类型&apos;, `biz_name` varchar(50) NOT NULL DEFAULT &apos;&apos; COMMENT &apos;业务名称&apos;, `item_id` bigint(20) NOT NULL COMMENT &apos;元素id，如榜单id&apos;, `name` varchar(50) NOT NULL DEFAULT &apos;&apos; COMMENT &apos;小组名称&apos;, `status` smallint(1) NOT NULL DEFAULT &apos;0&apos; COMMENT &apos;状态：0-正常 1-下架&apos;, `seq` smallint(3) NOT NULL DEFAULT &apos;0&apos; COMMENT &apos;序号&apos;, `create_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &apos;创建时间&apos;, `last_update_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT &apos;最后更新时间&apos;, `last_operator_id` bigint(20) NOT NULL COMMENT &apos;最后更新人id&apos;, PRIMARY KEY (`id`), INDEX `idx_item_id`(`item_id`) USING BTREE) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT=&apos;排行pk分组元信息&apos;; PK分组成员信息123456789101112CREATE TABLE `ranking_list_pk_group_member_info` ( `id` bigint(20) NOT NULL COMMENT &apos;小组成员信息记录id&apos;, `group_id` bigint(20) NOT NULL COMMENT &apos;分组id&apos;, `target_id` bigint(20) NOT NULL COMMENT &apos;对象id&apos;, `status` smallint(1) NOT NULL DEFAULT &apos;0&apos; COMMENT &apos;状态：0-正常 1-下架&apos;, `seq` smallint(3) NOT NULL DEFAULT &apos;0&apos; COMMENT &apos;序号&apos;, `create_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &apos;创建时间&apos;, `last_update_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT &apos;最后更新时间&apos;, `last_operator_id` bigint(20) NOT NULL COMMENT &apos;最后更新人id&apos;, PRIMARY KEY (`id`), INDEX `idx_group_id_target_id`(`group_id`, `target_id`) USING BTREE) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT=&apos;pk分组成员信息&apos;; 对象池榜单从参与者角度来说分为无限及有限两种需求场景，本次需求主要为有限场景。其实很多业务会用到关联对象这个概念，比如本次的活动榜单参与者，流量入口的指定者等等。 表设计123456789101112131415CREATE TABLE `common_target_pool` ( `id` bigint(20) NOT NULL COMMENT &apos;记录id&apos;, `biz_type` smallint(6) NOT NULL DEFAULT &apos;0&apos; COMMENT &apos;业务类型&apos;, `biz_name` varchar(50) NOT NULL DEFAULT &apos;&apos; COMMENT &apos;业务名称&apos;, `item_id` bigint(20) NOT NULL DEFAULT &apos;0&apos; COMMENT &apos;业务元素id&apos;, `target_type` smallint(1) NOT NULL DEFAULT &apos;0&apos; COMMENT &apos;业务目标类型&apos;, `target_id` bigint(20) NOT NULL DEFAULT &apos;0&apos; COMMENT &apos;目标id&apos;, `status` smallint(1) NOT NULL DEFAULT &apos;1&apos; COMMENT &apos;状态：0-正常 1-下架&apos;, `create_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &apos;创建时间&apos;, `last_update_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT &apos;最后更新时间&apos;, `last_operator_id` bigint(20) NOT NULL COMMENT &apos;最后更新人id&apos;, PRIMARY KEY (`id`), KEY `idx_biz_item` (`biz_type`,`item_id`) USING BTREE, KEY `idx_biz_target` (`biz_type`,`target_id`) USING BTREE) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT=&apos;通用目标关联池&apos;; 对象池作为通用模块读多写少，缓存层按CAP（cache aside pattern）来设计。根据数据量大小做对应的分表策略，分表策略及实践另外文章再谈。 数值服务榜单最基本的功能之一就是数值累加，刚好我们接下来也有积分相关的需求，所以也趁着这次抽象出来。数值服务的职能提供数值增加/减少/排序服务，是一个写多/读多的服务。 表设计123456789101112131415161718192021CREATE TABLE `common_value_pool` ( `id` bigint(20) NOT NULL COMMENT &apos;记录id&apos;, `biz_type` smallint(6) NOT NULL DEFAULT &apos;0&apos; COMMENT &apos;业务类型&apos;, `biz_sub_type` smallint(6) NOT NULL DEFAULT &apos;0&apos; COMMENT &apos;业务子类型&apos;, `biz_name` varchar(50) NOT NULL DEFAULT &apos;&apos; COMMENT &apos;业务名称&apos;, `item_id` bigint(20) NOT NULL DEFAULT &apos;0&apos; COMMENT &apos;业务元素id&apos;, `target_type` smallint(1) NOT NULL DEFAULT &apos;0&apos; COMMENT &apos;业务目标类型&apos;, `target_id` bigint(20) NOT NULL DEFAULT &apos;0&apos; COMMENT &apos;目标id&apos;, `target_value` bigint(20) NOT NULL DEFAULT &apos;0&apos; COMMENT &apos;目标值&apos;, `seq` int(11) NOT NULL DEFAULT &apos;0&apos; COMMENT &apos;排序&apos;, `opt_start_time` datetime NOT NULL DEFAULT &apos;2019-01-01&apos; COMMENT &apos;数值可操作开始时间&apos;, `opt_end_time` datetime NOT NULL DEFAULT &apos;2119-01-01&apos; COMMENT &apos;数值可操作结束时间&apos;, `status` smallint(1) NOT NULL DEFAULT &apos;0&apos; COMMENT &apos;状态：0-正常 1-下架&apos;, `action_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &apos;行为时间&apos;, `create_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &apos;创建时间&apos;, `last_update_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT &apos;最后更新时间&apos;, `last_operator_id` bigint(20) NOT NULL DEFAULT &apos;0&apos; COMMENT &apos;最后更新人id&apos;, PRIMARY KEY (`id`), KEY `idx_biz_item` (`biz_type`,`item_id`) USING BTREE, KEY `idx_biz_target` (`biz_type`,`target_id`) USING BTREE) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT=&apos;通用数值池&apos;; 数值服务读取数据方面也是使用缓存CAP设计，难度主要是在写方面，重点如下: 由于是面向通用服务开发，所以使用消息异步写的方法，使用有界线程池限定服务支撑量，超过服务支撑量的请求丢到待处理请求池，如果待处理请求池写入失败，丢回队列重新排队，风险是有可能会造成消息堆积 幂等控制。接口预留业务传入会话id，以会话id为维度进行控制 数值变更安全问题使用原始值加版本号乐观锁设计。数值加减涉及先读后写，在写入前需要对比原始值，避免ABA问题，使用版本号。 为保证数值安全在并发高的时候有比较大的机率会出现操作失败，而对于业务来说，不应该让业务处理并发失败的结果，返回处理中状态，记录并发失败数据，使用定时补偿策略。 活动活动本身没什么，除了基本属性就是预留模块的概念，本次主要是榜单和奖金池(对应榜单的总数加和)。 活动模块123456789101112131415CREATE TABLE `activity_module_info` ( `id` bigint(20) NOT NULL COMMENT &apos;记录id&apos;, `acivity_id` bigint(20) NOT NULL DEFAULT 0 COMMENT &apos;活动id&apos;, `module_group` smallint(2) NOT NULL DEFAULT 0 COMMENT &apos;模块组&apos;, `module_type` smallint(2) NOT NULL DEFAULT 0 COMMENT &apos;模块类型，1为榜单&apos;, `module_seq` smallint(2) NOT NULL DEFAULT 0 COMMENT &apos;模块排序&apos;, `target_id` bigint(20) NOT NULL DEFAULT 0 COMMENT &apos;关联对象id，当type为1，为榜单id&apos;, `target_seq` smallint(2) NOT NULL DEFAULT 0 COMMENT &apos;关联对象排序&apos;, `status` smallint(1) NOT NULL DEFAULT &apos;1&apos; COMMENT &apos;状态：0-正常 1-下架&apos;, `extra` varchar(1000) NOT NULL DEFAULT &apos;&apos; COMMENT &apos;扩展参数，json格式存储&apos;, `create_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &apos;创建时间&apos;, `last_update_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT &apos;最后更新时间&apos;, `last_operator_id` bigint(20) NOT NULL COMMENT &apos;最后更新人id&apos;, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT=&apos;活动模块信息&apos;; 人工干预做榜单很常见的就会有人工干预的需求，比如榜单初始值等，或者“运营手段”策略支持也有，这里我们抽象了人工干预的常用属性，目标值/平均数/次数/频率/总时长 进行控制。基本上对数值的干预用以上属性能够覆盖许多需求了。 模块交互简单的模块如下 总结本次服务己上线，稳定运行。本次主要是针对服务端进行设计优化，前端还未接入，还是有很大一部分定向开发，在下次活动需求来之时，将后台及前端进行接入和服务端进行完善。]]></content>
      <categories>
        <category>设计</category>
      </categories>
      <tags>
        <tag>架构</tag>
        <tag>商业化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[商业化产品规划与服务架构思考]]></title>
    <url>%2F2019%2F10%2F20%2F%E5%95%86%E4%B8%9A%E5%8C%96%E4%BA%A7%E5%93%81%E8%A7%84%E5%88%92%E4%B8%8E%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84%E6%80%9D%E8%80%83%2F</url>
    <content type="text"><![CDATA[背景近来有幸负责了公司自己部门一个商业化小组的研发事项，结合自己的工作经验对产品将来走向和服务架构规划梳理自己的见解，希望可以让小组目标一致，高效地进行积累进行沉淀。 业务理解及规划按个人愚见商业化前期主要分为几个核心模块，GMV短期快速增长/基础设施搭建/用户消费习惯培养/渠道引流变现能力，每个模块并非独立，而是相互交叉相互依赖。 GMV短期快速增长是团队运作过程中常见的场景，单独划分模块往往是因为支持团队在指定时间内可以达到相应指标而需要低成本快速支持运营手段达到指标。其中需要流量管控/活动属性管控/玩法沉淀配套/交易流程动态调整营销策略 基础设施主是为实现商业化整套玩法的服务支撑，包括并不限于流量入口/交易流程/会员体系/特权体系/积分体系/活动体系/营销体系/租赁体系等 用户消费习惯培养主要需要对用户进行分层，需要在数据层面制定好分析模型，统一业务指标数据字典及统计口径，在研发过程预留足够的空间给后期分析。 渠道引流变现一般为与外部渠道，通过流量付费或利益分成的形式进行合作 团队行事基准各行各业，不同的团队行事基准可能很多不同，但是基本都离开不了一种通用原则，领域模型。积累方法论及实践方法，抽象领域分析模型及执行策略。团队就以此进行需求迭代，产品研发，运营事项及日常工作交流指导。 领域模型一般两种来源，专家或行业通用模型修改加上经验积累。大多数公司不像大厂会有专门的专家，绝大多数公司更是没有领域模型的发展概念。 领域模型一般先按团队内对产品理解较深的人制定第一版框架，后续不停通过迭代优化。前期可选择通用模型进行指标组建，再细化模块。如决策可尝试使用SWOT，人人都会的RFM用户分层模型（事实上维度选择及划分非常有学问），用户行为漏斗分析模型，盘面分析模型等。盘面分析及用户行为分析是最基本。 简单举个例子，通过接口数据发现付费转化率低，即发起了预下单，但是却没有最终成功支付，那猜测主要要嘛是付费内容质量问题，要嘛是充值流程问题，那可以从用户到底有没有充值来判断，然后进行下步策略。 当然有理论支撑之后，必须在基础设施上能支持得上，在研发过程需要预埋一些点。 技术服务架构有以上前提的理解下，对总体的服务架构进行了个初步的划分 业务网关负责外部交互，web对应http rest, as是我们公司自己封装的一套通信交互标准,消息网关用于与公司其它内部服务通信。 在这一层，需要注意的是协议层的相关模型定义，整个系统对内对外通信，吸取DDD的指导思想，定义好业务领域模型。一家公司发展到一定程度之后，代码功能模块会经过很多人维护研发，想保证成本（结构封装，接口适配、沟通学习等），就必须梳理沉淀相关的业务领域模型，不然越往后越难控制。 除了定义模型，协议规范也是必须，请求体/返回体结构、状态码约定、分页/聚合/规则查询方式等。 商业化核心服务商业化通用逻辑可以看到在商业化发展过程中可以抽象的服务其实有可能会很多，可以有一个汇总服务，作为母体孵化其它模块，当达到比较成熟或遇到业务机遇时可进行抽离独立。 服务间的通信领域模型事件驱动服务只关注领域内事项处理，将处理结果通过消息总线广播出去，有需要的服务自行进行定阅，参考ddd的设计理念，在发送消息和解析加入工具包，封装领域模型及相应的事件状态和流程。 系统规模大了之后往往需要考虑事件流的问题，需要对事件顺序编排，有可能会多个上游依赖的情况，为了避免这种情况，可以只关注核心一个事件，主动查询其它模块结果的处理方式，这样保证了一个事件流是树状结构。 研发事件管理服务及后台，拿kafka为例，可以在应用层面添加工具包，为producer添加生产标识，consumer添加消费标识，可以用注解和扫描，并发送给事件管理服务，这样事件流的结构就可以被绘画。这样只要稍微做下支持，就可以知道整个事件流每个环节的处理情况，数据统计等，甚至可以自动/人工进行介入消息失败/异常处理策略的实现。 当然前期可简单的先各个模块自维护各自的消息发送，消费和补偿实现。比如只是定义各自的消息的队列名、结构和行为状态定义，让下游各自监听处理。在服务完善之后再进行迁移。 补偿模块凡是依赖消息通知的实现，在完整性和稳定性上考虑，必须加上补偿模块，凡是需要依赖消费事件的服务都需要制定主动询问上流的策略，比如开通会员触发了特权发放，除了正常消息通知以外，特权服务需要主动询问会员服务最近一段时间内有哪些用户开通了会员但是还没发放特权，并进行发放，当然也需要做好幂等控制。 而补偿也可以像事件流管理平台一样，提供工具包，支持补偿发起者注册到平台上，可以对系统中的补偿行为进行监控以及介入。 基础服务一般商业化会需要一些基础服务支撑，这一层会尽量剥离业务特性，专注专业领域上的研发。本文主要介绍业务层面的实现，便不多加介绍这一环节。 结语目前在公司内只是把以上的相关业务理解及设计思考与团队的产品/研发同事进行了同步，在每个点上都有相应的积累，但是还是任重而道远，而要独步完善及验证。 今天加油，明天也加油！]]></content>
      <categories>
        <category>设计</category>
      </categories>
      <tags>
        <tag>架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一种serverless的实现方案]]></title>
    <url>%2F2019%2F09%2F16%2F%E4%B8%80%E7%A7%8Dserverless%E7%9A%84%E5%AE%9E%E7%8E%B0%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[背景自从上次参加qcon开发者大会，一直在思考serviceless的可执行方案，一路上也在公司推进中，虽然进度有点慢，没办法，业务太忙了。。。 架构总览 服务模块网关需要实现配置化扩展及热更新接口服务，主要需要支持数据的curd场景。抽象的说其实只有2种场景，就是数据的查询和变更。 抽象交互场景，制定一套接口使用规范 查询查询一般分明细查询和聚合查询，核心结构如下： 字段列表 支持别名，数据格式定义 请求参数列表（过滤） 支持别名，请求参数类型（如日期、范围、字段值匹配等） 排序 支持别名，排序类型（升序降序） 分页 游标或者页码 之前已经有 基于solr服务提供通用配置化接口服务 可以参考 变更变更一般有replace和del场景，del比较简单，只需要请求参数列表即可。replace的核心结构如下： 变更数据 以key value的形式传参，支持伪cas，传key的原值，如果不是原值放弃修改 请求参数列表（过滤） 支持别名，请求参数类型（如日期、范围、字段值匹配等） 安全需要针对使用方提供租赁服务，查询接口限流，变更接口安全参数派发及验证 语法引擎需要根据接口配置模板选择不同的数据源的语法进行转译，最基本的支持sql查询模板（JAVA动态编译/解析文本的一种简易方法）,如果存储层有不支持sql的中间件或者引擎，就需要定向开发。参考datax的设计，抽象组件,只针对reader和writer编程，以插件的形式加入项目对应的目录和修改对应的配置文件即可。 存储及查询引擎其实最简单在这一层添加个db，就已经能把一个简单的serviceless架构跑起来了 apache kudu + impala考虑到高可用、高性能、扩展性和成本的问题，又要支持oltp和olap，选择普通db的话很快就会到整套服务各方面的天花板，参考开源OLAP引擎测评报告 联表查询性能 单表查询性能 综合对比 综合考虑下选择impala 考虑kudu的原因，参考有了HBase为什么还要Kudu 其实选型上也是考虑到大厂都有在使用，impala不用说了，很多公司都用到tx/ali/神策等，kudu像京东/小米都有在用。正准备在公司申请开发环境进行探研。 搜索引擎搜索引擎在明细查询上有很优秀的支持，如es、solr redis业务很常用的，在数据存储上没太高要求的前提下的性能最优选择 配置以上模块的运作需要有一套元数据设计来支持，元数据主要包括几方面： 应用信息 安全信息，比如盐信息 接口描述 针对sql及特定语法的接口配置信息，之前已经有 基于solr服务提供通用配置化接口服务 可以参考 数据源信息 异常策略等 云函数sql和代码加载（代码块及jar包上传）两种实现思路，sql是成本最低，但是也限制比较多，代码热加载会有一些性能和安全隐患问题，需要额外的成本去维护。 数据同步使用了非普通db存储的方案，而且serviceless的目标并不是也不可能覆盖所有的场景，那就肯定存在需要进行数据同步的情况，数据同步行业内主要分批处理和流处理两种，当然直接服务对接也可以，不过不建议，因为会对接服务多了，会比较很难把控。 批处理使用azkaban进行离线调度是现在很多公司会做的，我们公司的大数据部门也即将提供基于azkaban改造的调度系统，可直接对接使用 流数据如果是面向业务的场景的，其实并没有像大数据场景那种实时更新模型推荐的需要，主要是想支持实时更新，使用kafka 和kafka streams 基本能满足(spring cloud stream 基于kafka的使用简析)。还有其它工具，如kettle或者apache nifi，但是考虑到是面向研发特性不建议直接使用这种数据处理流工具。这里更想提的其实是管道处理和管理的能力搭建。 数据的产生之后（source），会经过一到多层的中间处理（processor），最终将结果落地到某个地方（sink），基于这样的理念，可以很容易基于kafka抽象一套服务出来。但是缺少平台把控能力。 spring cloud data flow 就是管道管理平台，有很多现成的组件。SCDF (Spring Cloud Data Flow)的核心功能是ETL （Extract, Transform, Load ），Extract，Transform，Load 分别对应上图的Source，Processor 和Sink，这三个组件是Spring Boot 微服务，部署运行在SCDF之上的，三个微服务放在一起构成一个Stream（pipeline）用来实现数据处理，它们之间通过AMQP进行异步的消息传递。 架构简析 SCDF 由下面的Spring Cloud家族成员组成 服务组件 流处理 批处理支持 后台支持语言定义流程及拖拽操作 但是实践下来发现两个问题，一个是不能有通用组件环节，它是以cicd流水线管理方式，每条流水线的应用都得重新部署,没有公共流水线的概念（有可能我使用姿势不对?）,另一个问题是如果使用SCDF，就得跟公司现有的使用框架及发布部署平台对接，需要进行改造，这其中的成本也不小。 结语基本上serviceless的一种实现思路及方案已经描述完了，这其中会有很多技术难点及问题，之后在推进过程中再一一细述。]]></content>
      <categories>
        <category>设计</category>
      </categories>
      <tags>
        <tag>架构</tag>
        <tag>serviceless</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Qcon广州站]]></title>
    <url>%2F2019%2F07%2F14%2FQcon%E5%B9%BF%E5%B7%9E%E7%AB%99%E5%A4%A7%E4%BC%9A%E4%B8%AA%E4%BA%BA%E7%BA%AA%E8%A6%81%2F</url>
    <content type="text"><![CDATA[大会ppt下载地址 &ensp; &ensp;&ensp; &ensp;今年5月27号在举行的qcon全球开发者大会广州站，在下有幸，公司安排参加，就着大会的内容，个人闲聊一下看法。（工作比较忙，导致拖了一个半月才回过头来聊这次大会） Service Mesh&ensp; &ensp;&ensp; &ensp;qcon的大会安排是有不同卖场同时进行，自己优先选择了后端相关的微服务实战及高可用高性能架构专场参加。有幸见到arthas的作者，阿里在专场中更多针对他们是如何在微服务这块提升研发效能进行分享，网易及唯品会对service mesh的落地踩坑改善经验进行了讲解。&ensp; &ensp;&ensp; &ensp;对于service mesh，先感谢大厂和很多大牛在一些新的方向或者是旧技术点翻新上，给行业领头踩坑及推广。江南白衣说了句大实话，目前看来无论是哪里的service mesh的实践方案都还不够成熟，不适合生产环境大面积推广。&ensp; &ensp;&ensp; &ensp;个人认为service mesh虽然不一定会在公司落地，但是作为架构知识，还是有必要掌握，主要是针对服务云化之后的能力支持。目前国内市场上主要是Linkerd和Istio两个方案，个人准备就着Istio进行研究。 火爆的实时流&ensp; &ensp;&ensp; &ensp;在大会上刚好有空档，去听了一下阿里的flink改造版本，7月份已经将合并入官方主干且发版，真的是很厉害。然而在会议上透露着一些问题依然无法很好被解决，那便是数据初始化需求、与批处理比较的稳定性和多表聚合的复杂性问题。 service less的思考虽然service less与本次大会无直接关联，但是近几年我一直在研究service less及推荐落地，细想之下，其实service less的落地离不开成熟的微服务架构用于实例的管理及云函数的实现，成熟的存储方案及计算能力和数据流方案。接下来将会梳理一篇关于service less落地的文章。]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>qcon</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一次App首页代码优化纪要]]></title>
    <url>%2F2019%2F07%2F06%2F%E4%B8%80%E6%AC%A1App%E9%A6%96%E9%A1%B5%E4%BB%A3%E7%A0%81%E4%BC%98%E5%8C%96%E7%BA%AA%E8%A6%81%2F</url>
    <content type="text"><![CDATA[背景最近在负责公司APP首页性能优化相关项目，就着原来的技术方案及代码进行了重构，原来接口中存在的问题如下： 代码问题，瀑布式编码，导致单个类的代码很容易膨胀，最大体积的类已经快接近2000行代码，还是之前有优化过的。 代码问题，方法参数问题，方法参数没有封装，有一些通用方法的参数已经有十几个，不容易进行扩展，维护成本比较高。 性能问题，由于涉及到多种数据构造来源，没有进行批量处理，有很多rpc请求。 很多公司在发展过程中为了能快速满足业务，很多点并不是当时写代码的人没有考虑，而是根本没时间考虑，这都很正常，既然安排到这块的工作，就尽力做到最好。 先来看一下app当前的大概效果 可以看到app的设计是卡片加瀑布流的交互形式，旧的设计是每种卡片一种结构体，目前有28种卡片，给客户端和服务端都带来性能问题和维护成本，新的设计是将卡片抽象成统一结构体，主要分展示字段和预留扩展字段，有点像BI的结构设计，在这里就不展开讲。主要先记一下这个结构体命名为section。 旧代码流程简析 优化内容责任划分整理下来，其实接口处理流程可以划分为 获取卡片数据 获取实体数据，即卡片内容模板数据 构造结构体 补充卡片数据 位置调整 上下文内容作为链路参数将请求的内容进行处理后作为上下文内容参数传递进责任链，每个环节各自进行加工传递下个环节，比如section列表、推荐section个数等 卡片模板使用抽象模板，每种卡片的构造抽象成一种模板，持有通用接口，各自实现不同，包括获取实体id信息和构造section的方法等 使用桥接减少指定卡片调用的代码复杂度其实根据卡片类型即可知道使用哪种模板，使用桥接即可方便获取对应模板的实例进行处理 减少外部请求抽象实体环节，很方便可变多个单次为批量原来的接口中由于实现方案的问题，需要每次都获取DB配置数据及推荐数据，通过客户端回传的方式，改为当开启了推荐数据就不需要进行DB配置数据请求 改造后数据流程 代码功能模块更为内聚，入口类从原有的近2000行代码缩减为200行左右。每个扩展类的代码简洁清晰，大多不超过200行，其它不超过300行，便于维护。改造后的接口响应时间为旧接口的2/3，还待压测看具体数据]]></content>
      <categories>
        <category>设计</category>
      </categories>
      <tags>
        <tag>JAVA基础</tag>
        <tag>优化</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GC问题解决的那些套路]]></title>
    <url>%2F2019%2F05%2F19%2FGC%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3%E7%9A%84%E9%82%A3%E4%BA%9B%E5%A5%97%E8%B7%AF%2F</url>
    <content type="text"><![CDATA[利器介绍 gceasy 是一个国外在线的gc日志分析工具，可以帮你快速定位到gc问题，并且博客内容也有一些高级的gc问题排查分析文章，即blog.gceasy.io 简单问题 GC异常 主要是GC日志中有明确标明异常类型的情况，如 针对每种异常情况，某度和某歌都有很多资料带你飞，一般都由内存泄露及不合理的内存分配导致。OOM不同情况及解决方法 合理的内存分配及降低GC频次 针对mirror gc,major gc,full gc的频次管理，只要不是内存泄露引起，一般可以通过调整内存大小来解决，而合理的内存分配，在不考虑代码优化的情况下，需要进行一版参数配置之后观察GC情况之后，结合各个区域的回收机制可以调整改善。如果初期不知道怎么进行参数配置，根据应用所需，分配堆内存2-4G，新生代/老年代以1:2的比例配置。如果需要调整新生代的内存分配情况，记得默认情况下是eden:s0:s1为8:1:1 这种问题要求对垃圾回收器的策略及jvm堆内存模型比较清楚 进阶问题 调整某个阶段时长 并非所有GC阶段都可以直接配置时长，像parnew gc的单次时长无法直接控制，像这种情况一般可以通过内存大小调整，gc线程数的配置来间接改善，总时长可以通过频次来间接改善。 而有直接时长配置的参数，通过日志观察，不断进行调整，调整的套路基本为 观察原来的情况，取一个合理值进行配置观察 观察想调整的阶段情况及其它阶段，看是否会影响其它阶段的时长，比如减少preclean时长可能会影响remark的时长 是否有策略可以解决影响到的阶段，比如影响了remark时长，那就配合major gc 前进行一次mirror gc，但有可能会影响总的mirror次数及时长 跳转步骤1 这种问题要求对垃圾回收器具体的执行内容及步骤要比较清晰，清楚知道垃圾回收器在做什么操作以及会带来什么影响 ，了解安全点的概念及日志分析 基于GC日志时间参数进行调整 主要是针对 user,sys,real这三个值进行调整 user时间长导致real比较长 这种情况好处理，说明gc花费时间比较，从内存分配及并行线程数量分配角度入手 sys时间长导致real比较长 这种情况比较复杂，大多数情况下跟业务代码无直接关系，在后面的扫盲知识里有对应的字段意义说明及排障贴里面有对应的跟进情况，可以了解一下。基本思路是排除法，到最终需要strace抓进程的系统调用情况或跟进系统级别的情况如内存页，CPU，IO等。在系统各方面都正常情况下，可能Gc的时候向OS申请内存的时候导致的，启动参数加上-XX:+AlwaysPreTouch。 如果没有提前申请好内存，gc时年轻代向老年代copy对象的时候，老年代需要临时向OS申请内存。AlwaysPreTouch意味着在Jvm启动的时候申请好heap内存，堆内的每个page在启动的时候初始化为0，避免Jvm运行过程中临时向OS申请内存。 这种问题要求能够查看hotspot源码，能大概知道有什么操作，了解gc过程中单个gc操作时间的分配情况，如何进行调整及跟进，也得了解一些系统相关的知识 按公司某大神的说法，有时候只能靠玄学了，一路猜想及排除定位 简易方法论 GC问题可能还有很多情况是大家没遇到过，结合以上的问题类型，基本都是以下套路去跟进解决： 查看GC情况 定位问题 确定目标 最好是单个目标进行，不要同时调整多个内容，到头来不知道是哪个影响哪个，比如减少preclean时间，然后不增加remark时间，然后是不增加总体pause的时间，或者是减少full gc的次数，或者是减少mirror gc的次数 查询解决方案及实践 持续观察改进 知识扫盲 基于公司GC调优会涉及到的点，整理了对应的知识 GC日志时间概念 real —— 程序从开始到结束所用的时钟时间。这个时间包括其他进程使用的时间片和进程阻塞的时间（比如等待 I/O 完成） user —— 进程执行用户态代码（核心之外）所使用的时间。这是执行此进程所使用的实际 CPU 时间，其他进程和此进程阻塞的时间并不包括在内。在垃圾收集的情况下，表示 GC 线程执行所使用的 CPU 总时间 sys —— 进程在内核态消耗的 CPU 时间，即在内核执行系统调用或等待系统事件所使用的 CPU 时间 安全点SafePoint概念及日志简析 概念 安全点是在程序执行期间的所有GC Root已知并且所有堆对象的内容一致的点。 从全局的角度来看，所有线程必须在GC运行之前在安全点阻塞。 （作为一种特殊情况，运行JNI代码的线程可以继续运行，因为它们只使用句柄。但在安全点期间，它们必须阻塞而不是加载句柄的内容。） 从本地的角度来看，安全点是一个显着的点，它位于执行线程可能阻止GC的代码块中。 大多数调用点都能当做安全点。 在每个安全点都存在强大的不变量永远保持true不变，而在非安全点可能会被忽视。 编译的Java代码和C / C ++代码都在安全点之间进行了优化，但跨安全点时却不那么优化。 JIT编译器在每个安全点发出GC映射。 VM中的C / C ++代码使用程式化的基于宏的约定（例如，TRAPS）来标记潜在的安全点。 类型 GC safepoint需要知道在那个程序位置上，调用栈、寄存器等一些重要的数据区域里什么地方包含了GC管理的指针；如果要触发一次GC，那么JVM里的所有Java线程都必须到达GC safepoint。 Deoptimization safepoint需要知道在那个程序位置上，原本抽象概念上的JVM的执行状态（所有局部变量、临时变量、锁，等等）到底分配到了什么地方，是在栈帧的具体某个slot还是在某个寄存器里，之类的。 如果要执行一次deoptimization，那么需要执行deoptimization的线程要在到达deoptimization safepoint之后才可以开始deoptimize。HotSpot中，安全点位置主要在： 方法返回之前 调用某个方法之后 抛出异常的位置 循环的末尾 为什么把这些位置设置为jvm的安全点呢,主要目的就是避免程序长时间无法进入safepoint,比如JVM在做GC之前要等所有的应用线程进入到安全点后VM线程才能分派GC任务 ,如果有线程一直没有进入到安全点,就会导致GC时JVM停顿时间延长,比如写了一个超大的循环导致线程一直没有进入到安全点,GC前停顿了8秒。 之所以只在选定的位置放置安全点是因为： 挂在安全点的调试符号信息要占用空间。如果允许每条机器码都可以是安全点的话，需要存储的数据量会很大（当然这有办法解决，例如用delta存储和用压缩） 安全点会影响优化。特别是deoptimization 安全点，会迫使JVM保留一些只有解释器可能需要的、JIT编译器认定无用的变量的值。本来JIT编译器可能可以发现某些值不需要而消除它们对应的运算，如果在安全点需要这些值的话那就只好保留了。这才是更重要的地方，所以要尽量少放置安全点 像HotSpot VM这样，在安全点会生成polling代码询问VM是否要“进入安全点”，polling也有开销所以要尽量减少。 还有一种情况是当某个线程在执行native函数的时候。此时该线程在执行JVM管理之外的代码，不能对JVM的执行状态做任何修改，因而JVM要进入安全点不需要关心它。所以也可以把正在执行native函数的线程看作“已经进入了安全点”，或者把这种情况叫做“在safe-region里”。JVM外部要对JVM执行状态做修改必须要通过JNI。所有能修改JVM执行状态的JNI函数在入口处都有安全点检查，一旦JVM已经发出通知说此时应该已经到达安全点，就会在这些检查的地方停下来把控制权交给JVM。 日志 开启参数 -XX:+PrintGCApplicationStoppedTime -XX:+PrintGCApplicationConcurrentTime -XX:+PrintSafepointStatistics -XX:PrintSafepointStatisticsCount=1 -XX:+UnlockDiagnosticVMOptions -XX:-DisplayVMOutput -XX:+LogVMOutput 格式 12vmop [threads: total initially_running wait_to_block] [time: spin block sync cleanup vmop] page_trap_count66935.969: GenCollectForAllocation [ 1782 0 0 ] [ 0 0 0 3 15 ] 0 除了GC，其他触发安全点的VM Operation包括： Biased lock revocation 取消偏向锁 Class redefinition (e.g. javaagent，AOP的代码植入) Various debug operation (e.g. thread dump 一条或所有线程，heapduump等) 线程情况 total: 所有的java线程数 initially_running: 号召进入安全点时，还是Running状态的线程数 wait_to_block: 所有线程都不Running时，仍不是Block状态的线程数 时间情况 spin: VMOP线程使用自旋，等待所有线程都不是Running的时间 block: VMOP线程基于锁，等待所有线程都是Block的时间 sync: spin+block +其他，这是从开始到进入安全点的总耗时 cleanup: 退出清理所用时间 vmop: 真正执行VM Operation的时间 Full GC 触发条件 由System.gc调用 老年代空间不足 永久代空间不足 gc 担保失败 在发生MinorGC前,检查老年代是否有连续空间,如果有,则执行,如果没有,根据设置:-XX:-HandlePromotionFailure 指定,如果打开,那么继续检查,当前老年代最大可用连续空间大于平均历次晋升到老年代大小,如果大于,则进行MinorGC,否则进行FullGC,如果HandlePromotionFailure 不设置 直接进行FullGC. Cocurrent mode failure 发生在cms的清理sweep阶段,发现有新的垃圾产生,而且老年代没有足够空间导致的 parnew 使用的是复制算法，并行回收 并行：多条垃圾回收线程并行工作，用户线程仍处于等待状态 并发: 垃圾收集线程跟用户线程同时执行，不一定是并行，可能交替执行，垃圾收集程序运行在区分业务线程的另外一个CPU上 serial共用配置参数 -XX:SurvivorRatio -XX:PretenureSizeThreshold -XX:HandlePromotionFailure 启用参数 -XX：+UseConcMarkSweepGC -XX: +UseParNewGC 性能参数 -XX:ParallelGCThreads &lt;=8?8:3+5n/8 触发条件 eden满了就进行 晋升条件 大对象直接进入老年代 PretenureSizeThreshold 长期存活对象将进入老年代 -XX:MaxTenuringThreshold=15 动态对象年龄判定 在Survivor空间相同年龄所有对象大小总和大于Survivor空间一半就会进入老年代 cms gc stage 1. CMS-initial-mark 初始标记 此阶段是初始标记阶段，是stop the world阶段，因此此阶段标记的对象只是从root集最直接可达的对象 2. CMS-concurrent-mark 并发标记 此阶段是和应用线程并发执行的，所谓并发收集器指的就是这个，主要作用是标记可达的对象 3. CMS-concurrent-preclean 执行预清理 此阶段主要是进行一些预清理，因为标记和应用线程是并发执行的，因此会有些对象的状态在标记后会改变，此阶段正是解决这个问题 4. CMS-concurrent-abortable-preclean 执行可中止预清理 加入此阶段的目的是使cms gc更加可控一些，作用也是执行一些预清理，以减少Rescan阶段造成应用暂停的时间 5. CMS-remark 重新标记 第二个stop the world阶段了，即Rescan阶段，此阶段暂停应用线程，对对象进行重新扫描并标记，主要是标记并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象 6. CMS-concurrent-sweep 并发清除 Start of sweeping of dead/non-marked objects. Sweeping is concurrent phase performed with all other threads running. 7. CMS-concurrent-reset 并发重设状态等待下次CMS的触发 In this phase, the CMS data structures are reinitialized so that a new cycle may begin at a later time. In this case, it took 0.127 secs. 线上用到的相关参数及新增参数 -XX:+CMSParallelInitialMarkEnabled 可以开启该阶段的并行标记，使用多个线程进行标记，减少暂停时间 -XX:+CMSParallelRemarkEnabled 同上，针对remark阶段 -XX:+UseCMSInitiatingOccupancyOnly 指定HotSpot VM总是使用-XX:CMSInitiatingOccupancyFraction的值作为old的空间使用率限制来启动CMS垃圾回收。 如果没有使用-XX:+UseCMSInitiatingOccupancyOnly，那么HotSpot VM只是利用这个值来启动第一次CMS垃圾回收，后面都是使用HotSpot VM自动计算出来的值。 -XX:CMSInitiatingOccupancyFraction=80 结合上面的参数使用，当老年代使用率达到百分之几的时候使用 -XX:+CMSScavengeBeforeRemark 这个选项强制HotSpot VM在CMS GC之前执行MinorGC，在再标记步骤之前做MinorGC，可以减少再标记的工作量，目的是减少young代的对象数 -XX:CMSMaxAbortablePrecleanTime：当abortable-preclean阶段执行达到这个时间时才会结束 -XX:CMSScheduleRemarkEdenSizeThreshold（默认2m）：控制abortable-preclean阶段什么时候开始执行，即当eden使用达到此值时，才会开始abortable-preclean阶段 -XX:CMSScheduleRemarkEdenPenetratio（默认50%）：控制abortable-preclean阶段什么时候结束执行 -XX:CMSWaitDuration=5010 保证了最晚每 X 毫秒进行一次判断是否要进行CMS GC，默认2S -XX:+CMSClassUnloadingEnabled 允许CMS对永久代不再使用的对象进行回收 CMS碎片整理 由于cms是基于标记-清理算法，会导致空间碎片，难以分配新的连续内存，所以要进行内存空间整理，保证可分配的连续性内存，要不然会触发full gc -XX:+UseCMSCompactAtFullCollection 用于在full GC之后增加一个碎片整理过程 -XX:CMSFullGCsBeforeCompaction=0 设置执行多少次不压缩的full GC之后，跟着来一次碎片整理过程 线上其它参数 -XX:LargePageSizeInBytes=128M 系统内存页相关参数 详细资料 https://www.cnblogs.com/bonelee/p/6207037.html -XX:+UseFastAccessorMethods 设置关闭快速调用成员方法，这里表述可能不是太准确。首先说明一下什么方法叫做AccessorMethods， 1必须是成员方法，静态方法不行， 2返回值类型必须是引用类型或者int，其它都不算， 3方法体的代码必须满足aload_0; getfield #index; areturn或ireturn这样的模式，方法名是什么都没关系，是不是get、is、has开头都不重要。 因为类方法方法体很简单，而且没有方法计数器，开启此设置后可以跳过对该类方法的编译。 但是貌似不推荐使用，详见以下链接 http://cr.openjdk.java.net/~never/6385687/ -XX:SoftRefLRUPolicyMSPerMB=0 设置每兆堆空闲空间中SoftReference的存活时间，默认值是1s CMS GC 触发条件 FullGC 预计完成CMS回收所需要的时间小于预计的老年代填满的时间 判断老年代内存使用率是否大于初始化参数，如果为true，则触发GC，如果为false，且UseCMSInitiatingOccupancyOnly 为true，则返回false 判断年轻代存活的对象晋升是否可能会失败，如果失败，触发GC。 如果metaSpace认为需要回收metaSpace区域，也会触发一次cms回收 Q&amp;A 在公司进行了分享，最后给听客问了几个问题，感觉算是分享的小考核吧，如果您有幸看到这篇文章并且看到这里不妨尝试着回答下: 实测新生代使用率90%左右会触发mirror gc,为什么？ 为什么线上不将CMSParallelInitialMarkEnabled作为默认参数? mirror gc ,young gc,major gc ,full gc的区别 结合jvm内存模型讲一下GC过程在每个区域的变化 CMSWaitDuration的值为什么要这样设置？]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>java基础</tag>
        <tag>JVM</tag>
        <tag>内存</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于solr服务提供通用配置化接口服务]]></title>
    <url>%2F2019%2F05%2F15%2F%E5%9F%BA%E4%BA%8Esolr%E6%9C%8D%E5%8A%A1%E6%8F%90%E4%BE%9B%E9%80%9A%E7%94%A8%E9%85%8D%E7%BD%AE%E5%8C%96%E6%8E%A5%E5%8F%A3%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[背景&ensp; &ensp;&ensp; &ensp;公司内部有基于solr搜索平台服务，在做需求的过程中，对接了搜索平台，发现可以将搜索平台的交互抽象并使用配置化的方式进行数据请求，这样一来，可以通过配置化的方式达到数据查询需求的快速实现，提高开发效率，于是进行了技术方案的设计与评估。 技术方案架构 时序图 类图 配置模板 项目落地情况&ensp; &ensp;&ensp; &ensp;经过一个3天快速开发及2天自测，开发好了第一个版本，service+http服务，不带可视化配置支持，紧接着对接了一个新需求，有直接对接http接口的，也有对接service的，在对接过程中情况如下 好处/优点 业务服务不用多次对接数据源层的实现，可以做到只要导入数据即可通过通用接口查询，节省调试的时间 因为配置化，支持热变更，快速调整入参及结果，节省联调时间 添加通用额外业务实体关联配置支持扩展源数据 最大的好处直接提供配置即可提供http接口，无需开发 配置模板一般比较简单，复杂需求才有可能会稍微比较复杂 坏处/缺点 前期服务还未完善前，联调链变长，会有在业务开发和搜索平台中间多一层服务需要调试的错觉 基于solr本身的特点，在数据分页的方式上会有特殊要求，是基于游标滚动的形式翻页，导致前端需要支持多一种分页查询的方法 还不能支持过于复杂的聚合查询,比如group by 字段A ,聚合查询count(带条件 字段B) 这样的查询目前还支持不了，只能支持group by 字段A ，count(B的各种值)，比如按分类（字段A）的聚合后推荐状态为1(字段B)的个数这样的支持不了，但是可以支持按分类（字段A）的聚合后不同推荐状态(字段B)的个数 目前还没有可视化的配置支持，接口一但多起来便会很难管理 业务如果对通用接口做熔断，只能涉及到的操作都统一处理，除非可以做到按参数熔断，公司目前的熔断器还不支持 solr的数据更新延迟问题 感想&ensp; &ensp;&ensp; &ensp;看起来貌似问题多多，但是好处的吸引力很大，而且遇到的问题貌似并没有不可解决的 项目计划 支持可视化配置，区分业务模块及api Id,后期支持对业务及api id限流 支持dataset的缓存策略配置 结合前端，可自研BI系统，这样连前端的后台活动类开发工作都可以减少 支持修改更新配置操作，支持事务操作 支持不同数据源 案例&ensp; &ensp;&ensp; &ensp;查询某个集合的原始字段,通过stat_date_s及nj_id_l两个字段过滤及自定义排序123456789101112131415161718192021&#123;&quot;id&quot;:xxx,&quot;key&quot;:&quot;xxx&quot;,&quot;searchToken&quot;:&quot;xxx&quot;,&quot;type&quot;:&quot;list&quot;,&quot;fields&quot;:[ ],&quot;queries&quot;:[ &#123;&quot;fieldName&quot;:&quot;stat_date_s&quot;,&quot;type&quot;:&quot;mix&quot;&#125;, &#123;&quot;fieldName&quot;:&quot;nj_id_l&quot;,&quot;type&quot;:&quot;field&quot;&#125; ],&quot;sorts&quot;:[ &#123;&quot;fieldName&quot;:&quot;nj_id_l&quot;,&quot;type&quot;:&quot;asc&quot;&#125;, &#123;&quot;fieldName&quot;:&quot;stat_date_s&quot;,&quot;type&quot;:&quot;asc&quot;&#125;], &quot;facets&quot;:&#123;&#125;, &quot;extInfo&quot;:[ ], &quot;fieldValueTransfer&quot;:[ ]&#125; &ensp; &ensp;&ensp; &ensp;复杂一点的列表查询1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283&#123;&quot;id&quot;:xxx,&quot;key&quot;:&quot;xxx&quot;,&quot;searchToken&quot;:&quot;xxx&quot;,&quot;type&quot;:&quot;list&quot;,&quot;fields&quot;:[ &#123;&quot;fieldName&quot;:&quot;id&quot;,&quot;alias&quot;:&quot;recordId&quot;&#125;, &#123;&quot;fieldName&quot;:&quot;nj_id_l&quot;,&quot;alias&quot;:&quot;anchorId&quot;&#125;, ...],&quot;queries&quot;:[ &#123;&quot;fieldName&quot;:&quot;stat_date_s&quot;,&quot;alias&quot;:&quot;statDate&quot;,&quot;type&quot;:&quot;field&quot;&#125;, ... ],&quot;sorts&quot;:[ &#123;&quot;fieldName&quot;:&quot;nj_id_l&quot;,&quot;type&quot;:&quot;asc&quot;&#125;], &quot;facets&quot;:&#123;&#125;, &quot;extInfo&quot;:[ &#123; &quot;connectFieldName&quot;:&quot;anchorId&quot;, &quot;type&quot;:&quot;user&quot;, &quot;field&quot;:[ &#123;&quot;fieldName&quot;:&quot;name&quot;&#125;, &#123;&quot;fieldName&quot;:&quot;thumb&quot;&#125; ] &#125; ], &quot;fieldValueTransfer&quot;:[ &#123; &quot;fieldName&quot;:&quot;anchorGroup&quot;, &quot;items&quot;:[ &#123;&quot;og&quot;:&quot;xxx主播&quot;,&quot;biz&quot;:0&#125;, &#123;&quot;og&quot;:&quot;xxxx主播&quot;,&quot;biz&quot;:1&#125; ] &#125; ]&#125;//看下http接口的请求及返回 参数&#123; &quot;statDate&quot;:&quot;2019-05-07T00:00:00Z&quot;, &quot;regTime&quot;:&#123;&quot;start&quot;:&quot;2013-07-30&quot;,&quot;end&quot;:&quot;2013-08-30&quot;&#125;, &#125;返回&#123; &quot;code&quot;: 0, &quot;data&quot;: [ &#123; &quot;anchorIndex&quot;: xxx, &quot;replayCountDaily&quot;: 0, &quot;anchorCover&quot;: &quot;xxx&quot;, &quot;hasPay&quot;: xx, &quot;fansCount&quot;: xxx, &quot;anchorGroup&quot;: &quot;&quot;, &quot;source&quot;: &quot;&quot;, &quot;anchorId&quot;: xxx, &quot;anchorName&quot;: &quot;xxx&quot;, &quot;anchorLevel&quot;: &quot;xxx&quot;, &quot;recordId&quot;: &quot;xxx&quot;, &quot;regTime&quot;: &quot;xxx&quot;, &quot;anchorCategory&quot;: &quot;xxx&quot;, &quot;replayCount&quot;: 0, &quot;voiceCount&quot;: xxx, &quot;replayCountWeekly&quot;: 0, &quot;band&quot;: xxx, &quot;lived&quot;: 0, &quot;recommendStatus&quot;: &quot;&quot;, &quot;lastUpdateTime&quot;: &quot;xxx&quot;, &quot;firstVoiceTime&quot;: &quot;xxx&quot; &#125;,... ], &quot;msg&quot;: &quot;OK&quot;, &quot;page&quot;: &#123; &quot;cursor&quot;: &quot;xxx&quot;, &quot;isLastPage&quot;: true, &quot;pageSize&quot;: 30, &quot;totalCount&quot;: 13, &quot;type&quot;: &quot;cursor&quot; &#125;&#125; &ensp; &ensp;&ensp; &ensp;聚合查询123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960&#123; &quot;id&quot;: xxx, &quot;key&quot;: &quot;xxx&quot;, &quot;searchToken&quot;: &quot;xxx&quot;, &quot;type&quot;: &quot;agg&quot;, &quot;fields&quot;: [], &quot;queries&quot;: [&#123; &quot;fieldName&quot;: &quot;stat_date_s&quot;, &quot;alias&quot;: &quot;statDate&quot;, &quot;type&quot;: &quot;field&quot; &#125;, &#123; &quot;fieldName&quot;: &quot;user_type_ti&quot;, &quot;alias&quot;: &quot;userType&quot;, &quot;type&quot;: &quot;field&quot; &#125; ], &quot;sorts&quot;: [], &quot;facets&quot;: &#123; &quot;groupByFieldName&quot;: &quot;xxxx&quot;, &quot;groupByFieldAlias&quot;: &quot;xxxx&quot;, &quot;alias&quot;: [&#123; &quot;fieldName&quot;: &quot;status_0_count&quot;, &quot;alias&quot;: &quot;recommendCount&quot; &#125;, &#123; &quot;fieldName&quot;: &quot;status_1_count&quot;, &quot;alias&quot;: &quot;forbiddenCount&quot; &#125; ], &quot;items&quot;: [&#123; &quot;type&quot;: &quot;agg&quot;, &quot;fieldName&quot;: &quot;status_s&quot;, &quot;aggName&quot;: &quot;status&quot; &#125;] &#125;, &quot;extInfo&quot;: []&#125;http请求无参数,返回结果&#123; &quot;code&quot;: 0, &quot;data&quot;: [ &#123; &quot;anchorClassTotal&quot;: xxx, &quot;anchorClass&quot;: &quot;xxx&quot;, &quot;noStatusCount&quot;: xxx &#125;,... ], &quot;msg&quot;: &quot;OK&quot;, &quot;page&quot;: &#123; &quot;cursor&quot;: &quot;xxx&quot;, &quot;isLastPage&quot;: false, &quot;pageNo&quot;: 0, &quot;pageSize&quot;: 30, &quot;totalCount&quot;: xxx, &quot;type&quot;: &quot;pagination&quot; &#125;&#125;]]></content>
      <categories>
        <category>设计</category>
      </categories>
      <tags>
        <tag>架构</tag>
        <tag>数据平台</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[long-gc案例分析]]></title>
    <url>%2F2019%2F05%2F04%2Flong-gc%E6%A1%88%E4%BE%8B%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[long gc优化&ensp; &ensp;&ensp; &ensp;近来发现负责研发的项目总是会收到long-gc的告警，比如： 12345678910major GC: - 2 (No GC) start: 2019-05-06 06:18:47.678, end: 2019-05-06 06:18:53.125 [Par Survivor Space] init:209664K; used:19.7%(41348K) -&gt; 19.7%(41348K); committed: 100.0%(209664K) -&gt; 100.0%(209664K) [Code Cache] init:2496K; used:19.7%(48450K) -&gt; 19.7%(48430K); committed: 19.9%(49088K) -&gt; 19.9%(49088K) [Compressed Class Space] init:0K; used:0.7%(7721K) -&gt; 0.7%(7721K); committed: 0.7%(8040K) -&gt; 0.7%(8040K) [Metaspace] init:0K; used:68569K -&gt; 68574K); committed: 69932K -&gt; 69932K) [Par Eden Space] init:1677824K; used:57.3%(961524K) -&gt; 59.6%(1001110K); committed: 100.0%(1677824K) -&gt; 100.0%(1677824K) [CMS Old Gen] init:1048576K; used:23.8%(250428K) -&gt; 13.4%(140549K); committed: 100.0%(1048576K) -&gt; 100.0%(1048576K) duration:5447ms, throughput:99.9% &ensp; &ensp;&ensp; &ensp;可以直接看到用的parnew + cms的收集器组合,也能看得出来主要回收行为发生在 old gen，所以就提取gc的日志来看，如下:12345678910111213141516171819202019-05-06T06:18:47.678+0800: 16712.771: [GC (CMS Initial Mark) [1 CMS-initial-mark: 250428K(1048576K)] 1253301K(2936064K), 0.0643432 secs] [Times: user=1.12 sys=0.00, real=0.06 secs]2019-05-06T06:18:47.742+0800: 16712.836: Total time for which application threads were stopped: 0.0655335 seconds, Stopping threads took: 0.0001332 seconds2019-05-06T06:18:47.742+0800: 16712.836: [CMS-concurrent-mark-start]2019-05-06T06:18:47.820+0800: 16712.913: [CMS-concurrent-mark: 0.077/0.077 secs] [Times: user=0.41 sys=0.00, real=0.07 secs]2019-05-06T06:18:47.820+0800: 16712.913: [CMS-concurrent-preclean-start]2019-05-06T06:18:47.831+0800: 16712.924: [CMS-concurrent-preclean: 0.010/0.011 secs] [Times: user=0.01 sys=0.00, real=0.01 secs]2019-05-06T06:18:47.831+0800: 16712.924: [CMS-concurrent-abortable-preclean-start]2019-05-06T06:18:49.745+0800: 16714.839: Total time for which application threads were stopped: 0.0014635 seconds, Stopping threads took: 0.0001513 seconds CMS: abort preclean due to time 2019-05-06T06:18:52.845+0800: 16717.939: [CMS-concurrent-abortable-preclean: 4.912/5.014 secs] [Times: user=5.40 sys=0.83, real=5.02 secs]2019-05-06T06:18:52.846+0800: 16717.940: [GC (CMS Final Remark) [YG occupancy: 1042070 K (1887488 K)]2019-05-06T06:18:52.847+0800: 16717.940: [Rescan (parallel) , 0.1073388 secs]2019-05-06T06:18:52.954+0800: 16718.047: [weak refs processing, 0.0108072 secs]2019-05-06T06:18:52.965+0800: 16718.058: [class unloading, 0.0341564 secs]2019-05-06T06:18:52.999+0800: 16718.092: [scrub symbol table, 0.0079842 secs]2019-05-06T06:18:53.007+0800: 16718.100: [scrub string table, 0.0021272 secs][1 CMS-remark: 250428K(1048576K)] 1292498K(2936064K), 0.1678019 secs] [Times: user=1.54 sys=0.00, real=0.17 secs]2019-05-06T06:18:53.014+0800: 16718.108: Total time for which application threads were stopped: 0.1689968 seconds, Stopping threads took: 0.0001364 seconds2019-05-06T06:18:53.015+0800: 16718.108: [CMS-concurrent-sweep-start]2019-05-06T06:18:53.125+0800: 16718.219: [CMS-concurrent-sweep: 0.111/0.111 secs] [Times: user=0.13 sys=0.03, real=0.11 secs]2019-05-06T06:18:53.125+0800: 16718.219: [CMS-concurrent-reset-start]2019-05-06T06:18:53.128+0800: 16718.222: [CMS-concurrent-reset: 0.003/0.003 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] &ensp; &ensp;&ensp; &ensp;眼尖的人可能已经看出来，事实上会stw的过程并没有很长,重点主要看CMS-initial-mark 和 CMS-remark 的记录，可以看到时间比较正常，所以看来CAT的long-gc告警是针对整个gc耗时的。接着看可以发现abortable-preclean的耗时比较长，如果对CMS gc每个阶段的工作都比较清楚，很快就可以找到方法解决。那我们的目标就是降低preclean的时长且不影响remark的时长，并且不会对gc的总体时长及频率带来影响。&ensp; &ensp;&ensp; &ensp;既然abortable-preclean长达5秒，那就先把preclean的最长时间限制设置短，添加-XX:CMSMaxAbortablePrecleanTime=1000参数。添加之后如果不做其它操作，有可能会带来remark的时间增加，所以基于preclean的特性，自然想到remark之前减少remark的工作负担，那就添加参数-XX:CMSScheduleRemarkEdenPenetration=20&ensp; &ensp;&ensp; &ensp;CMSScheduleRemarkEdenSizeThreshold、CMSScheduleRemarkEdenPenetration，默认值分别是2M、50%。两个参数组合起来的意思是预清理后，eden空间使用超过2M时启动可中断的并发预清理（CMS-concurrent-abortable-preclean），直到eden空间使用率达到50%时中断，进入remark阶段。我们设置成20，让Preclean更快地进入remark阶段-XX:+CMSScavengeBeforeRemark 在remark强制触发一次mirror gc&ensp; &ensp;&ensp; &ensp;这样配置的结果其实也可以预见，总的pause time会增加，按天来算的话，但是假设单次gc的时间加上强制触发的时间比之前的单次gc时间要短且总的puase time不会增加很多，那就达到我们的目的了。那多少才算多，具体得看应用的情况了。&ensp; &ensp;&ensp; &ensp;看一下配置前后的gc情况未配置参数前配置参数后而总的pause时间并没有增加，所以该问题得到了解决 优化后遇到的另一个问题&ensp; &ensp;&ensp; &ensp;在同一个项目进行配置后过了几天，突然出现不断进行CMS GC的情况，分析GC日志情况如下堆内存情况GC cause&ensp; &ensp;&ensp; &ensp;看到这两个模块的情况，基于上可以推测是新生代和老年代内存配置问题，检查jvm内存参数配置，发现配置了123 -XX:MaxHeapSize=3221225472-XX:MaxNewSize=2147483648&ensp; &ensp;&ensp; &ensp;也就是说配置了新生代与老年代的比例大约是2:1，官方默认配置在x86机器是应该是1:8，网上大部分资料都推荐是1:2,如果新生代配置比老年代小，有新生代晋升比较快的情况会导致CMS处理不过来,将参数调整为MaxHeapSize为4G，MaxNewSize略小于2G就不再出现 神奇的长initial Mark及YGC过长的sys时间&ensp; &ensp;&ensp; &ensp;在GC日志中发偶尔initial Mark偶尔会比较长，有出现1s以上的情况1234567891011121314151617181920212223242526272829302019-05-10T13:03:18.282+0800: 61533.941: [GC2019-05-10T13:03:18.283+0800: 61533.942: [ParNew: 848736K-&gt;9204K(943744K), 0.0091360 secs] 2526438K-&gt;1686979K(3040896K), 0.0105130 secs] [Times: user=0.10 sys=0.01, real=0.01 secs]2019-05-10T13:03:18.293+0800: 61533.952: Total time for which application threads were stopped: 0.0152630 seconds2019-05-10T13:03:18.296+0800: 61533.956: [GC [1 CMS-initial-mark: 1677774K(2097152K)] 1687161K(3040896K), 1.4645810 secs] [Times: user=0.00 sys=1.49, real=1.47 secs]2019-05-10T13:03:19.761+0800: 61535.421: Total time for which application threads were stopped: 1.4685620 seconds2019-05-10T13:03:19.762+0800: 61535.421: [CMS-concurrent-mark-start]2019-05-10T13:03:19.765+0800: 61535.425: Total time for which application threads were stopped: 0.0031970 seconds2019-05-10T13:03:19.780+0800: 61535.439: Total time for which application threads were stopped: 0.0044250 seconds2019-05-10T13:03:19.880+0800: 61535.540: [CMS-concurrent-mark: 0.111/0.119 secs] [Times: user=1.30 sys=0.30, real=0.12 secs]2019-05-10T13:03:19.881+0800: 61535.540: [CMS-concurrent-preclean-start]2019-05-10T13:03:19.900+0800: 61535.560: [CMS-concurrent-preclean: 0.019/0.020 secs] [Times: user=0.06 sys=0.00, real=0.02 secs]2019-05-10T13:03:19.901+0800: 61535.560: [CMS-concurrent-abortable-preclean-start] CMS: abort preclean due to time 2019-05-10T13:03:20.905+0800: 61536.564: [CMS-concurrent-abortable-preclean: 0.999/1.004 secs] [Times: user=1.80 sys=0.20, real=1.00 secs]2019-05-10T13:03:20.909+0800: 61536.568: [GC[YG occupancy: 470719 K (943744 K)]2019-05-10T13:03:20.909+0800: 61536.568: [GC2019-05-10T13:03:20.909+0800: 61536.569: [ParNew: 470719K-&gt;11056K(943744K), 0.0087720 secs] 2148494K-&gt;1688888K(3040896K), 0.0100970 secs] [Times: user=0.10 sys=0.01, real=0.01 secs]2019-05-10T13:03:20.919+0800: 61536.579: [Rescan (parallel) , 0.0042770 secs]2019-05-10T13:03:20.923+0800: 61536.583: [weak refs processing, 0.0237130 secs]2019-05-10T13:03:20.947+0800: 61536.607: [class unloading, 0.0255570 secs]2019-05-10T13:03:20.973+0800: 61536.632: [scrub symbol table, 0.0084850 secs]2019-05-10T13:03:20.981+0800: 61536.641: [scrub string table, 0.0014630 secs] [1 CMS-remark: 1677831K(2097152K)] 1688888K(3040896K), 0.1002410 secs] [Times: user=0.25 sys=0.01, real=0.10 secs]2019-05-10T13:03:21.010+0800: 61536.669: Total time for which application threads were stopped: 0.1046380 seconds2019-05-10T13:03:21.010+0800: 61536.669: [CMS-concurrent-sweep-start]2019-05-10T13:03:21.013+0800: 61536.673: Total time for which application threads were stopped: 0.0034750 seconds2019-05-10T13:03:21.016+0800: 61536.675: Total time for which application threads were stopped: 0.0027740 seconds2019-05-10T13:03:21.019+0800: 61536.678: Total time for which application threads were stopped: 0.0025430 seconds2019-05-10T13:03:21.021+0800: 61536.680: Total time for which application threads were stopped: 0.0022570 seconds2019-05-10T13:03:21.023+0800: 61536.683: Total time for which application threads were stopped: 0.0019970 seconds2019-05-10T13:03:21.025+0800: 61536.684: Total time for which application threads were stopped: 0.0019480 seconds2019-05-10T13:03:21.027+0800: 61536.687: Total time for which application threads were stopped: 0.0021600 seconds2019-05-10T13:03:21.029+0800: 61536.689: Total time for which application threads were stopped: 0.0021560 seconds2019-05-10T13:03:21.031+0800: 61536.691: Total time for which application threads were stopped: 0.0020060 seconds2019-05-10T13:03:21.033+0800: 61536.693: Total time for which application threads were stopped: 0.0021040 seconds2019-05-10T13:03:21.040+0800: 61536.700: Total time for which application threads were stopped: 0.0041470 seconds2019-05-10T13:03:22.343+0800: 61538.003: [CMS-concurrent-sweep: 1.309/1.333 secs] [Times: user=2.36 sys=0.23, real=1.33 secs]2019-05-10T13:03:22.343+0800: 61538.003: [CMS-concurrent-reset-start]2019-05-10T13:03:22.353+0800: 61538.013: [CMS-concurrent-reset: 0.010/0.010 secs] [Times: user=0.02 sys=0.01, real=0.01 secs]&ensp; &ensp;&ensp; &ensp;查看安全点日志,并没有发现异常12 61533.938: GenCollectForAllocation [ 1780 0 0 ] [ 0 0 0 3 11 ] 0&ensp; &ensp;&ensp; &ensp;所以既没有vmop，也没有应用线程号召安全点阻塞的情况，user为0，real却为1.47，同时sys为1.49一般来说real时间远大于user时间有可能由两方面导致，一是比较重的 I/O 行为包括网络连接及磁盘操作,另一个是CPU资源紧缺.通过zbx观察机器对应时间的io、tcp连接及cpu情况，都比较正常，参考文章（点击查看）。基于sys &gt; user的情况的分析文章(点击查看)&ensp; &ensp;&ensp; &ensp;查看hotspot源码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869void VM_CMS_Initial_Mark::doit() &#123; if (lost_race()) &#123; // Nothing to do. return; &#125; HS_DTRACE_PROBE(hs_private, cms__initmark__begin); GenCollectedHeap* gch = GenCollectedHeap::heap(); GCCauseSetter gccs(gch, GCCause::_cms_initial_mark); VM_CMS_Operation::verify_before_gc(); IsGCActiveMark x; // stop-world GC active _collector-&gt;do_CMS_operation(CMSCollector::CMS_op_checkpointRootsInitial); VM_CMS_Operation::verify_after_gc(); HS_DTRACE_PROBE(hs_private, cms__initmark__end);&#125;void VM_CMS_Operation::verify_before_gc() &#123; if (VerifyBeforeGC &amp;&amp; GenCollectedHeap::heap()-&gt;total_collections() &gt;= VerifyGCStartAt) &#123; HandleMark hm; FreelistLocker x(_collector); MutexLockerEx y(_collector-&gt;bitMapLock(), Mutex::_no_safepoint_check_flag); Universe::heap()-&gt;prepare_for_verify(); Universe::verify(true); &#125;&#125;void CMSCollector::do_CMS_operation(CMS_op_type op) &#123; gclog_or_tty-&gt;date_stamp(PrintGC &amp;&amp; PrintGCDateStamps); TraceCPUTime tcpu(PrintGCDetails, true, gclog_or_tty); TraceTime t(&quot;GC&quot;, PrintGC, !PrintGCDetails, gclog_or_tty); TraceCollectorStats tcs(counters()); switch (op) &#123; case CMS_op_checkpointRootsInitial: &#123; SvcGCMarker sgcm(SvcGCMarker::OTHER); checkpointRootsInitial(true); // asynch if (PrintGC) &#123; _cmsGen-&gt;printOccupancy(&quot;initial-mark&quot;); &#125; break; &#125; case CMS_op_checkpointRootsFinal: &#123; SvcGCMarker sgcm(SvcGCMarker::OTHER); checkpointRootsFinal(true, // asynch false, // !clear_all_soft_refs false); // !init_mark_was_synchronous if (PrintGC) &#123; _cmsGen-&gt;printOccupancy(&quot;remark&quot;); &#125; break; &#125; default: fatal(&quot;No such CMS_op&quot;); &#125;&#125;void VM_CMS_Operation::verify_after_gc() &#123; if (VerifyAfterGC &amp;&amp; GenCollectedHeap::heap()-&gt;total_collections() &gt;= VerifyGCStartAt) &#123; HandleMark hm; FreelistLocker x(_collector); MutexLockerEx y(_collector-&gt;bitMapLock(), Mutex::_no_safepoint_check_flag); Universe::verify(true); &#125;&#125; &ensp; &ensp;&ensp; &ensp; 进入到vmop操作即do_CMS_operation(CMSCollector::CMS_op_checkpointRootsInitial),怀疑是操作前有cpu资源等待的情况，由于机器为32个虚拟核，而机器上的java实例达到了16个，cpu并非独享，查看jvm参数，没有开启并行initial mark，添加参数CMSParallelInitialMarkEnabled进行观察，同时添加-XX:CMSWaitDuration=5010 &ensp; &ensp;&ensp; &ensp; 同时发现parnew也有类似的情况12 2019-05-03T11:19:26.016+0800: 320262.210: [GC2019-05-03T11:19:26.017+0800: 320262.211: [ParNew: 847306K-&gt;8507K(943744K), 0.7853400 secs] 2462473K-&gt;1623871K(3040896K), 0.7866170 secs] [Times: user=0.18 sys=0.80, real=0.78 secs]&ensp; &ensp;&ensp; &ensp; 调取安全点日志1320262.188: GenCollectForAllocation [ 1782 0 0 ] [ 0 0 0 8 787 ] 0&ensp; &ensp;&ensp; &ensp; 可以看到没有线程wait to block,spin,block及sync的时间都正常，时间都集中在vmop中，也就是说安全点的操作并没有产生额外的耗时，结合gc的日志，可以看得出来gc线程本身的操作是正常的，那问题集中在gc日志的real时间及safepoint日志的vmop时间。虑到一样是cpu非独占的情况，查看jvm参数，发现ParallelGCThreads设置为20，上面提到机器是32虚拟核，16个java实例，估怀疑还是cpu资源抢占的问题，将ParallelGCThreads设置为8,进行观察&ensp; &ensp;&ensp; &ensp; 分析到这里其实可以知道已经非程序内部可以调整的问题，一开始以为与io阻塞相关，想先从hsperfdata进行实验,但发现已经添加了参数PerfDisableSharedMem,如果定位cpu抢占资源的情况是错的，那只能通过strace跟进进程系统调用 配置前配置后可以看到initial mark和remark都比之前的要少，而且initial mark的时间转为正常，没有再出现上述情况，但是发现young gc的总耗时变长,之前是一天5分钟左右，现在是11分钟，如下配置前配置后 查看堆内存情况配置前配置后 &ensp; &ensp;&ensp; &ensp;这样看就很明显了，查看jvm参数没有配置新生代内存占用大小或比例，添加xmn参数指定1g，解决young gc次数增加的情况。 &ensp; &ensp;&ensp; &ensp;另外parnew的长耗时问题，也得到改善，之前每天都有超过1s的情况，在新配置上线后降低了长耗时的出现频率。至少可判断猜想是正确的。]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>java基础</tag>
        <tag>JVM</tag>
        <tag>内存</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[创业团队那些事]]></title>
    <url>%2F2019%2F02%2F09%2F%E5%88%9B%E4%B8%9A%E5%9B%A2%E9%98%9F%E9%82%A3%E4%BA%9B%E4%BA%8B%2F</url>
    <content type="text"><![CDATA[&ensp; &ensp;&ensp; &ensp;近来由于忙着换工作和春节生活杂事安排很久没更新博客，原本想着年前写一篇docker或者spring cloud gateway的相关文章也是被搁下了。昨天送走了春节最后一波来访的亲戚，今天终于有时间可以写写东西。&ensp; &ensp;&ensp; &ensp;自从有换工作的念头后，其实就很想写一下自我总结，总结算上实习7年来在工作上的感想。其实每年以及每隔一段时间我都会在个人笔记上自我复盘，但这次想分享出来，权当是给看客茶余饭后打发时间杂文也行。&ensp; &ensp;&ensp; &ensp;前段日子在网上看到一句话&ensp; &ensp;&ensp; &ensp;当你觉得痛苦时，你只有两个选择，一个是被打倒，一个是被逼着成长&ensp; &ensp;&ensp; &ensp;类似的话语其实大家都听得不少，这句话我再次听到的时候很有感触，回想起自己从业以来每次遇到的痛苦时刻，有放弃，有坚持。 &ensp; &ensp;&ensp; &ensp;2015年8月，我从唯品会离职出来加入这家公司，当时工作3年有多，一腔热血，老板b君和当时已经加入他们且和我比较要好的同事y君过来聊了会，我毅然决定加入团队，即便是降薪过去。后来回想自己当时真的是年轻不懂事。转眼3年半过去了，公司从一开始做Pass到后来tob电商入驻平台再到后来做tob电商自营平台，期间经历过挺多苦难，但是就我个人感觉而言，当一切上了轨道，遇到的困难其实并没有一开始遇到的要难。&ensp; &ensp;&ensp; &ensp;一开始老板b君经常会拉着我们几个技术负责人做培训，包括他对行业的认知，产品的规划，个人的价值观和创业的大饼想象等。后来公司越来越大，b君也不怎么拉着人培训了，直到开始做自营，经常看到b君拉着物流、市场、采购的人做狼性培训。&ensp; &ensp;&ensp; &ensp;b君有些话让我感受比较深。 &ensp; &ensp;&ensp; &ensp;“我们过往都在选择容易的路在走，而往往只有痛苦的路才是正确的，我们不能绕过去”这句话本身我并没有太大的感觉，但是结合b君自身的经历和公司一些有能力的人，我不禁反思，为什么要选择难的路走，b君期望得到的和大家期望得到的，通过这条路真的可以得到快速实现吗？也许放在tob电商这个事是正确的，但是再往大的方向上看，为什么要选择tob电商，虽然近些年都说tob电商很大机率是风口，但是很明显市场并没有大家想象中那么热烈，对比一些红火行业来看。所以这句话也许适用b君及公司，因为b君觉得他没有退路了，但是却不定适用他手下的人，很难引起共鸣。最终b君很多事情的推动都被手下的人应付着。 &ensp; &ensp;&ensp; &ensp;“我都这么痛苦了，为什么你们不能再往前一步”后期b君对初始的核心团队成员是这样的想法，并传达给了大部分人。技术副总监办事不力，他跟技术副总监说了这话，技术的一些高层人员不愿放弃技术转纯管理岗，他对他们也说了这句话，等等。不得不承认，b君为了公司能活下去活得好，他牺牲了很多东西，全公司压力最大那个确实是他。公司越来越大，老板自然也不可能照顾到每个初创团队的成员，自然是公司需要什么，做得到就做，做不到别人顶上，大多数情况下是小公司找不到合适价位的人才。 &ensp; &ensp;&ensp; &ensp;“只要xxx还在，他手下整个团队换掉都没关系”，“到现在这阶段，没有说缺了谁不行”b君对团队的管理还是比较侧重抓头不抓尾，其实没什么毛病，只是没做好人才储备的情况下就比较麻烦，而且不是非常优秀的小公司很难做人才储备，尤其当公司的人力资源能力水平还处于不完善阶段，更加是难上加难。 &ensp; &ensp;&ensp; &ensp;目前这家公司发展还可以，我写b君的东西其实也思量了挺久，写不好就变成抱怨吐槽，其实没有哪家创业公司的老板是没能力的，但也没有人是十全十美的，没有问题的公司都已经挂掉了。写b君的东西是想表达在选择创业团队的时候，老板是重要考虑因素之一，不过可能很多人在求职过程中并接触不到，可以了解好公司的氛围和企业文化再做决定。 &ensp; &ensp;&ensp; &ensp;知乎上有一小篇文章叫《别做被小公司毁掉的年轻人》，文章最后说“小公司毁不掉你，毁掉自己只是那不思进取的自己”，说的也没错，但是这里想说的其实是，能有更好的选择，就别让自己吃那么多无谓的苦，让自己能在快乐中做贡献，对公司对个人都是好事。 &ensp; &ensp;&ensp; &ensp;个人的建议是除非看得特别透彻，综合考虑好个人自身的性格，做好了准备，才可以选择创业团队，要不然还是选择能让自己术业有专攻的平台会来得更好，做好沉淀，为将来更好的机会做好准备。创业公司的大饼是一种期望，有风险，像理财一样，个人也需要给自己划定风险承受能力范围。有更好的选择还是选择更好的，大多数人往往还是看不够透彻，做不够准备的。 &ensp; &ensp;&ensp; &ensp;创业团队有很多乱七八糟的坑，只有你想不到，没有尽头。运气特别好的上市，稍次的被收购，大多还是处于不上不下的尴尬层次，还有更多的是直接挂掉。但是我感谢在创业团队的经历，让我更加成熟。]]></content>
      <categories>
        <category>随笔</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[datax源码解析及分布式实现思路]]></title>
    <url>%2F2018%2F11%2F23%2Fdatax%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E5%8F%8A%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9E%E7%8E%B0%E6%80%9D%E8%B7%AF%2F</url>
    <content type="text"><![CDATA[&ensp; &ensp;&ensp; &ensp;相信很多人接触datax都会去了解它的分布式执行模式，很“幸运”，阿里开源出来的是阉割版，默认只支持单机模式，研发团队对外基本也不回应分布式相关的问题。故此，想让datax支持分布式功能，只能自己下些功夫。&ensp; &ensp;&ensp; &ensp;在github上也有人做了分布式的支持项目，如 TianLangStudio/DataXServer 后面再聊下这个项目的情况。&ensp; &ensp;&ensp; &ensp;开始之前，按官方文档的建议，了解一下以下概念: Job: Job是DataX用以描述从一个源头到一个目的端的同步作业，是DataX数据同步的最小业务单元。比如：从一张mysql的表同步到odps的一个表的特定分区。 Task: Task是为最大化而把Job拆分得到的最小执行单元。比如：读一张有1024个分表的mysql分库分表的Job，拆分成1024个读Task，用若干个并发执行。 TaskGroup: 描述的是一组Task集合。在同一个TaskGroupContainer执行下的Task集合称之为TaskGroup JobContainer: Job执行器，负责Job全局拆分、调度、前置语句和后置语句等工作的工作单元。类似Yarn中的JobTracker TaskGroupContainer: TaskGroup执行器，负责执行一组Task的工作单元，类似Yarn中的TaskTracker。 了解源码&ensp; &ensp;&ensp; &ensp;我们先看下datax的源码，从datax.py入手，datax.py 收集运行机器的相关信息组装参数调用com.alibaba.datax.core.Engine类，从类入口开始看主要流程分几个部分。 容器启动前操作 JOB容器启动操作 TaskGroup容器启动操作 Job跟Task的处理流程 插件相关类关系 &ensp; &ensp;&ensp; &ensp;主要流程差不多就这样了，需要注意的是，在单个容器里，研发团队的设计理念是希望建立reader和write的1：1的管道模型来处理数据。 分布式支持实现思路正派做法&ensp; &ensp;&ensp; &ensp;按以上的解析内容，最“正经”的方案应该是让datax 将task切分好分发给不同的TaskGroup容器执行，直接执行job文件一般都是使用的job容器，如果不指定的话。按源码调试的结果，task其实是job文件中content里的每个实例。一开始提到TianLangStudio/DataXServer其实就是基于hadoop yarn api和client包进行这个思路的实现，可惜很久没维护，文档也没写好，而且远程调用只有Thrift。&ensp; &ensp;&ensp; &ensp;基于“正经”方案的思路和我们的使用的习惯（目前我们是单个task一个job文件），其实可以使用一些支持服务发现及负载平衡的框架，如spring cloud，将job内容及相关参数提交给网关接口，使用自定义流量分发规则（考虑不同节点硬件资源），分发到对应节点上的服务上，服务再调起datax engin。假如需要切分task，则只需要在分发前建一层task切分的服务即可，节点上的服务根据接收到的任务类型来组装参数调用不同的datax容器。&ensp; &ensp;&ensp; &ensp;挫一点的做法就是使用azkaban，手工配置指定机器运行data job 邪门歪道&ensp; &ensp;&ensp; &ensp; 单个task不能再切分我认为是不合理的，首先reader和writer支持分布式的选择不多，其次，会有单点流量问题。所以其实我想要的是能不能将datax单一数据管道的模型给改造成支持分布式，让单个task也支持分布式。&ensp; &ensp;&ensp; &ensp; 了解了源码之后，我觉得可以是可以有如下切入点： 从job接收的时候就切分好数据块,master负责接收job/task，切分成任务块，每场任务块由一对reader和writer完成处理，就是基本datax task更小粒度或者说基于数据粒度上的切分 reader支持分布式，比如presto reader不切，在传输给writer的queue时切，多个writer接收。其实就是将queue做成支持分布式，比如使用kafka writer本身支持分布式，比如presto &ensp; &ensp;&ensp; &ensp; 如果纯粹地做数仓，我觉得reader和writer使用presto或其它支持分布式读写操作的技术等，然后再结合task负载均衡分配，基本可以满足了。如果需要做数据更新情况会比较复杂，需要考虑writer是否支持分布式更新及目标数据源是否支持并发插入而不容易产生锁。&ensp; &ensp;&ensp; &ensp; 目前我们的架构是基于项目的情况，选择最低成本能够实现的最优方案，就是使用spring cloud + datax，保持datax核心的完整性不修改，在上面加一层，reader和writer尽量地使用presto为主，es为辅。下个阶段才会考虑使用yarn和queue的改造。]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>数据平台</tag>
        <tag>ETL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[并发编程]]></title>
    <url>%2F2018%2F10%2F18%2F%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[&ensp; &ensp;&ensp; &ensp;并发编程是java的基础知识，但是也论深度，工作这些年与很多开发打过交道，有些人工作几年了也没有系统的认识，如果是做业务为主的开发，如果自己没有意识主动学习，往往就是基本使用、用封装好的工具或框架而不加思索。 就着以前学习过的《JAVA并发编程》的知识整理了并发编程的基本知识点]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>JVM</tag>
        <tag>JAVA基础</tag>
        <tag>并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JAVA动态编译/解析文本的一种简易方法]]></title>
    <url>%2F2018%2F10%2F07%2FJAVA%E5%8A%A8%E6%80%81%E7%BC%96%E8%AF%91-%E8%A7%A3%E6%9E%90%E6%96%87%E6%9C%AC%E7%9A%84%E7%AE%80%E6%98%93%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[&ensp; &ensp; 追着国庆假期的尾巴，更新一下博客，讲一下项目上之前遇到的文本动态编译/解析的问题，虽然比较简单，但是感觉适合场景还是挺多的。&ensp; &ensp; 团队自研BI系统，在数据源选择及查询的实现使用桥接模式，针对不同的数据源采用不同的查询方式，而目前我们平台支持的数据源的查询可以通过构建不同的文本请求体进行查询，例如mysql、presto、ElasticSearch等。在这里对文本动态构建的实现方案进行讲述。&ensp; &ensp; 我们的源文本都是基于xml标签编写，起因是BI系统一开始是基于mybatis对mysql数据库进行DAO操作。举个栗子：12345678910&lt;select id=&quot;test&quot; parameterType=&quot;map&quot; resultType=&quot;java.util.HashMap&quot;&gt;select id from table_test where 1=1 &lt;if test=&quot;startTime != null and startTime != &apos;&apos;&quot;&gt; and sale_date &gt;= #&#123;startTime&#125; &lt;/if&gt; &lt;if test=&quot;endTime != null and endTime != &apos;&apos;&quot;&gt; and #&#123;endTime&#125; &gt;= sale_date &lt;/if&gt;&lt;/select&gt; &ensp; &ensp; 在这个基础上我们了解了mybatis的解析过程，使用mybatis的底层实现进行动态sql语句文本编译,其实原理就是利用mybatis的xml标签解析sql实现。&ensp; &ensp; xml动态文本编译/解析有多种方法，但是基于以上的情况，我们抽取了mybatis的boundsql编译过程用来构建我们的文本请求体12345678910111213 //使用mybatis编译逻辑标签 Document doc = DOMUtils.parseXMLDocument(query); XPathParser xPathParser = new XPathParser(doc, false); Node node = doc.getFirstChild(); XNode xNode = new XNode(xPathParser, node, null); XMLScriptBuilder xmlScriptBuilder = new XMLScriptBuilder(configuration, xNode); SqlSource sqlSource = xmlScriptBuilder.parseScriptNode(); BoundSql boundSql = sqlSource.getBoundSql(param);&ensp; &ensp; 通过boundSql.getSql()可以获取编译后的文本（configuration是mybatis的基础配置类，由于这里并不用到数据库请求，所以创建一个新的单例对象传入就可以），但是需要注意的是mybatis这种编译方式是用来编译prepare statment的，什么意思呢，就是使用mybatis的标签变量声明规则，即变量是#{var}这种声明方式，会被编译成问号占位符，如果不想这样可以自己制定变量规则进行替换，比如${var}123 boundSql.getSql().indexOf(&quot;$&quot;) &gt; 0 ? replaceVariables(boundSql.getSql(),param) : boundSql.getSql(); &ensp; &ensp; 到此我们的presto动态语句可以写成1234567891011 &lt;select id=&quot;test&quot; parameterType=&quot;map&quot; resultType=&quot;java.util.HashMap&quot;&gt;select bill_id,total from platform_data.t_sales_bill where 1=1 &lt;if test=&quot;startTime != null and startTime != &apos;&apos;&quot;&gt; and sale_date &gt;= cast(#&#123;startTime&#125; as timestamp) &lt;/if&gt; &lt;if test=&quot;endTime != null and endTime != &apos;&apos;&quot;&gt; and cast(#&#123;endTime&#125; as timestamp) &gt;= sale_date &lt;/if&gt;&lt;/select&gt; &ensp; &ensp; es的请求体可以写成1234567891011121314151617181920212223242526272829 &lt;query&gt;&#123; &quot;query&quot; : &#123; &quot;bool&quot;:&#123; &quot;filter&quot;:[ &lt;if test=&quot;agentCodes!=null&quot;&gt; &#123;&quot;match&quot; : &#123; &quot;agentCode&quot; : &quot;$&#123;agentCodes&#125;&quot;&#125; &#125;, &lt;/if&gt; &#123;&quot;range&quot; : &#123; &quot;saleDate&quot; : &#123;&quot;gte&quot;:&quot;$&#123;startTime&#125;&quot;,&quot;lte&quot;:&quot;$&#123;endTime&#125;&quot;&#125; &#125; &#125; ] &#125; &#125;, &quot;aggs&quot;:&#123; &quot;sales_number&quot;:&#123; &quot;terms&quot; : &#123; &quot;field&quot; : &quot;goodsId&quot;, &quot;order&quot;:&#123; &quot;salesNumber&quot;:&quot;desc&quot; &#125; &#125;, &quot;aggs&quot;:&#123; &quot;salesNumber&quot;:&#123;&quot;sum&quot;:&#123; &quot;field&quot;:&quot;salesNumber&quot; &#125; &#125;, &quot;salesTotal&quot;:&#123;&quot;sum&quot;:&#123; &quot;field&quot;:&quot;salesTotal&quot; &#125; &#125; &#125; &#125; &#125;, &quot;sort&quot;: &#123; &quot;salesNumber&quot;: &#123; &quot;order&quot;: &quot;desc&quot; &#125;&#125; &#125;&lt;/query&gt;&ensp; &ensp; 同理其它可以使用文本构建查询的数据源都可以支持，比如Hql,spark-sql,ksql等，再扩展也可以支持动态脚本。为我们自助查询平台和BI平台奠定了基础。&ensp; &ensp; 以上，说得比较简单，希望对看到的人可以有帮助。]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>java基础</tag>
        <tag>mybatis</tag>
        <tag>动态解析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[个人基于大数据平台的设计与思考]]></title>
    <url>%2F2018%2F08%2F19%2F%E4%B8%AA%E4%BA%BA%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E7%9A%84%E8%AE%BE%E8%AE%A1%E4%B8%8E%E6%80%9D%E8%80%83%2F</url>
    <content type="text"><![CDATA[背景介绍&ensp; &ensp; 本人是在一家TOB电商平台的创业公司就职，目前负责整个数据部门的架构与业务跟进。之前从事过YY与唯品会的web开发工作，也有了解到一些大数据架构相关的设计。&ensp; &ensp; 目前数据部门的技术架构发展大体方向已经确定得差不多，于是在此梳理一下设计思路、历程与将要实现的内容。 一开始都是坑&ensp; &ensp; 一开始的数据需求都是来源于生意运营的报表，我由负责电商app web转向数据开发，说实话，一开始做报表我心里是拒绝的，但是创业团队为了公司能活下去，什么活不得做。领着几个兄弟搭建了公司的”数据中心”，其实就是个报表系统。当时对hadoop,hive,spark,etl等技术及概念懵懵懂懂。 &ensp; &ensp; 很快我们发现，第一轮的坑来了，面临两个问题：一，报表需求多，小伙伴们整天在写sql，代码组合数据；二，数据量慢慢大起来，有些地方性能比较差，报表要查很久，有时候影响线上性能，线上出问题总要挨白眼。 &ensp; &ensp; 经过了解对比，我们毅然决定开始自研BI系统(参照superset功能设计)和开启我们的ETL架构设计与实现的开头，独立一套数据环境。其实当时我们心中还有点窃喜，终于可以接触高大上的hadoop全家桶了，选取的技术有hadoop、hive、spark、sqoop和shell脚本来实现我们的第一版数据流程。嗯，这才有点数据中心的样子。 &ensp; &ensp; 然而，跑了一段时间后，随着了解越多知识，才知道我们的情况有多糟糕，当时数据量不到100g，只有两台8核16G的机器（手动捂脸），离线任务依靠时间弱依赖，就算只有两台，运维起来也要花不少时间，sqoop在小数据量小集群的应用场景下性能真的很一般啊，渐渐感觉到这套架构对我们来说也许”太早了”。自研BI方面，很考验写sql的功力，虽然由此我们对mysql的sql编写技巧有很大提升，用了很多奇淫巧技，但是，我们的研发现在都花很多时间写sql啊，而且大家对数据不敏感，反正就是完成开发任务就得了。这段时间确实人心很不稳。。。当然很感谢那时坚持陪着我奋斗的小伙伴们。 初版架构如下: 有坑就要填思考、计划、实现与招聘，我们在1个月内重塑了整个交互流程。 数据通过爬虫、收集日志与第三方公司进行业务结合等方式慢慢积累起来 招来第一位数据分析师，并由他负责BI的输出与日常报表需求 申请多了几台机器资源 用azkaban替换shell脚本管理，正式接上任务流 使用datax替换sqoop hadoop、hive及spark主要用来做少量智能化的业务，大部分数据聚合逻辑回迁数据库 这样的数据流程立马解放了开发小伙伴的双手，去做更能体现价值的事情，而且报表输出的质量也大大提高了，机器资源也暂时足够，维护起来还不算特别麻烦。心里舒了一口气。 架构如下: 业务不断发展，坑坑更健康&ensp; &ensp; 这个时候我们的业务数据量已经超过100-200G之间，数据中心的数据量也300g左右，数据库中的中间表特别多。&ensp; &ensp; 现在已经好几位分析师，各自负责自己的需求，经常有数据打架的情况发生，而且制作报表很多依然用的业务源表，有性能问题就使用中间表。&ensp; &ensp; 业务应用越来越多对数据聚合服务有需求，我们都是通过RPC接口来对外服务提供服务,我们经常得深入业务逻辑去提供聚合服务，而且服务对象多，所有服务在数据库聚合，经常影响数据中心整体的服务质量，也出现过多次应用雪崩的情况。&ensp; &ensp; 业务也出现了实时反馈的产品需求 不断学习探研改造我们又再一次进行架构改造 接入otter实现业务数据实时同步 使用canal + kafka + kafka streams 实现实时数据变更订阅，提供实时聚合服务 开始设计自己的数据字典与数据仓库 采用微服务设计理念，使用spring cloud 架构如下: 就着这样节奏又走了一段日子 总是会有不如意的地方&ensp; &ensp; 此时我们的机器资源也只有近10台一般配置的节点，随着微服务越来越多，而且与其它大数据的工具平台共用，很快又到瓶颈，而且进程多维护起来也是麻烦。&ensp; &ensp; 数据团队的人员由于资源限制没有再新增，而业务缺越来越多需要支持，在生产力方面，数据处理环节明显成为瓶颈。&ensp; &ensp; 此时在数据聚合方面，我们采用了redis作为缓存，但是依然存在缓存击破的情况，导致数据库偶尔会锁表，即使我们已经主从读写分离。 像刀一样，越磨越亮我们在新的阶段探研了新的技术 使用ambari管理各种集群 探索数据流任务管理平台，对比了kettle，apache nifi和spring cloud data flow 研究能够快速检索数据且能够横向扩展的技术，如elasticsearch,kafka等 过往我们都是存储及计算一体，像我们对mysql,hive的应用就是典型的先把数据迁移到哪里再进行计算，所以我们也探研了计算分离的技术方案，最终采用presto 对于快速发展的创业公司来说好用才是王道，大家舒服才是王道&ensp; &ensp;我们的数据量始终没有达到TB级别，可预见如果业务没有新的发展方向，就当前的产品的数据增长速度来看，可以把我们要做的数据平台定义为“小数据量的大数据平台”，机器资源也只是近10台（我知道市场正常搞大数据的机器集群一般都有几十上百台，再次手动捂脸）。最终确定我们架构的方向: 使用otter实时同步我们所有业务数据到我们自己的数据库，减少离线同步的管理和资源成本 使用canal 监听自己数据库的所有表变化，程序同步序列化数据到kafka中，由业务方使用kafka streams自行订阅，实现业务逻辑 使用azkaban + datax + presto ，实现分布式计算，分离存储与计算环节，完成etl流程 最终离线数据落地elasticsearch 业务方通过数据平台进行数据需求的自满足及溯源 我们当前的架构如下(蓝色箭头为源头输出，红色箭头指向为输入，黄色箭头为溯源流向，黄色闪电为依存关系): 而最终稳定版的架构如下: 智能化的业务&ensp; &ensp;近来公司重点发展智能化业务，需要我们支持机器学习相关的算法模型实现及调优，目前还是处于使用python脚本的实现方式及azkaban进行任务训练及提供脚本给程序调用。一方面还不是分布式计算，当然我们也可以用spark解决这个问题，第二方面，支持不了实时训练的场景，虽然我们当前也还没有这种需求。目前这块还是架构规划当中，可能会比较倾向于使用tensorflow,后续有进展再更新。 感想&ensp; &ensp; 我始终没觉得自己是一个大数据开发人员，在我看来，web开发与数据开发同样是后端研发，只不过业务不同，使用的技术不同，然而很多研发的基础是一样。语言基础，高并发，大数据量，大吞吐量，分布式，高可用，模式设计，基础算法，调优，使用的工具掌握及理解像redis,zk,es,kafka,mysql这些，运维基础，前端基础，像这些我觉得都是应该掌握的。&ensp; &ensp; 面试过很多大数据的开发，从初级到高级。很多人都只关心一个问题，你们的数据量有多大，你们的集群有多大。我承认这些这两个“指标”确实能说明一些东西，但是对于我面试过的人来说，我的结论是，数据量的大小对于只是一个使用工具的人来说，其实并不重要，因为你也只是用，你从来不深究，为什么要这样设计，为什么要这样实现，有没有办法做得更好，你不了解原理，你不熟悉工具技术，反而看不起数据量小的业务场景，这会让人觉得不成熟。&ensp; &ensp; 当然我也是认为如果有机会接触真正的大量数据的场景，还是得尽量接触，在保证自己有不断提升的觉悟为前提去接触。面试过很多游戏通信行业的真正大数据量场景下的小伙伴，真的不得不提一句，你公司的业务场景只是一方面，不“用”起来，只是负责某个环节的加工还不深究，这样的开发真的不算是大数据研发啊。&ensp; &ensp; peace &amp; love]]></content>
      <categories>
        <category>设计</category>
      </categories>
      <tags>
        <tag>架构</tag>
        <tag>数据平台</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[天然苏打水市场的了解与分析]]></title>
    <url>%2F2018%2F08%2F14%2F%E5%A4%A9%E7%84%B6%E8%8B%8F%E6%89%93%E6%B0%B4%E5%B8%82%E5%9C%BA%E7%9A%84%E4%BA%86%E8%A7%A3%E4%B8%8E%E6%80%9D%E8%80%83%2F</url>
    <content type="text"><![CDATA[背景近来有个朋友找到我说拿到某品牌的天然苏打水广东省省级代理，问我得怎样开展工作及市场上的情况是怎么样的。12产品定价15元一支品牌方给出了一年一千万件，即八千万支的销量目标。 table td {text-align:center} table thead td {background:#73B1E0;color:#FFF;} table th {border:1}由于个人是在TO B电商平台工作（苦逼码农一个），就着自己的资源和能力稍微进行一下分析。目标是找出工作推进的方案和尽量找出市场数据以及判断这个销量kpi是否合理。 梳理步骤 了解市场竞品数据 了解一般水饮新品推广方法 了解行业高端专业人士对这个事件的看法 了解市场竞品数据找遍关系圈并没有任何可以了解到天然苏打水相关的线下渠道，于是只能针对线上电商平台先下手。挑选了天然苏打水销量量较大的平台的销量较好的四个产品进行对比。结果如下: 产品 产品单价 规格 活动 京东销量 天猫销量 品牌 产品卖点 产地 公司 公司旗下产品 公司官网 新闻备注 品牌故事 舒达源克东天然苏打水 9.5 550ml 买2送1（送6支400ml） 1.9w评价 2758 舒达源 世界三大冷矿泉之一 克东 黑龙江舒达饮品有限公司 单一产品不同规格 跳转 新闻1 中国国家田径队官方用水 活力恩克东天然苏打水 3.66 500ml 无 3.3w评价 4542(单价4.5) 活力恩 火山岩層精淬礦泉 克东 海昌國際股份有限公司（彰化縣秀水鄉） 主打5度C系列，销量情况一般 跳转 无 无 火山鸣泉克东天然苏打水 7.3 470ml 无 1.7w评价 3578 火山鸣泉 火山岩層精淬礦泉 克东 火山鸣泉生态科技有限公司 单一产品不同规格不同包装 跳转 新闻1 新闻2 中国田径队官方饮用水 水易方克东天然苏打水 7.1 500ml 买5送1 1.5w评价 537 水易方 常见天然苏打水特性 克东 大连水易方科技发展有限公司 单一产品不同规格不同包装 跳转 新闻 无 就这样看可以得到一些信息12345* 京东是现在最大的销售渠道，天猫第二（其它平台几乎没有销量所以没对比）* 天然苏打水线上市场并不乐观,如果按这数据来看，一年100w件的销量目标都很有挑战性* 国内最有知名度的天然苏打水产地应该是克东，如果非克东产地的苏打水估计比较难引起消费者共鸣* 产品形象及品牌故事在市场竞争中影响并不大，消费者可能更看重实惠程度* 基本没看到哪个天然苏打水产品有打广告，更多应该是参加电商平台的促销活动 基本上线上销售相关信息了解就到这了，但是感觉还不够，进而找了各大数据平台搜索相关报告，收集到资料如下: 网上评价中国十大苏打水企业http://www.china-10.com/china/1002sds_index.html 中国会员经济数据报告http://tech.qq.com/a/20170719/007724.htm#p=1 尼尔森数据线上线下结合销售数据资讯http://www.nielsen.com/cn/zh/press-room/2015/Nielsen-global-survey-on-e-commerce-and-new-retailing.html 百度指数http://index.baidu.com/?tpl=trend&amp;word=%CB%D5%B4%F2%CB%AE 腾讯BIhttp://tbi.tencent.com/index?word=苏打水&amp;date=1&amp;type=0 36kr关于高端水的观点http://36kr.com/p/5073894.html 3mbang文库http://www.3mbang.com/p-171349.html 百度文库https://wenku.baidu.com/view/adb970a03968011ca200911f.htmlhttps://wenku.baidu.com/view/64a25f0869eae009581becfb.htmlhttp://www.chinairn.com/news/20160705/150700863.shtml ps:苏打水市场研究报告 很多咨询网站都有做，但是哪里都要钱的，一份就要好几k大洋，要不起，还是靠自己吧。 基于网上的资料可以看出来苏打水在中国的市场热度有上升的趋势，但是不大，天然苏打水就更小了。 一般水饮新品推广方法我找了我们公司运营部门副总监W君请教了一下，他原本是从宝洁出来的，至今工作多年，从开始的市场人员转为运营人员。从与他的交流上我总结了一下代理商一般水饮新品的推广方法如下: KA(大型卖场)如沃尔玛、华润万家、永旺（吉之岛）等。 KA是最容易进行新品试验的地方。每个KA都有自己招商的标准，对进场的产品会有不同的要求，KA每个点（如广州天河分店等）也各自有自己的要求。一般想谈合作可以直接到联系总部或者分点对应负责人直接谈就行了。 这里假设能够满足要求并进场。合作的对象有两种，一种是直接找总部谈合作，这种方式会要求产品本身有足够强的优势，总公司才会考虑帮你铺点，而且一般找总部谈的整个流程比较长，但是一旦确定产品OK，能够大面积铺开，另一种是找某个KA的分点负责人谈，这种的门槛会比较低，但是产品流通只限于该门店，如果想再扩大市场只能自己重新去谈其它KA分点。 合作的方式有两种，一种是直接给钱进场，KA不管你销量，反正它有钱收，另一种是根据销量来进行利润分成，这种一般只会针对成熟的产品或者非常有潜力的产品。 走KA的公司的运营比较简单，只需要有人负责促销活动的规划，聘请对应的促销人员派到各大卖场进行促销活动就可以了。 然而KA渠道基本就是走量，利润空间比较小。 城市有能力的中间商如广州宝祺来，专门做日化渠道，能够快速铺货到各大KA卖场，合作方式得自己谈，基本是直接给钱合作的。 这个渠道会比直接找KA利润更低，因为有中间商赚差价嘛。但是铺货速度跟能力绝对是杠杠的。 特殊渠道带有特殊性质的饮品，如能量饮料、苏打水，都有一些特殊的渠道可以卖，这个渠道比较看重经营方即卖饮品的公司渠道能力。比如红牛可以铺货进网吧、各大运动场所等。这个渠道我也没有资源可以继续了解，只是知道，特殊渠道是毛利可以爆发的渠道。 中小超市士多基本上品牌代理商不会自己直接去铺小店，成本高，效益低。 专业人士意见我找了我们公司采购部副总监请教，他是一路从恒大、沃尔玛等大公司由基层做到高层的。沟通下来我总结有以下几点： 新品不能急着铺货，只要你产品OK，销售渠道是比较容易疏通的 确定好主打市场，目标人群 做好市场调研，可以采用问券调查等方式。如果真的不清晰怎么做，可以拜访其它省级代理，咨询下人家的情况与做法 商品本身的主打特性要宣传到位，假如商品本身有什么特别性质的，如真的可以治疗什么疾病或者产源稀缺，那定价高一样可以卖得火爆 特殊渠道在定位高端产品的渠道中比较重要，往往是有利可图的渠道 15元的高端水在市场很少见，至少这位哥是没见过，当时在恒大做恒大冰泉也是定价高昂，现在一样卖到跟普通差不多，正常渠道销量也一般。所以这个定价的水产品市场不好做 总结针对销量目标来说，天然苏打水新品一年一千万件即八千箱的省级销售目标，从运营和专业人士的角度来看，都是很难达到，结合线上数据来看，也更加能说明这点。合理的有挑战性的目标大概是一百万件左右。假如有特殊渠道另说，因为特殊渠道的量就看主营公司的能力了，不好预估。推广新品的方法上面已经提到，但是推广前需要确定好目标人群、商品的亮点、品牌故事与背景和渠道。如果不清楚怎么做，可以去其它省级代理了解咨询，如果有的话。 吐槽基本上KA或者平台级的公司不会管你产品好不好卖，都想你投钱进场，反正不好卖也不关他们的事。包括我们公司那采购副总监，一边说着感觉市场不好做，一边想让我朋友来找我们公司合作，笑哭，哈哈]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring cloud stream 基于kafka的使用简析]]></title>
    <url>%2F2018%2F08%2F11%2Fspring-cloud-stream-%E5%9F%BA%E4%BA%8Ekafka%E7%9A%84%E4%BD%BF%E7%94%A8%E7%AE%80%E6%9E%90%2F</url>
    <content type="text"><![CDATA[流式数据故名思义，即数据像开了小河里的流水般不停流动，除非水源出现问题，否则没有结束时间。流式数据在行业内已经有非常多针对不同应用量级的成熟方案，这里就不加以详述。本次主要介绍spring cloud stream 基于kafka对流式数据的基本应用。而使用spring cloud stream之前，可以先理解一下spring cloud对数据流程的几个概念，分别是source（生产数据者），processor(数据加工者), sink(最终结果处理者)。 准备工作项目基本框架:当然是基于maven构建的spring-boot最省心省力啦添加依赖:1234567891011121314151617&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-stream-binder-kafka-streams&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-stream-binder-kafka&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- 用于代码中的一些便捷注解 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.18.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt; 公共配置:1234567891011121314151617181920spring: cloud: kafka: streams: binder: brokers: localhost:9092 zk-nodes: localhost:2181 #2.0以上就不需要该配置 configuration: default: key: serde: org.apache.kafka.common.serialization.Serdes$StringSerde value: serde: org.apache.kafka.common.serialization.Serdes$StringSerde cache: max: bytes: buffering: 0 #所有线程可以用于缓存的最大字节数,达到多少数据量之后聚合一次流中的数据，设置为0则实时聚合 commit: interval: ms: 1000 #版本数据确认消费时间ack 我们来模拟用户页面访问记录流 声明binding相关信息添加接口AnalyticsBinding1234567891011121314151617181920public interface AnalyticsBinding &#123; String PAGE_VIEWS_OUT = &quot;pvout&quot;; String PAGE_VIEWS_IN = &quot;pvin&quot;; String PAGE_COUNT_MV = &quot;pcmv&quot;; String PAGE_COUNT_OUT = &quot;pcout&quot;; String PAGE_COUNT_IN = &quot;pcin&quot;; @Input(PAGE_VIEWS_IN) KStream&lt;String,PageViewEvent&gt; pageViewsIn(); @Output(PAGE_COUNT_OUT) KStream&lt;String,Long&gt; pageCountOut(); @Input(PAGE_COUNT_IN) KTable&lt;String,Long&gt; pageCountIn(); @Output(PAGE_VIEWS_OUT) MessageChannel pageViewsOut();&#125; 添加配置在application.yml中声明以下配置12345678910111213141516171819202122232425262728293031323334353637spring: cloud: stream: bindings: pvout: destination: pvst group: pvst producer: header-mode: raw pvin: destination: pvst group: pvst consumer: header-mode: raw pcout: destination: pcst group: pcst producer: use-native-encoding: true pcin: destination: pcst group: pcst content-type: application/json consumer: use-native-encoding: true header-mode: raw kafka: streams: bindings: pcout: producer: key-serde: org.apache.kafka.common.serialization.Serdes$StringSerde value-serde: org.apache.kafka.common.serialization.Serdes$LongSerde pcin: consumer: key-serde: org.apache.kafka.common.serialization.Serdes$StringSerde value-serde: org.apache.kafka.common.serialization.Serdes$LongSerde destination对应kafka中的主题。serde就是serialization和deserialization，针对流中的key和value都需要指定，默认使用default中配置的内容，也可以针对主题单独设置。 source创建每秒随机产生用户访问页面及停留时间的数据 先创建事件类1234567@Data@AllArgsConstructor@NoArgsConstructorpublic class PageViewEvent &#123; private String userId,page; private long duration;&#125; 生成数据的实现123456789101112131415161718192021222324252627282930313233@Slf4j@Component@EnableBinding(AnalyticsBinding.class)public class PageViewEventSource implements ApplicationRunner &#123; private final MessageChannel pageViewsOut; public PageViewEventSource(AnalyticsBinding binding) &#123; this.pageViewsOut = binding.pageViewsOut(); &#125; @Override public void run(ApplicationArguments applicationArguments) throws Exception &#123; List&lt;String&gt; names = Arrays.asList(&quot;jlong&quot;,&quot;dyser&quot;,&quot;shacko&quot;,&quot;abilan&quot;,&quot;ooasdf&quot;,&quot;grussell&quot;); List&lt;String&gt; pages = Arrays.asList(&quot;blog&quot;,&quot;sitemap&quot;,&quot;initializr&quot;,&quot;news&quot;,&quot;colophon&quot;,&quot;about&quot;); Runnable runnable = () -&gt; &#123; String rPage = pages.get(new Random().nextInt(pages.size())); String rName = names.get(new Random().nextInt(names.size())); PageViewEvent pageViewEvent = new PageViewEvent(rName,rPage,Math.random() &gt; .5?10:1000); Message&lt;PageViewEvent&gt; message = MessageBuilder.withPayload(pageViewEvent) .setHeader(KafkaHeaders.MESSAGE_KEY,pageViewEvent.getUserId().getBytes()) .build(); try &#123; this.pageViewsOut.send(message); log.info(&quot;sent&quot; + message.toString()); &#125; catch (Exception e)&#123; log.error(e.getMessage()); &#125; &#125;; Executors.newScheduledThreadPool(1).scheduleAtFixedRate(runnable,1,1, TimeUnit.SECONDS); &#125;&#125; processor获取到事件数据之后基于聚合处理，创建新的数据流123456789101112131415@Slf4j@Componentpublic class PageViewEventProcessor &#123; @StreamListener @SendTo(AnalyticsBinding.PAGE_COUNT_OUT) public KStream&lt;String,Long&gt; process( @Input(AnalyticsBinding.PAGE_VIEWS_IN) KStream&lt;String,PageViewEvent&gt; events)&#123; return events .map((key,value) -&gt; new KeyValue&lt;&gt;(value.getUserId() + &quot;-&quot; + value.getPage(),&quot;0&quot;)) .groupByKey() //.windowedBy(TimeWindows.of(1000*60)) .count(Materialized.as(AnalyticsBinding.PAGE_COUNT_MV)) .toStream(); &#125;&#125; windowedBy可以根据时间窗口进行聚合，用法请详见文档。 sink获取聚合后的结果进行处理123456789@Slf4j@Componentpublic class PageCountSink &#123; @StreamListener public void process(@Input(AnalyticsBinding.PAGE_COUNT_IN)KTable&lt;String,Long&gt; counts)&#123; counts.toStream().foreach((key,value) -&gt; log.info(&quot;PCIN -----:&quot; + key + &quot;=&quot; + value)); &#125;&#125; 至此一个从数据生产到结果消费的简单数据流处理就完成了 解析这个例子是基于spring cloud 完整的流数据处理，有source,processor,sink的概念是spring cloud data flow的设计理念，这里不展开阐述。processor环节非必需的，可以只有source和sink的实现。假如不需要进行流的处理，只需要消息内容，可以在@StreamListener的方法声明中不使用@Input声明，而是直接通过@StreamListener(主题名称)来进行监听，方法接收消息参数使用Message msg，如下: 123456789@StreamListener(Processor.INPUT) public void receive1(Message&lt;String&gt; msg)&#123; System.out.println(msg.getPayload()); //消息体 Acknowledgment acknowledgment = msg.getHeaders().get(KafkaHeaders.ACKNOWLEDGMENT, Acknowledgment.class); if (acknowledgment != null) &#123; System.out.println(&quot;Acknowledgment provided&quot;); acknowledgment.acknowledge();//手动ack &#125; &#125; 多流聚合在实际应用中不只存在单流数据的处理，也经常会遇到多流聚合处理。我们来添加多一种事件的实现，这里模拟销售数据。相关的实现如下 SalesEvent1234567@Data@AllArgsConstructor@NoArgsConstructorpublic class SalesEvent &#123; private String userId,goods; private int amount;&#125; SalesEventSource12345678910111213141516171819202122232425262728293031@Slf4j@Component@EnableBinding(AnalyticsBinding.class)public class SalesEventSource implements ApplicationRunner &#123; private final MessageChannel salesOut; public SalesEventSource(AnalyticsBinding binding) &#123; this.salesOut = binding.salesOut(); &#125; @Override public void run(ApplicationArguments applicationArguments) throws Exception &#123; List&lt;String&gt; names = Arrays.asList(&quot;jlong&quot;,&quot;dyser&quot;,&quot;shacko&quot;,&quot;abilan&quot;,&quot;ooasdf&quot;,&quot;grussell&quot;); List&lt;String&gt; goods = Arrays.asList(&quot;apple&quot;,&quot;oringe&quot;,&quot;banana&quot;,&quot;lemon&quot;,&quot;shit&quot;,&quot;book&quot;); Runnable runnable = () -&gt; &#123; String rGoods = goods.get(new Random().nextInt(goods.size())); String rName = names.get(new Random().nextInt(names.size())); SalesEvent salesEvent = new SalesEvent(rName,rGoods,Math.random() &gt; .5?5:10); Message&lt;SalesEvent&gt; message = MessageBuilder.withPayload(salesEvent) .setHeader(KafkaHeaders.MESSAGE_KEY,salesEvent.getUserId().getBytes()) .build(); try &#123; this.salesOut.send(message); log.info(&quot;sent&quot; + message.toString()); &#125; catch (Exception e)&#123; log.error(e.getMessage()); &#125; &#125;; Executors.newScheduledThreadPool(1).scheduleAtFixedRate(runnable,1,1, TimeUnit.SECONDS); &#125;&#125; SalesEventProcessor123456789101112131415@Slf4j@Component@EnableBinding(AnalyticsBinding.class)public class SalesEventProcessor &#123; @StreamListener @SendTo(AnalyticsBinding.SALES_COUNT_OUT) public KStream&lt;String,Long&gt; process(@Input(AnalyticsBinding.SALES_IN)KStream&lt;String,SalesEvent&gt; events)&#123; return events .map((key,value) -&gt; new KeyValue&lt;&gt;(value.getUserId() + &quot;-&quot; + value.getGoods(),&quot;0&quot;)) .groupByKey() //.windowedBy(TimeWindows.of(1000*60)) .count(Materialized.as(AnalyticsBinding.SALES_COUNT_MV)) .toStream(); &#125;&#125; SaleCountSink123456789101112131415161718@Slf4j@Component@EnableBinding(AnalyticsBinding.class)public class SaleCountSink &#123; @StreamListener public void process(@Input(AnalyticsBinding.SALES_COUNT_IN)KTable&lt;String,Long&gt; salesCounts, @Input(AnalyticsBinding.PAGE_COUNT_IN)KTable&lt;String,Long&gt; pageCounts)&#123; salesCounts.toStream().map((k,v) -&gt; new KeyValue&lt;&gt;(k.split(&quot;-&quot;)[0],k.split(&quot;-&quot;)[1] + &quot;-&quot; + v)) .join(pageCounts.toStream().map((k,v) -&gt; &#123; System.out.println(&quot;-------&quot; + k +&quot; : &quot; + v ); return new KeyValue&lt;&gt;(k.split(&quot;-&quot;)[0],k.split(&quot;-&quot;)[1] + &quot;-&quot; + v);&#125;), (v1, v2) -&gt; v1 + &quot;:&quot; + v2, JoinWindows.of(10000) ) .foreach((k,v) -&gt; System.out.println(k+ &quot;---&quot; + v)); &#125;&#125; 注意：同个应用中对同个流的监听实例只能有一个，SaleCountSink使用了@Input(AnalyticsBinding.PAGE_COUNT_IN)KTable&lt;String,Long&gt;与PageCountSink有冲突，要嘛把PageCountSink中的监听去掉，要嘛重命名其中一个相关的监听配置 AnalyticsBinding 完整代码12345678910111213141516171819202122232425262728293031323334353637public interface AnalyticsBinding &#123; String PAGE_VIEWS_OUT = &quot;pvout&quot;; String PAGE_VIEWS_IN = &quot;pvin&quot;; String PAGE_COUNT_MV = &quot;pcmv&quot;; String PAGE_COUNT_OUT = &quot;pcout&quot;; String PAGE_COUNT_IN = &quot;pcin&quot;; String SALES_OUT = &quot;salesout&quot;; String SALES_IN = &quot;salesin&quot;; String SALES_COUNT_MV = &quot;scmv&quot;; String SALES_COUNT_OUT = &quot;scout&quot;; String SALES_COUNT_IN = &quot;scin&quot;; @Input(PAGE_VIEWS_IN) KStream&lt;String,PageViewEvent&gt; pageViewsIn(); @Output(PAGE_COUNT_OUT) KStream&lt;String,Long&gt; pageCountOut(); @Input(PAGE_COUNT_IN) KTable&lt;String,Long&gt; pageCountIn(); @Output(PAGE_VIEWS_OUT) MessageChannel pageViewsOut(); @Output(SALES_OUT) MessageChannel salesOut(); @Input(SALES_IN) KStream&lt;String,SalesEvent&gt; salesIn(); @Output(SALES_COUNT_OUT) KStream&lt;String,Long&gt; salesCountOut(); @Input(SALES_COUNT_IN) KTable&lt;String,Long&gt; salesCountIn();&#125; application.yml完整配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990server: port: 8388spring: application: name: input-demo cloud: instance-count: 1 instance-index: 0 stream: bindings: pvout: destination: pvst group: pvst producer: header-mode: raw pvin: destination: pvst group: pvst consumer: header-mode: raw pcout: destination: pcst group: pcst producer: use-native-encoding: true pcin: destination: pcst group: pcst content-type: application/json consumer: use-native-encoding: true header-mode: raw salesout: destination: sost group: sost producer: header-mode: raw salesin: destination: sost group: sost consumer: header-mode: raw scout: destination: scst group: scst producer: use-native-encoding: true scin: destination: scst group: scst content-type: application/json consumer: use-native-encoding: true header-mode: raw kafka: streams: binder: configuration: default: key: serde: org.apache.kafka.common.serialization.Serdes$StringSerde value: serde: org.apache.kafka.common.serialization.Serdes$StringSerde cache: max: bytes: buffering: 0 commit: interval: ms: 1000 brokers: localhost:9092 zk-nodes: localhost:2181 bindings: pcout: producer: key-serde: org.apache.kafka.common.serialization.Serdes$StringSerde value-serde: org.apache.kafka.common.serialization.Serdes$LongSerde pcin: consumer: key-serde: org.apache.kafka.common.serialization.Serdes$StringSerde value-serde: org.apache.kafka.common.serialization.Serdes$LongSerde scout: producer: key-serde: org.apache.kafka.common.serialization.Serdes$StringSerde value-serde: org.apache.kafka.common.serialization.Serdes$LongSerde scin: consumer: key-serde: org.apache.kafka.common.serialization.Serdes$StringSerde value-serde: org.apache.kafka.common.serialization.Serdes$LongSerde 多流合并的理念是把流两两之间的key处理成一样进行join处理，join的实现方法大家可以自行阅读文档。如果是三个流以上，需要先将两个流合并之后生成一个流再与第三流合并处理。 相关文档 spring cloud data flow spring cloud stream spring cloud stream kafka streams应用官方视频讲解 KTable与KStream的关系 kafka官方文档 kafka streams window的概念翻译版 kafka权威指南]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>实时流</tag>
        <tag>spring</tag>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[内存与JVM]]></title>
    <url>%2F2018%2F07%2F23%2F%E5%86%85%E5%AD%98%E4%B8%8EJVM%2F</url>
    <content type="text"><![CDATA[自己一边看书一边实践一边整理下来的知识思维导向图，个人感觉能够掌握自动内存管理机制、高效并发并加以应用，理解虚拟机执行子系统、程序编译与代码优化，才可以说熟悉JVM。]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>java基础</tag>
        <tag>JVM</tag>
        <tag>内存</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zk分布式任务队列交互设计]]></title>
    <url>%2F2018%2F07%2F22%2Fzk%E5%88%86%E5%B8%83%E5%BC%8F%E4%BB%BB%E5%8A%A1%E9%98%9F%E5%88%97%E4%BA%A4%E4%BA%92%E8%AE%BE%E8%AE%A1%2F</url>
    <content type="text"><![CDATA[项目地址：https://github.com/super-sean/task-pipeline 背景近来公司业务上越来越多的跨进程比较耗时计算的场景出现，想用异步通信来解决长时间资源占用及等待问题，而基于多方的探讨，不考虑采用mina和netty这种异步通信的框架，最后决定使用zookeeper来实现 目的异步进行耗时较长的复杂计算请求，可随时获取请求执行进度 实现思路 将这种请求的发起者当作是请求任务的生产者，每个请求其实就是一个计算任务。 后端接收请求的服务就是消费者，获得请求之后进行计算，并更新计算进度。 当任务完成时，请求发起者可以通过监听任务状态回调实现自己的逻辑。 过程中，请求发起者也可以主动获取计算讲求的进度。 实现设计基于实现思路，设计zk的path结构如下 /master为程序高可用实现预留路径 /apps为业务连接节点，底下结构为/app/node，比如你有个业务叫a,有两个业务节点b1和b2，那就有/a/b1和/a/b2 路径。由业务节点启动时注册 /workers底下结构逻辑与/apps一致，只不过节点为服务端的节点，由服务端节点启动时注册 /tasks由业务提交注册的计算任务,以业务区分目录，以app-node-timestamp格式来命名taskid,每个节点拥有params,status和result三个节点 params 为请求参数，以文本格式存储，例如可以使用json格式传输 status 为task状态，默认有submit,running,done,noworker（无计算服务）,missapp（app节点断线）,consumed（已消费），resubmit（重分配）几种状态，worker可以添加自定义中间过程状态，任务提交时默认为submit状态。 result 为初始不存在，当status变更为done时添加，内容为文本格式，例如可以使用json，包括type和value,先只支持两种，第一种为直接返回为{“type”:”content”,”value”:”something”},考虑zk单个节点的容量问题，可能返回较大数据量，使用redis作为结果缓存层，返回{“type”:”redis_key”,”value”:”one redis key”} 当然不用redis也行，当数据量更大的时候可使用其它工具，这里先选用redis history目录下为完成的任务，定时持久化清理。 /assign由系统根据业务app分配作业给worker，以node-taskid来标识作业history目录下为执行完的作业，定时持久化清理 模块设计 调度系统 实现基于zk的路径交互，负责与业务和服务两端交互 业务端接口包封装 对于业务端来说，只需要提交服务端接口标识，接口参数之后返回taskId,根据需要通过taskId进行结果回调监听，支持查询task状态，需要屏蔽底层操作，透明化复杂操作。 服务端接口包封装 对于服务端来说，只需要继承某个类，声明服务标识，实现监听task队列的方法，处理被推送过来的任务，并根据需要更新自定义task状态，处理完成后在方法选择返回的内容类型即可 流程设计正常交互流程(由于用的uml画图工具问题，画得不是很规范，见谅…)正常交互流程worker断线重新分配任务流程 核心模块类图基本操作都抽象成名为operation的类，基于不同角色做扩展，目前情况如下baseOperation为zk的基本操作，operation为倾向原子性业务操作，分角色扩展的operation如serverOperation为封装角色实现本身的组合操作监听器主要有以下监听器实现每个角色都是基于以上两个核心模块加以逻辑处理来实现自己的功能 其它相关设计Task分发策略worker每当被分发task，便权重添加1，处理完则减1分发Task时选择权重最小的节点若权重都一样，则选择第一个节点 server主从实现使用curator包的LeaderLatch zk path acl权限管理使用三个角色，tp_server,tp_worker,tp_app目前没有做细粒度控制，只是tp_server创建的给另外两个角色授权，tp_worker创建的给tp_server授权，tp_app创建的给tp_server授权]]></content>
      <categories>
        <category>设计</category>
      </categories>
      <tags>
        <tag>zookeeper</tag>
        <tag>分布式</tag>
        <tag>队列</tag>
      </tags>
  </entry>
</search>
