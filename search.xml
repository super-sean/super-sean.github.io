<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[商业化产品规划与服务架构思考]]></title>
    <url>%2F2019%2F10%2F20%2F%E5%95%86%E4%B8%9A%E5%8C%96%E4%BA%A7%E5%93%81%E8%A7%84%E5%88%92%E4%B8%8E%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84%E6%80%9D%E8%80%83%2F</url>
    <content type="text"><![CDATA[背景近来有幸负责了公司自己部门一个商业化小组的研发事项，结合自己的工作经验对产品将来走向和服务架构规划梳理自己的见解，希望可以让小组目标一致，高效地进行积累进行沉淀。 业务理解及规划按个人愚见商业化前期主要分为几个核心模块，GMV短期快速增长/基础设施搭建/用户消费习惯培养/渠道引流变现能力，每个模块并非独立，而是相互交叉相互依赖。 GMV短期快速增长是团队运作过程中常见的场景，单独划分模块往往是因为支持团队在指定时间内可以达到相应指标而需要低成本快速支持运营手段达到指标。其中需要流量管控/活动属性管控/玩法沉淀配套/交易流程动态调整营销策略 基础设施主是为实现商业化整套玩法的服务支撑，包括并不限于流量入口/交易流程/会员体系/特权体系/积分体系/活动体系/营销体系/租赁体系等 用户消费习惯培养主要需要对用户进行分层，需要在数据层面制定好分析模型，统一业务指标数据字典及统计口径，在研发过程预留足够的空间给后期分析。 渠道引流变现一般为与外部渠道，通过流量付费或利益分成的形式进行合作 团队行事基准各行各业，不同的团队行事基准可能很多不同，但是基本都离开不了一种通用原则，领域模型。积累方法论及实践方法，抽象领域分析模型及执行策略。团队就以此进行需求迭代，产品研发，运营事项及日常工作交流指导。 领域模型一般两种来源，专家或行业通用模型修改加上经验积累。大多数公司不像大厂会有专门的专家，绝大多数公司更是没有领域模型的发展概念。 领域模型一般先按团队内对产品理解较深的人制定第一版框架，后续不停通过迭代优化。前期可选择通用模型进行指标组建，再细化模块。如决策可尝试使用SWOT，人人都会的RFM用户分层模型（事实上维度选择及划分非常有学问），用户行为漏斗分析模型，盘面分析模型等。盘面分析及用户行为分析是最基本。 简单举个例子，通过接口数据发现付费转化率低，即发起了预下单，但是却没有最终成功支付，那猜测主要要嘛是付费内容质量问题，要嘛是充值流程问题，那可以从用户到底有没有充值来判断，然后进行下步策略。 当然有理论支撑之后，必须在基础设施上能支持得上，在研发过程需要预埋一些点。 技术服务架构有以上前提的理解下，对总体的服务架构进行了个初步的划分 业务网关负责外部交互，web对应http rest, as是我们公司自己封装的一套通信交互标准,消息网关用于与公司其它内部服务通信。 在这一层，需要注意的是协议层的相关模型定义，整个系统对内对外通信，吸取DDD的指导思想，定义好业务领域模型。一家公司发展到一定程度之后，代码功能模块会经过很多人维护研发，想保证成本（结构封装，接口适配、沟通学习等），就必须梳理沉淀相关的业务领域模型，不然越往后越难控制。 除了定义模型，协议规范也是必须，请求体/返回体结构、状态码约定、分页/聚合/规则查询方式等。 商业化核心服务商业化通用逻辑可以看到在商业化发展过程中可以抽象的服务其实有可能会很多，可以有一个汇总服务，作为母体孵化其它模块，当达到比较成熟或遇到业务机遇时可进行抽离独立。 服务间的通信领域模型事件驱动服务只关注领域内事项处理，将处理结果通过消息总线广播出去，有需要的服务自行进行定阅，参考ddd的设计理念，在发送消息和解析加入工具包，封装领域模型及相应的事件状态和流程。 系统规模大了之后往往需要考虑事件流的问题，需要对事件顺序编排，有可能会多个上游依赖的情况，为了避免这种情况，可以只关注核心一个事件，主动查询其它模块结果的处理方式，这样保证了一个事件流是树状结构。 研发事件管理服务及后台，拿kafka为例，可以在应用层面添加工具包，为producer添加生产标识，consumer添加消费标识，可以用注解和扫描，并发送给事件管理服务，这样事件流的结构就可以被绘画。这样只要稍微做下支持，就可以知道整个事件流每个环节的处理情况，数据统计等，甚至可以自动/人工进行介入消息失败/异常处理策略的实现。 当然前期可简单的先各个模块自维护各自的消息发送，消费和补偿实现。比如只是定义各自的消息的队列名、结构和行为状态定义，让下游各自监听处理。在服务完善之后再进行迁移。 补偿模块凡是依赖消息通知的实现，在完整性和稳定性上考虑，必须加上补偿模块，凡是需要依赖消费事件的服务都需要制定主动询问上流的策略，比如开通会员触发了特权发放，除了正常消息通知以外，特权服务需要主动询问会员服务最近一段时间内有哪些用户开通了会员但是还没发放特权，并进行发放，当然也需要做好幂等控制。 而补偿也可以像事件流管理平台一样，提供工具包，支持补偿发起者注册到平台上，可以对系统中的补偿行为进行监控以及介入。 基础服务一般商业化会需要一些基础服务支撑，这一层会尽量剥离业务特性，专注专业领域上的研发。本文主要介绍业务层面的实现，便不多加介绍这一环节。 结语目前在公司内只是把以上的相关业务理解及设计思考与团队的产品/研发同事进行了同步，在每个点上都有相应的积累，但是还是任重而道远，而要独步完善及验证。 今天加油，明天也加油！]]></content>
      <tags>
        <tag>架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一种serverless的实现方案]]></title>
    <url>%2F2019%2F09%2F16%2F%E4%B8%80%E7%A7%8Dserverless%E7%9A%84%E5%AE%9E%E7%8E%B0%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[背景自从上次参加qcon开发者大会，一直在思考serviceless的可执行方案，一路上也在公司推进中，虽然进度有点慢，没办法，业务太忙了。。。 架构总览 服务模块网关需要实现配置化扩展及热更新接口服务，主要需要支持数据的curd场景。抽象的说其实只有2种场景，就是数据的查询和变更。 抽象交互场景，制定一套接口使用规范 查询查询一般分明细查询和聚合查询，核心结构如下： 字段列表 支持别名，数据格式定义 请求参数列表（过滤） 支持别名，请求参数类型（如日期、范围、字段值匹配等） 排序 支持别名，排序类型（升序降序） 分页 游标或者页码 之前已经有 基于solr服务提供通用配置化接口服务 可以参考 变更变更一般有replace和del场景，del比较简单，只需要请求参数列表即可。replace的核心结构如下： 变更数据 以key value的形式传参，支持伪cas，传key的原值，如果不是原值放弃修改 请求参数列表（过滤） 支持别名，请求参数类型（如日期、范围、字段值匹配等） 安全需要针对使用方提供租赁服务，查询接口限流，变更接口安全参数派发及验证 语法引擎需要根据接口配置模板选择不同的数据源的语法进行转译，最基本的支持sql查询模板（JAVA动态编译/解析文本的一种简易方法）,如果存储层有不支持sql的中间件或者引擎，就需要定向开发。参考datax的设计，抽象组件,只针对reader和writer编程，以插件的形式加入项目对应的目录和修改对应的配置文件即可。 存储及查询引擎其实最简单在这一层添加个db，就已经能把一个简单的serviceless架构跑起来了 apache kudu + impala考虑到高可用、高性能、扩展性和成本的问题，又要支持oltp和olap，选择普通db的话很快就会到整套服务各方面的天花板，参考开源OLAP引擎测评报告 联表查询性能 单表查询性能 综合对比 综合考虑下选择impala 考虑kudu的原因，参考有了HBase为什么还要Kudu 其实选型上也是考虑到大厂都有在使用，impala不用说了，很多公司都用到tx/ali/神策等，kudu像京东/小米都有在用。正准备在公司申请开发环境进行探研。 搜索引擎搜索引擎在明细查询上有很优秀的支持，如es、solr redis业务很常用的，在数据存储上没太高要求的前提下的性能最优选择 配置以上模块的运作需要有一套元数据设计来支持，元数据主要包括几方面： 应用信息 安全信息，比如盐信息 接口描述 针对sql及特定语法的接口配置信息，之前已经有 基于solr服务提供通用配置化接口服务 可以参考 数据源信息 异常策略等 云函数sql和代码加载（代码块及jar包上传）两种实现思路，sql是成本最低，但是也限制比较多，代码热加载会有一些性能和安全隐患问题，需要额外的成本去维护。 数据同步使用了非普通db存储的方案，而且serviceless的目标并不是也不可能覆盖所有的场景，那就肯定存在需要进行数据同步的情况，数据同步行业内主要分批处理和流处理两种，当然直接服务对接也可以，不过不建议，因为会对接服务多了，会比较很难把控。 批处理使用azkaban进行离线调度是现在很多公司会做的，我们公司的大数据部门也即将提供基于azkaban改造的调度系统，可直接对接使用 流数据如果是面向业务的场景的，其实并没有像大数据场景那种实时更新模型推荐的需要，主要是想支持实时更新，使用kafka 和kafka streams 基本能满足(spring cloud stream 基于kafka的使用简析)。还有其它工具，如kettle或者apache nifi，但是考虑到是面向研发特性不建议直接使用这种数据处理流工具。这里更想提的其实是管道处理和管理的能力搭建。 数据的产生之后（source），会经过一到多层的中间处理（processor），最终将结果落地到某个地方（sink），基于这样的理念，可以很容易基于kafka抽象一套服务出来。但是缺少平台把控能力。 spring cloud data flow 就是管道管理平台，有很多现成的组件。SCDF (Spring Cloud Data Flow)的核心功能是ETL （Extract, Transform, Load ），Extract，Transform，Load 分别对应上图的Source，Processor 和Sink，这三个组件是Spring Boot 微服务，部署运行在SCDF之上的，三个微服务放在一起构成一个Stream（pipeline）用来实现数据处理，它们之间通过AMQP进行异步的消息传递。 架构简析 SCDF 由下面的Spring Cloud家族成员组成 服务组件 流处理 批处理支持 后台支持语言定义流程及拖拽操作 但是实践下来发现两个问题，一个是不能有通用组件环节，它是以cicd流水线管理方式，每条流水线的应用都得重新部署,没有公共流水线的概念（有可能我使用姿势不对?）,另一个问题是如果使用SCDF，就得跟公司现有的使用框架及发布部署平台对接，需要进行改造，这其中的成本也不小。 结语基本上serviceless的一种实现思路及方案已经描述完了，这其中会有很多技术难点及问题，之后在推进过程中再一一细述。]]></content>
      <categories>
        <category>设计</category>
      </categories>
      <tags>
        <tag>架构</tag>
        <tag>serviceless</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Qcon广州站]]></title>
    <url>%2F2019%2F07%2F14%2FQcon%E5%B9%BF%E5%B7%9E%E7%AB%99%E5%A4%A7%E4%BC%9A%E4%B8%AA%E4%BA%BA%E7%BA%AA%E8%A6%81%2F</url>
    <content type="text"><![CDATA[大会ppt下载地址 &ensp; &ensp;&ensp; &ensp;今年5月27号在举行的qcon全球开发者大会广州站，在下有幸，公司安排参加，就着大会的内容，个人闲聊一下看法。（工作比较忙，导致拖了一个半月才回过头来聊这次大会） Service Mesh&ensp; &ensp;&ensp; &ensp;qcon的大会安排是有不同卖场同时进行，自己优先选择了后端相关的微服务实战及高可用高性能架构专场参加。有幸见到arthas的作者，阿里在专场中更多针对他们是如何在微服务这块提升研发效能进行分享，网易及唯品会对service mesh的落地踩坑改善经验进行了讲解。&ensp; &ensp;&ensp; &ensp;对于service mesh，先感谢大厂和很多大牛在一些新的方向或者是旧技术点翻新上，给行业领头踩坑及推广。江南白衣说了句大实话，目前看来无论是哪里的service mesh的实践方案都还不够成熟，不适合生产环境大面积推广。&ensp; &ensp;&ensp; &ensp;个人认为service mesh虽然不一定会在公司落地，但是作为架构知识，还是有必要掌握，主要是针对服务云化之后的能力支持。目前国内市场上主要是Linkerd和Istio两个方案，个人准备就着Istio进行研究。 火爆的实时流&ensp; &ensp;&ensp; &ensp;在大会上刚好有空档，去听了一下阿里的flink改造版本，7月份已经将合并入官方主干且发版，真的是很厉害。然而在会议上透露着一些问题依然无法很好被解决，那便是数据初始化需求、与批处理比较的稳定性和多表聚合的复杂性问题。 service less的思考虽然service less与本次大会无直接关联，但是近几年我一直在研究service less及推荐落地，细想之下，其实service less的落地离不开成熟的微服务架构用于实例的管理及云函数的实现，成熟的存储方案及计算能力和数据流方案。接下来将会梳理一篇关于service less落地的文章。]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>qcon</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一次App首页代码优化纪要]]></title>
    <url>%2F2019%2F07%2F06%2F%E4%B8%80%E6%AC%A1App%E9%A6%96%E9%A1%B5%E4%BB%A3%E7%A0%81%E4%BC%98%E5%8C%96%E7%BA%AA%E8%A6%81%2F</url>
    <content type="text"><![CDATA[背景最近在负责公司APP首页性能优化相关项目，就着原来的技术方案及代码进行了重构，原来接口中存在的问题如下： 代码问题，瀑布式编码，导致单个类的代码很容易膨胀，最大体积的类已经快接近2000行代码，还是之前有优化过的。 代码问题，方法参数问题，方法参数没有封装，有一些通用方法的参数已经有十几个，不容易进行扩展，维护成本比较高。 性能问题，由于涉及到多种数据构造来源，没有进行批量处理，有很多rpc请求。 很多公司在发展过程中为了能快速满足业务，很多点并不是当时写代码的人没有考虑，而是根本没时间考虑，这都很正常，既然安排到这块的工作，就尽力做到最好。 先来看一下app当前的大概效果 可以看到app的设计是卡片加瀑布流的交互形式，旧的设计是每种卡片一种结构体，目前有28种卡片，给客户端和服务端都带来性能问题和维护成本，新的设计是将卡片抽象成统一结构体，主要分展示字段和预留扩展字段，有点像BI的结构设计，在这里就不展开讲。主要先记一下这个结构体命名为section。 旧代码流程简析 优化内容责任划分整理下来，其实接口处理流程可以划分为 获取卡片数据 获取实体数据，即卡片内容模板数据 构造结构体 补充卡片数据 位置调整 上下文内容作为链路参数将请求的内容进行处理后作为上下文内容参数传递进责任链，每个环节各自进行加工传递下个环节，比如section列表、推荐section个数等 卡片模板使用抽象模板，每种卡片的构造抽象成一种模板，持有通用接口，各自实现不同，包括获取实体id信息和构造section的方法等 使用桥接减少指定卡片调用的代码复杂度其实根据卡片类型即可知道使用哪种模板，使用桥接即可方便获取对应模板的实例进行处理 减少外部请求抽象实体环节，很方便可变多个单次为批量原来的接口中由于实现方案的问题，需要每次都获取DB配置数据及推荐数据，通过客户端回传的方式，改为当开启了推荐数据就不需要进行DB配置数据请求 改造后数据流程 代码功能模块更为内聚，入口类从原有的近2000行代码缩减为200行左右。每个扩展类的代码简洁清晰，大多不超过200行，其它不超过300行，便于维护。改造后的接口响应时间为旧接口的2/3，还待压测看具体数据]]></content>
      <categories>
        <category>设计</category>
      </categories>
      <tags>
        <tag>JAVA基础</tag>
        <tag>优化</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GC问题解决的那些套路]]></title>
    <url>%2F2019%2F05%2F19%2FGC%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3%E7%9A%84%E9%82%A3%E4%BA%9B%E5%A5%97%E8%B7%AF%2F</url>
    <content type="text"><![CDATA[利器介绍&ensp; &ensp;&ensp; &ensp; gceasy 是一个国外在线的gc日志分析工具，可以帮你快速定位到gc问题，并且博客内容也有一些高级的gc问题排查分析文章，即blog.gceasy.io 简单问题GC异常&ensp; &ensp;&ensp; &ensp;主要是GC日志中有明确标明异常类型的情况，如&ensp; &ensp;&ensp; &ensp;针对每种异常情况，某度和某歌都有很多资料带你飞，一般都由内存泄露及不合理的内存分配导致。OOM不同情况及解决方法 合理的内存分配及降低GC频次&ensp; &ensp;&ensp; &ensp;针对mirror gc,major gc,full gc的频次管理，只要不是内存泄露引起，一般可以通过调整内存大小来解决，而合理的内存分配，在不考虑代码优化的情况下，需要进行一版参数配置之后观察GC情况之后，结合各个区域的回收机制可以调整改善。如果初期不知道怎么进行参数配置，根据应用所需，分配堆内存2-4G，新生代/老年代以1:2的比例配置。如果需要调整新生代的内存分配情况，记得默认情况下是eden:s0:s1为8:1:1这种问题要求对垃圾回收器的策略及jvm堆内存模型比较清楚 进阶问题调整某个阶段时长&ensp; &ensp;&ensp; &ensp;并非所有GC阶段都可以直接配置时长，像parnew gc的单次时长无法直接控制，像这种情况一般可以通过内存大小调整，gc线程数的配置来间接改善，总时长可以通过频次来间接改善。 &ensp; &ensp;&ensp; &ensp;而有直接时长配置的参数，通过日志观察，不断进行调整，调整的套路基本为 观察原来的情况，取一个合理值进行配置观察 观察想调整的阶段情况及其它阶段，看是否会影响其它阶段的时长，比如减少preclean时长可能会影响remark的时长 是否有策略可以解决影响到的阶段，比如影响了remark时长，那就配合major gc 前进行一次mirror gc，但有可能会影响总的mirror次数及时长 跳转步骤1这种问题要求对垃圾回收器具体的执行内容及步骤要比较清晰，清楚知道垃圾回收器在做什么操作以及会带来什么影响 ，了解安全点的概念及日志分析 基于GC日志时间参数进行调整&ensp; &ensp;&ensp; &ensp;主要是针对 user,sys,real这三个值进行调整 user时间长导致real比较长这种情况好处理，说明gc花费时间比较，从内存分配及并行线程数量分配角度入手 sys时间长导致real比较长&ensp; &ensp;&ensp; &ensp;这种情况比较复杂，大多数情况下跟业务代码无直接关系，在后面的扫盲知识里有对应的字段意义说明及排障贴里面有对应的跟进情况，可以了解一下。基本思路是排除法，到最终需要strace抓进程的系统调用情况或跟进系统级别的情况如内存页，CPU，IO等 &ensp; &ensp;&ensp; &ensp;这种问题要求能够查看hotspot源码，能大概知道有什么操作，了解gc过程中单个gc操作时间的分配情况，如何进行调整及跟进，也得了解一些系统相关的知识 &ensp; &ensp;&ensp; &ensp;按公司某大神的说法，有时候只能靠玄学了，一路猜想及排除定位 简易方法论&ensp; &ensp;&ensp; &ensp;GC问题可能还有很多情况是大家没遇到过，结合以上的问题类型，基本都是以下套路去跟进解决： 查看GC情况 定位问题 确定目标 &ensp; &ensp;&ensp; &ensp;最好是单个目标进行，不要同时调整多个内容，到头来不知道是哪个影响哪个，比如减少preclean时间，然后不增加remark时间，然后是不增加总体pause的时间，或者是减少full gc的次数，或者是减少mirror gc的次数 查询解决方案及实践 持续观察改进 知识扫盲&ensp; &ensp;&ensp; &ensp;基于公司GC调优会涉及到的点，整理了对应的知识 GC日志时间概念 real —— 程序从开始到结束所用的时钟时间。这个时间包括其他进程使用的时间片和进程阻塞的时间（比如等待 I/O 完成） user —— 进程执行用户态代码（核心之外）所使用的时间。这是执行此进程所使用的实际 CPU 时间，其他进程和此进程阻塞的时间并不包括在内。在垃圾收集的情况下，表示 GC 线程执行所使用的 CPU 总时间 sys —— 进程在内核态消耗的 CPU 时间，即在内核执行系统调用或等待系统事件所使用的 CPU 时间 安全点SafePoint概念及日志简析概念 安全点是在程序执行期间的所有GC Root已知并且所有堆对象的内容一致的点。 从全局的角度来看，所有线程必须在GC运行之前在安全点阻塞。 （作为一种特殊情况，运行JNI代码的线程可以继续运行，因为它们只使用句柄。但在安全点期间，它们必须阻塞而不是加载句柄的内容。） 从本地的角度来看，安全点是一个显着的点，它位于执行线程可能阻止GC的代码块中。 大多数调用点都能当做安全点。 在每个安全点都存在强大的不变量永远保持true不变，而在非安全点可能会被忽视。 编译的Java代码和C / C ++代码都在安全点之间进行了优化，但跨安全点时却不那么优化。 JIT编译器在每个安全点发出GC映射。 VM中的C / C ++代码使用程式化的基于宏的约定（例如，TRAPS）来标记潜在的安全点。类型 GC safepoint需要知道在那个程序位置上，调用栈、寄存器等一些重要的数据区域里什么地方包含了GC管理的指针；如果要触发一次GC，那么JVM里的所有Java线程都必须到达GC safepoint。 Deoptimization safepoint需要知道在那个程序位置上，原本抽象概念上的JVM的执行状态（所有局部变量、临时变量、锁，等等）到底分配到了什么地方，是在栈帧的具体某个slot还是在某个寄存器里，之类的。 如果要执行一次deoptimization，那么需要执行deoptimization的线程要在到达deoptimization safepoint之后才可以开始deoptimize。HotSpot中，安全点位置主要在： 方法返回之前 调用某个方法之后 抛出异常的位置 循环的末尾为什么把这些位置设置为jvm的安全点呢,主要目的就是避免程序长时间无法进入safepoint,比如JVM在做GC之前要等所有的应用线程进入到安全点后VM线程才能分派GC任务 ,如果有线程一直没有进入到安全点,就会导致GC时JVM停顿时间延长,比如写了一个超大的循环导致线程一直没有进入到安全点,GC前停顿了8秒。 之所以只在选定的位置放置安全点是因为： 挂在安全点的调试符号信息要占用空间。如果允许每条机器码都可以是安全点的话，需要存储的数据量会很大（当然这有办法解决，例如用delta存储和用压缩） 安全点会影响优化。特别是deoptimization 安全点，会迫使JVM保留一些只有解释器可能需要的、JIT编译器认定无用的变量的值。本来JIT编译器可能可以发现某些值不需要而消除它们对应的运算，如果在安全点需要这些值的话那就只好保留了。这才是更重要的地方，所以要尽量少放置安全点 像HotSpot VM这样，在安全点会生成polling代码询问VM是否要“进入安全点”，polling也有开销所以要尽量减少。 还有一种情况是当某个线程在执行native函数的时候。此时该线程在执行JVM管理之外的代码，不能对JVM的执行状态做任何修改，因而JVM要进入安全点不需要关心它。所以也可以把正在执行native函数的线程看作“已经进入了安全点”，或者把这种情况叫做“在safe-region里”。JVM外部要对JVM执行状态做修改必须要通过JNI。所有能修改JVM执行状态的JNI函数在入口处都有安全点检查，一旦JVM已经发出通知说此时应该已经到达安全点，就会在这些检查的地方停下来把控制权交给JVM。 日志开启参数-XX:+PrintGCApplicationStoppedTime -XX:+PrintGCApplicationConcurrentTime -XX:+PrintSafepointStatistics -XX:PrintSafepointStatisticsCount=1 -XX:+UnlockDiagnosticVMOptions -XX:-DisplayVMOutput -XX:+LogVMOutput 格式 12vmop [threads: total initially_running wait_to_block] [time: spin block sync cleanup vmop] page_trap_count66935.969: GenCollectForAllocation [ 1782 0 0 ] [ 0 0 0 3 15 ] 0 除了GC，其他触发安全点的VM Operation包括： Biased lock revocation 取消偏向锁 Class redefinition (e.g. javaagent，AOP的代码植入) Various debug operation (e.g. thread dump 一条或所有线程，heapduump等) 线程情况 total: 所有的java线程数 initially_running: 号召进入安全点时，还是Running状态的线程数 wait_to_block: 所有线程都不Running时，仍不是Block状态的线程数 时间情况 spin: VMOP线程使用自旋，等待所有线程都不是Running的时间 block: VMOP线程基于锁，等待所有线程都是Block的时间 sync: spin+block +其他，这是从开始到进入安全点的总耗时 cleanup: 退出清理所用时间 vmop: 真正执行VM Operation的时间 Full GC触发条件 由System.gc调用 老年代空间不足 永久代空间不足 gc 担保失败在发生MinorGC前,检查老年代是否有连续空间,如果有,则执行,如果没有,根据设置:-XX:-HandlePromotionFailure 指定,如果打开,那么继续检查,当前老年代最大可用连续空间大于平均历次晋升到老年代大小,如果大于,则进行MinorGC,否则进行FullGC,如果HandlePromotionFailure 不设置 直接进行FullGC. Cocurrent mode failure 发生在cms的清理sweep阶段,发现有新的垃圾产生,而且老年代没有足够空间导致的 parnew使用的是复制算法，并行回收 并行：多条垃圾回收线程并行工作，用户线程仍处于等待状态 并发: 垃圾收集线程跟用户线程同时执行，不一定是并行，可能交替执行，垃圾收集程序运行在区分业务线程的另外一个CPU上 serial共用配置参数 -XX:SurvivorRatio -XX:PretenureSizeThreshold -XX:HandlePromotionFailure 启用参数 -XX：+UseConcMarkSweepGC -XX: +UseParNewGC 性能参数 -XX:ParallelGCThreads &lt;=8?8:3+5n/8 触发条件 eden满了就进行 晋升条件 大对象直接进入老年代 PretenureSizeThreshold 长期存活对象将进入老年代 -XX:MaxTenuringThreshold=15 动态对象年龄判定 在Survivor空间相同年龄所有对象大小总和大于Survivor空间一半就会进入老年代 cmsgc stage 1. CMS-initial-mark 初始标记 此阶段是初始标记阶段，是stop the world阶段，因此此阶段标记的对象只是从root集最直接可达的对象 2. CMS-concurrent-mark 并发标记 此阶段是和应用线程并发执行的，所谓并发收集器指的就是这个，主要作用是标记可达的对象 3. CMS-concurrent-preclean 执行预清理 此阶段主要是进行一些预清理，因为标记和应用线程是并发执行的，因此会有些对象的状态在标记后会改变，此阶段正是解决这个问题 4. CMS-concurrent-abortable-preclean 执行可中止预清理 加入此阶段的目的是使cms gc更加可控一些，作用也是执行一些预清理，以减少Rescan阶段造成应用暂停的时间 5. CMS-remark 重新标记 第二个stop the world阶段了，即Rescan阶段，此阶段暂停应用线程，对对象进行重新扫描并标记，主要是标记并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象 6. CMS-concurrent-sweep 并发清除 Start of sweeping of dead/non-marked objects. Sweeping is concurrent phase performed with all other threads running. 7. CMS-concurrent-reset 并发重设状态等待下次CMS的触发 In this phase, the CMS data structures are reinitialized so that a new cycle may begin at a later time. In this case, it took 0.127 secs. 线上用到的相关参数及新增参数-XX:+CMSParallelInitialMarkEnabled 可以开启该阶段的并行标记，使用多个线程进行标记，减少暂停时间 -XX:+CMSParallelRemarkEnabled 同上，针对remark阶段 -XX:+UseCMSInitiatingOccupancyOnly 指定HotSpot VM总是使用-XX:CMSInitiatingOccupancyFraction的值作为old的空间使用率限制来启动CMS垃圾回收。 如果没有使用-XX:+UseCMSInitiatingOccupancyOnly，那么HotSpot VM只是利用这个值来启动第一次CMS垃圾回收，后面都是使用HotSpot VM自动计算出来的值。 -XX:CMSInitiatingOccupancyFraction=80 结合上面的参数使用，当老年代使用率达到百分之几的时候使用 -XX:+CMSScavengeBeforeRemark 这个选项强制HotSpot VM在CMS GC之前执行MinorGC，在再标记步骤之前做MinorGC，可以减少再标记的工作量，目的是减少young代的对象数 -XX:CMSMaxAbortablePrecleanTime：当abortable-preclean阶段执行达到这个时间时才会结束 -XX:CMSScheduleRemarkEdenSizeThreshold（默认2m）：控制abortable-preclean阶段什么时候开始执行，即当eden使用达到此值时，才会开始abortable-preclean阶段 -XX:CMSScheduleRemarkEdenPenetratio（默认50%）：控制abortable-preclean阶段什么时候结束执行 -XX:CMSWaitDuration=5010 保证了最晚每 X 毫秒进行一次判断是否要进行CMS GC，默认2S -XX:+CMSClassUnloadingEnabled 允许CMS对永久代不再使用的对象进行回收 CMS碎片整理由于cms是基于标记-清理算法，会导致空间碎片，难以分配新的连续内存，所以要进行内存空间整理，保证可分配的连续性内存，要不然会触发full gc -XX:+UseCMSCompactAtFullCollection 用于在full GC之后增加一个碎片整理过程 -XX:CMSFullGCsBeforeCompaction=0 设置执行多少次不压缩的full GC之后，跟着来一次碎片整理过程 线上其它参数-XX:LargePageSizeInBytes=128M 系统内存页相关参数 详细资料 https://www.cnblogs.com/bonelee/p/6207037.html -XX:+UseFastAccessorMethods 设置关闭快速调用成员方法，这里表述可能不是太准确。首先说明一下什么方法叫做AccessorMethods， 1必须是成员方法，静态方法不行， 2返回值类型必须是引用类型或者int，其它都不算， 3方法体的代码必须满足aload_0; getfield #index; areturn或ireturn这样的模式，方法名是什么都没关系，是不是get、is、has开头都不重要。 因为类方法方法体很简单，而且没有方法计数器，开启此设置后可以跳过对该类方法的编译。 但是貌似不推荐使用，详见以下链接 http://cr.openjdk.java.net/~never/6385687/ -XX:SoftRefLRUPolicyMSPerMB=0 设置每兆堆空闲空间中SoftReference的存活时间，默认值是1s CMS GC 触发条件 FullGC 预计完成CMS回收所需要的时间小于预计的老年代填满的时间 判断老年代内存使用率是否大于初始化参数，如果为true，则触发GC，如果为false，且UseCMSInitiatingOccupancyOnly 为true，则返回false 判断年轻代存活的对象晋升是否可能会失败，如果失败，触发GC。 如果metaSpace认为需要回收metaSpace区域，也会触发一次cms回收 Q&amp;A在公司进行了分享，最后给听客问了几个问题，感觉算是分享的小考核吧，如果您有幸看到这篇文章并且看到这里不妨尝试着回答下: 实测新生代使用率90%左右会触发mirror gc,为什么？ 为什么线上不将CMSParallelInitialMarkEnabled作为默认参数? mirror gc ,young gc,major gc ,full gc的区别 结合jvm内存模型讲一下GC过程在每个区域的变化 CMSWaitDuration的值为什么要这样设置？]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>java基础</tag>
        <tag>JVM</tag>
        <tag>内存</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于solr服务提供通用配置化接口服务]]></title>
    <url>%2F2019%2F05%2F15%2F%E5%9F%BA%E4%BA%8Esolr%E6%9C%8D%E5%8A%A1%E6%8F%90%E4%BE%9B%E9%80%9A%E7%94%A8%E9%85%8D%E7%BD%AE%E5%8C%96%E6%8E%A5%E5%8F%A3%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[背景&ensp; &ensp;&ensp; &ensp;公司内部有基于solr搜索平台服务，在做需求的过程中，对接了搜索平台，发现可以将搜索平台的交互抽象并使用配置化的方式进行数据请求，这样一来，可以通过配置化的方式达到数据查询需求的快速实现，提高开发效率，于是进行了技术方案的设计与评估。 技术方案架构 时序图 类图 配置模板 项目落地情况&ensp; &ensp;&ensp; &ensp;经过一个3天快速开发及2天自测，开发好了第一个版本，service+http服务，不带可视化配置支持，紧接着对接了一个新需求，有直接对接http接口的，也有对接service的，在对接过程中情况如下 好处/优点 业务服务不用多次对接数据源层的实现，可以做到只要导入数据即可通过通用接口查询，节省调试的时间 因为配置化，支持热变更，快速调整入参及结果，节省联调时间 添加通用额外业务实体关联配置支持扩展源数据 最大的好处直接提供配置即可提供http接口，无需开发 配置模板一般比较简单，复杂需求才有可能会稍微比较复杂 坏处/缺点 前期服务还未完善前，联调链变长，会有在业务开发和搜索平台中间多一层服务需要调试的错觉 基于solr本身的特点，在数据分页的方式上会有特殊要求，是基于游标滚动的形式翻页，导致前端需要支持多一种分页查询的方法 还不能支持过于复杂的聚合查询,比如group by 字段A ,聚合查询count(带条件 字段B) 这样的查询目前还支持不了，只能支持group by 字段A ，count(B的各种值)，比如按分类（字段A）的聚合后推荐状态为1(字段B)的个数这样的支持不了，但是可以支持按分类（字段A）的聚合后不同推荐状态(字段B)的个数 目前还没有可视化的配置支持，接口一但多起来便会很难管理 业务如果对通用接口做熔断，只能涉及到的操作都统一处理，除非可以做到按参数熔断，公司目前的熔断器还不支持 solr的数据更新延迟问题 感想&ensp; &ensp;&ensp; &ensp;看起来貌似问题多多，但是好处的吸引力很大，而且遇到的问题貌似并没有不可解决的 项目计划 支持可视化配置，区分业务模块及api Id,后期支持对业务及api id限流 支持dataset的缓存策略配置 结合前端，可自研BI系统，这样连前端的后台活动类开发工作都可以减少 支持修改更新配置操作，支持事务操作 支持不同数据源 案例&ensp; &ensp;&ensp; &ensp;查询某个集合的原始字段,通过stat_date_s及nj_id_l两个字段过滤及自定义排序123456789101112131415161718192021&#123;&quot;id&quot;:xxx,&quot;key&quot;:&quot;xxx&quot;,&quot;searchToken&quot;:&quot;xxx&quot;,&quot;type&quot;:&quot;list&quot;,&quot;fields&quot;:[ ],&quot;queries&quot;:[ &#123;&quot;fieldName&quot;:&quot;stat_date_s&quot;,&quot;type&quot;:&quot;mix&quot;&#125;, &#123;&quot;fieldName&quot;:&quot;nj_id_l&quot;,&quot;type&quot;:&quot;field&quot;&#125; ],&quot;sorts&quot;:[ &#123;&quot;fieldName&quot;:&quot;nj_id_l&quot;,&quot;type&quot;:&quot;asc&quot;&#125;, &#123;&quot;fieldName&quot;:&quot;stat_date_s&quot;,&quot;type&quot;:&quot;asc&quot;&#125;], &quot;facets&quot;:&#123;&#125;, &quot;extInfo&quot;:[ ], &quot;fieldValueTransfer&quot;:[ ]&#125; &ensp; &ensp;&ensp; &ensp;复杂一点的列表查询1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283&#123;&quot;id&quot;:xxx,&quot;key&quot;:&quot;xxx&quot;,&quot;searchToken&quot;:&quot;xxx&quot;,&quot;type&quot;:&quot;list&quot;,&quot;fields&quot;:[ &#123;&quot;fieldName&quot;:&quot;id&quot;,&quot;alias&quot;:&quot;recordId&quot;&#125;, &#123;&quot;fieldName&quot;:&quot;nj_id_l&quot;,&quot;alias&quot;:&quot;anchorId&quot;&#125;, ...],&quot;queries&quot;:[ &#123;&quot;fieldName&quot;:&quot;stat_date_s&quot;,&quot;alias&quot;:&quot;statDate&quot;,&quot;type&quot;:&quot;field&quot;&#125;, ... ],&quot;sorts&quot;:[ &#123;&quot;fieldName&quot;:&quot;nj_id_l&quot;,&quot;type&quot;:&quot;asc&quot;&#125;], &quot;facets&quot;:&#123;&#125;, &quot;extInfo&quot;:[ &#123; &quot;connectFieldName&quot;:&quot;anchorId&quot;, &quot;type&quot;:&quot;user&quot;, &quot;field&quot;:[ &#123;&quot;fieldName&quot;:&quot;name&quot;&#125;, &#123;&quot;fieldName&quot;:&quot;thumb&quot;&#125; ] &#125; ], &quot;fieldValueTransfer&quot;:[ &#123; &quot;fieldName&quot;:&quot;anchorGroup&quot;, &quot;items&quot;:[ &#123;&quot;og&quot;:&quot;xxx主播&quot;,&quot;biz&quot;:0&#125;, &#123;&quot;og&quot;:&quot;xxxx主播&quot;,&quot;biz&quot;:1&#125; ] &#125; ]&#125;//看下http接口的请求及返回 参数&#123; &quot;statDate&quot;:&quot;2019-05-07T00:00:00Z&quot;, &quot;regTime&quot;:&#123;&quot;start&quot;:&quot;2013-07-30&quot;,&quot;end&quot;:&quot;2013-08-30&quot;&#125;, &#125;返回&#123; &quot;code&quot;: 0, &quot;data&quot;: [ &#123; &quot;anchorIndex&quot;: xxx, &quot;replayCountDaily&quot;: 0, &quot;anchorCover&quot;: &quot;xxx&quot;, &quot;hasPay&quot;: xx, &quot;fansCount&quot;: xxx, &quot;anchorGroup&quot;: &quot;&quot;, &quot;source&quot;: &quot;&quot;, &quot;anchorId&quot;: xxx, &quot;anchorName&quot;: &quot;xxx&quot;, &quot;anchorLevel&quot;: &quot;xxx&quot;, &quot;recordId&quot;: &quot;xxx&quot;, &quot;regTime&quot;: &quot;xxx&quot;, &quot;anchorCategory&quot;: &quot;xxx&quot;, &quot;replayCount&quot;: 0, &quot;voiceCount&quot;: xxx, &quot;replayCountWeekly&quot;: 0, &quot;band&quot;: xxx, &quot;lived&quot;: 0, &quot;recommendStatus&quot;: &quot;&quot;, &quot;lastUpdateTime&quot;: &quot;xxx&quot;, &quot;firstVoiceTime&quot;: &quot;xxx&quot; &#125;,... ], &quot;msg&quot;: &quot;OK&quot;, &quot;page&quot;: &#123; &quot;cursor&quot;: &quot;xxx&quot;, &quot;isLastPage&quot;: true, &quot;pageSize&quot;: 30, &quot;totalCount&quot;: 13, &quot;type&quot;: &quot;cursor&quot; &#125;&#125; &ensp; &ensp;&ensp; &ensp;聚合查询123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960&#123; &quot;id&quot;: xxx, &quot;key&quot;: &quot;xxx&quot;, &quot;searchToken&quot;: &quot;xxx&quot;, &quot;type&quot;: &quot;agg&quot;, &quot;fields&quot;: [], &quot;queries&quot;: [&#123; &quot;fieldName&quot;: &quot;stat_date_s&quot;, &quot;alias&quot;: &quot;statDate&quot;, &quot;type&quot;: &quot;field&quot; &#125;, &#123; &quot;fieldName&quot;: &quot;user_type_ti&quot;, &quot;alias&quot;: &quot;userType&quot;, &quot;type&quot;: &quot;field&quot; &#125; ], &quot;sorts&quot;: [], &quot;facets&quot;: &#123; &quot;groupByFieldName&quot;: &quot;xxxx&quot;, &quot;groupByFieldAlias&quot;: &quot;xxxx&quot;, &quot;alias&quot;: [&#123; &quot;fieldName&quot;: &quot;status_0_count&quot;, &quot;alias&quot;: &quot;recommendCount&quot; &#125;, &#123; &quot;fieldName&quot;: &quot;status_1_count&quot;, &quot;alias&quot;: &quot;forbiddenCount&quot; &#125; ], &quot;items&quot;: [&#123; &quot;type&quot;: &quot;agg&quot;, &quot;fieldName&quot;: &quot;status_s&quot;, &quot;aggName&quot;: &quot;status&quot; &#125;] &#125;, &quot;extInfo&quot;: []&#125;http请求无参数,返回结果&#123; &quot;code&quot;: 0, &quot;data&quot;: [ &#123; &quot;anchorClassTotal&quot;: xxx, &quot;anchorClass&quot;: &quot;xxx&quot;, &quot;noStatusCount&quot;: xxx &#125;,... ], &quot;msg&quot;: &quot;OK&quot;, &quot;page&quot;: &#123; &quot;cursor&quot;: &quot;xxx&quot;, &quot;isLastPage&quot;: false, &quot;pageNo&quot;: 0, &quot;pageSize&quot;: 30, &quot;totalCount&quot;: xxx, &quot;type&quot;: &quot;pagination&quot; &#125;&#125;]]></content>
      <categories>
        <category>设计</category>
      </categories>
      <tags>
        <tag>数据平台</tag>
        <tag>架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[long-gc案例分析]]></title>
    <url>%2F2019%2F05%2F04%2Flong-gc%E6%A1%88%E4%BE%8B%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[long gc优化&ensp; &ensp;&ensp; &ensp;近来发现负责研发的项目总是会收到long-gc的告警，比如： 12345678910major GC: - 2 (No GC) start: 2019-05-06 06:18:47.678, end: 2019-05-06 06:18:53.125 [Par Survivor Space] init:209664K; used:19.7%(41348K) -&gt; 19.7%(41348K); committed: 100.0%(209664K) -&gt; 100.0%(209664K) [Code Cache] init:2496K; used:19.7%(48450K) -&gt; 19.7%(48430K); committed: 19.9%(49088K) -&gt; 19.9%(49088K) [Compressed Class Space] init:0K; used:0.7%(7721K) -&gt; 0.7%(7721K); committed: 0.7%(8040K) -&gt; 0.7%(8040K) [Metaspace] init:0K; used:68569K -&gt; 68574K); committed: 69932K -&gt; 69932K) [Par Eden Space] init:1677824K; used:57.3%(961524K) -&gt; 59.6%(1001110K); committed: 100.0%(1677824K) -&gt; 100.0%(1677824K) [CMS Old Gen] init:1048576K; used:23.8%(250428K) -&gt; 13.4%(140549K); committed: 100.0%(1048576K) -&gt; 100.0%(1048576K) duration:5447ms, throughput:99.9% &ensp; &ensp;&ensp; &ensp;可以直接看到用的parnew + cms的收集器组合,也能看得出来主要回收行为发生在 old gen，所以就提取gc的日志来看，如下:12345678910111213141516171819202019-05-06T06:18:47.678+0800: 16712.771: [GC (CMS Initial Mark) [1 CMS-initial-mark: 250428K(1048576K)] 1253301K(2936064K), 0.0643432 secs] [Times: user=1.12 sys=0.00, real=0.06 secs]2019-05-06T06:18:47.742+0800: 16712.836: Total time for which application threads were stopped: 0.0655335 seconds, Stopping threads took: 0.0001332 seconds2019-05-06T06:18:47.742+0800: 16712.836: [CMS-concurrent-mark-start]2019-05-06T06:18:47.820+0800: 16712.913: [CMS-concurrent-mark: 0.077/0.077 secs] [Times: user=0.41 sys=0.00, real=0.07 secs]2019-05-06T06:18:47.820+0800: 16712.913: [CMS-concurrent-preclean-start]2019-05-06T06:18:47.831+0800: 16712.924: [CMS-concurrent-preclean: 0.010/0.011 secs] [Times: user=0.01 sys=0.00, real=0.01 secs]2019-05-06T06:18:47.831+0800: 16712.924: [CMS-concurrent-abortable-preclean-start]2019-05-06T06:18:49.745+0800: 16714.839: Total time for which application threads were stopped: 0.0014635 seconds, Stopping threads took: 0.0001513 seconds CMS: abort preclean due to time 2019-05-06T06:18:52.845+0800: 16717.939: [CMS-concurrent-abortable-preclean: 4.912/5.014 secs] [Times: user=5.40 sys=0.83, real=5.02 secs]2019-05-06T06:18:52.846+0800: 16717.940: [GC (CMS Final Remark) [YG occupancy: 1042070 K (1887488 K)]2019-05-06T06:18:52.847+0800: 16717.940: [Rescan (parallel) , 0.1073388 secs]2019-05-06T06:18:52.954+0800: 16718.047: [weak refs processing, 0.0108072 secs]2019-05-06T06:18:52.965+0800: 16718.058: [class unloading, 0.0341564 secs]2019-05-06T06:18:52.999+0800: 16718.092: [scrub symbol table, 0.0079842 secs]2019-05-06T06:18:53.007+0800: 16718.100: [scrub string table, 0.0021272 secs][1 CMS-remark: 250428K(1048576K)] 1292498K(2936064K), 0.1678019 secs] [Times: user=1.54 sys=0.00, real=0.17 secs]2019-05-06T06:18:53.014+0800: 16718.108: Total time for which application threads were stopped: 0.1689968 seconds, Stopping threads took: 0.0001364 seconds2019-05-06T06:18:53.015+0800: 16718.108: [CMS-concurrent-sweep-start]2019-05-06T06:18:53.125+0800: 16718.219: [CMS-concurrent-sweep: 0.111/0.111 secs] [Times: user=0.13 sys=0.03, real=0.11 secs]2019-05-06T06:18:53.125+0800: 16718.219: [CMS-concurrent-reset-start]2019-05-06T06:18:53.128+0800: 16718.222: [CMS-concurrent-reset: 0.003/0.003 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] &ensp; &ensp;&ensp; &ensp;眼尖的人可能已经看出来，事实上会stw的过程并没有很长,重点主要看CMS-initial-mark 和 CMS-remark 的记录，可以看到时间比较正常，所以看来CAT的long-gc告警是针对整个gc耗时的。接着看可以发现abortable-preclean的耗时比较长，如果对CMS gc每个阶段的工作都比较清楚，很快就可以找到方法解决。那我们的目标就是降低preclean的时长且不影响remark的时长，并且不会对gc的总体时长及频率带来影响。&ensp; &ensp;&ensp; &ensp;既然abortable-preclean长达5秒，那就先把preclean的最长时间限制设置短，添加-XX:CMSMaxAbortablePrecleanTime=1000参数。添加之后如果不做其它操作，有可能会带来remark的时间增加，所以基于preclean的特性，自然想到remark之前减少remark的工作负担，那就添加参数-XX:CMSScheduleRemarkEdenPenetration=20&ensp; &ensp;&ensp; &ensp;CMSScheduleRemarkEdenSizeThreshold、CMSScheduleRemarkEdenPenetration，默认值分别是2M、50%。两个参数组合起来的意思是预清理后，eden空间使用超过2M时启动可中断的并发预清理（CMS-concurrent-abortable-preclean），直到eden空间使用率达到50%时中断，进入remark阶段。我们设置成20，让Preclean更快地进入remark阶段-XX:+CMSScavengeBeforeRemark 在remark强制触发一次mirror gc&ensp; &ensp;&ensp; &ensp;这样配置的结果其实也可以预见，总的pause time会增加，按天来算的话，但是假设单次gc的时间加上强制触发的时间比之前的单次gc时间要短且总的puase time不会增加很多，那就达到我们的目的了。那多少才算多，具体得看应用的情况了。&ensp; &ensp;&ensp; &ensp;看一下配置前后的gc情况未配置参数前配置参数后而总的pause时间并没有增加，所以该问题得到了解决 优化后遇到的另一个问题&ensp; &ensp;&ensp; &ensp;在同一个项目进行配置后过了几天，突然出现不断进行CMS GC的情况，分析GC日志情况如下堆内存情况GC cause&ensp; &ensp;&ensp; &ensp;看到这两个模块的情况，基于上可以推测是新生代和老年代内存配置问题，检查jvm内存参数配置，发现配置了123 -XX:MaxHeapSize=3221225472-XX:MaxNewSize=2147483648&ensp; &ensp;&ensp; &ensp;也就是说配置了新生代与老年代的比例大约是2:1，官方默认配置在x86机器是应该是1:8，网上大部分资料都推荐是1:2,如果新生代配置比老年代小，有新生代晋升比较快的情况会导致CMS处理不过来,将参数调整为MaxHeapSize为4G，MaxNewSize略小于2G就不再出现 神奇的长initial Mark及YGC过长的sys时间&ensp; &ensp;&ensp; &ensp;在GC日志中发偶尔initial Mark偶尔会比较长，有出现1s以上的情况1234567891011121314151617181920212223242526272829302019-05-10T13:03:18.282+0800: 61533.941: [GC2019-05-10T13:03:18.283+0800: 61533.942: [ParNew: 848736K-&gt;9204K(943744K), 0.0091360 secs] 2526438K-&gt;1686979K(3040896K), 0.0105130 secs] [Times: user=0.10 sys=0.01, real=0.01 secs]2019-05-10T13:03:18.293+0800: 61533.952: Total time for which application threads were stopped: 0.0152630 seconds2019-05-10T13:03:18.296+0800: 61533.956: [GC [1 CMS-initial-mark: 1677774K(2097152K)] 1687161K(3040896K), 1.4645810 secs] [Times: user=0.00 sys=1.49, real=1.47 secs]2019-05-10T13:03:19.761+0800: 61535.421: Total time for which application threads were stopped: 1.4685620 seconds2019-05-10T13:03:19.762+0800: 61535.421: [CMS-concurrent-mark-start]2019-05-10T13:03:19.765+0800: 61535.425: Total time for which application threads were stopped: 0.0031970 seconds2019-05-10T13:03:19.780+0800: 61535.439: Total time for which application threads were stopped: 0.0044250 seconds2019-05-10T13:03:19.880+0800: 61535.540: [CMS-concurrent-mark: 0.111/0.119 secs] [Times: user=1.30 sys=0.30, real=0.12 secs]2019-05-10T13:03:19.881+0800: 61535.540: [CMS-concurrent-preclean-start]2019-05-10T13:03:19.900+0800: 61535.560: [CMS-concurrent-preclean: 0.019/0.020 secs] [Times: user=0.06 sys=0.00, real=0.02 secs]2019-05-10T13:03:19.901+0800: 61535.560: [CMS-concurrent-abortable-preclean-start] CMS: abort preclean due to time 2019-05-10T13:03:20.905+0800: 61536.564: [CMS-concurrent-abortable-preclean: 0.999/1.004 secs] [Times: user=1.80 sys=0.20, real=1.00 secs]2019-05-10T13:03:20.909+0800: 61536.568: [GC[YG occupancy: 470719 K (943744 K)]2019-05-10T13:03:20.909+0800: 61536.568: [GC2019-05-10T13:03:20.909+0800: 61536.569: [ParNew: 470719K-&gt;11056K(943744K), 0.0087720 secs] 2148494K-&gt;1688888K(3040896K), 0.0100970 secs] [Times: user=0.10 sys=0.01, real=0.01 secs]2019-05-10T13:03:20.919+0800: 61536.579: [Rescan (parallel) , 0.0042770 secs]2019-05-10T13:03:20.923+0800: 61536.583: [weak refs processing, 0.0237130 secs]2019-05-10T13:03:20.947+0800: 61536.607: [class unloading, 0.0255570 secs]2019-05-10T13:03:20.973+0800: 61536.632: [scrub symbol table, 0.0084850 secs]2019-05-10T13:03:20.981+0800: 61536.641: [scrub string table, 0.0014630 secs] [1 CMS-remark: 1677831K(2097152K)] 1688888K(3040896K), 0.1002410 secs] [Times: user=0.25 sys=0.01, real=0.10 secs]2019-05-10T13:03:21.010+0800: 61536.669: Total time for which application threads were stopped: 0.1046380 seconds2019-05-10T13:03:21.010+0800: 61536.669: [CMS-concurrent-sweep-start]2019-05-10T13:03:21.013+0800: 61536.673: Total time for which application threads were stopped: 0.0034750 seconds2019-05-10T13:03:21.016+0800: 61536.675: Total time for which application threads were stopped: 0.0027740 seconds2019-05-10T13:03:21.019+0800: 61536.678: Total time for which application threads were stopped: 0.0025430 seconds2019-05-10T13:03:21.021+0800: 61536.680: Total time for which application threads were stopped: 0.0022570 seconds2019-05-10T13:03:21.023+0800: 61536.683: Total time for which application threads were stopped: 0.0019970 seconds2019-05-10T13:03:21.025+0800: 61536.684: Total time for which application threads were stopped: 0.0019480 seconds2019-05-10T13:03:21.027+0800: 61536.687: Total time for which application threads were stopped: 0.0021600 seconds2019-05-10T13:03:21.029+0800: 61536.689: Total time for which application threads were stopped: 0.0021560 seconds2019-05-10T13:03:21.031+0800: 61536.691: Total time for which application threads were stopped: 0.0020060 seconds2019-05-10T13:03:21.033+0800: 61536.693: Total time for which application threads were stopped: 0.0021040 seconds2019-05-10T13:03:21.040+0800: 61536.700: Total time for which application threads were stopped: 0.0041470 seconds2019-05-10T13:03:22.343+0800: 61538.003: [CMS-concurrent-sweep: 1.309/1.333 secs] [Times: user=2.36 sys=0.23, real=1.33 secs]2019-05-10T13:03:22.343+0800: 61538.003: [CMS-concurrent-reset-start]2019-05-10T13:03:22.353+0800: 61538.013: [CMS-concurrent-reset: 0.010/0.010 secs] [Times: user=0.02 sys=0.01, real=0.01 secs]&ensp; &ensp;&ensp; &ensp;查看安全点日志,并没有发现异常12 61533.938: GenCollectForAllocation [ 1780 0 0 ] [ 0 0 0 3 11 ] 0&ensp; &ensp;&ensp; &ensp;所以既没有vmop，也没有应用线程号召安全点阻塞的情况，user为0，real却为1.47，同时sys为1.49一般来说real时间远大于user时间有可能由两方面导致，一是比较重的 I/O 行为包括网络连接及磁盘操作,另一个是CPU资源紧缺.通过zbx观察机器对应时间的io、tcp连接及cpu情况，都比较正常，参考文章（点击查看）。基于sys &gt; user的情况的分析文章(点击查看)&ensp; &ensp;&ensp; &ensp;查看hotspot源码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869void VM_CMS_Initial_Mark::doit() &#123; if (lost_race()) &#123; // Nothing to do. return; &#125; HS_DTRACE_PROBE(hs_private, cms__initmark__begin); GenCollectedHeap* gch = GenCollectedHeap::heap(); GCCauseSetter gccs(gch, GCCause::_cms_initial_mark); VM_CMS_Operation::verify_before_gc(); IsGCActiveMark x; // stop-world GC active _collector-&gt;do_CMS_operation(CMSCollector::CMS_op_checkpointRootsInitial); VM_CMS_Operation::verify_after_gc(); HS_DTRACE_PROBE(hs_private, cms__initmark__end);&#125;void VM_CMS_Operation::verify_before_gc() &#123; if (VerifyBeforeGC &amp;&amp; GenCollectedHeap::heap()-&gt;total_collections() &gt;= VerifyGCStartAt) &#123; HandleMark hm; FreelistLocker x(_collector); MutexLockerEx y(_collector-&gt;bitMapLock(), Mutex::_no_safepoint_check_flag); Universe::heap()-&gt;prepare_for_verify(); Universe::verify(true); &#125;&#125;void CMSCollector::do_CMS_operation(CMS_op_type op) &#123; gclog_or_tty-&gt;date_stamp(PrintGC &amp;&amp; PrintGCDateStamps); TraceCPUTime tcpu(PrintGCDetails, true, gclog_or_tty); TraceTime t(&quot;GC&quot;, PrintGC, !PrintGCDetails, gclog_or_tty); TraceCollectorStats tcs(counters()); switch (op) &#123; case CMS_op_checkpointRootsInitial: &#123; SvcGCMarker sgcm(SvcGCMarker::OTHER); checkpointRootsInitial(true); // asynch if (PrintGC) &#123; _cmsGen-&gt;printOccupancy(&quot;initial-mark&quot;); &#125; break; &#125; case CMS_op_checkpointRootsFinal: &#123; SvcGCMarker sgcm(SvcGCMarker::OTHER); checkpointRootsFinal(true, // asynch false, // !clear_all_soft_refs false); // !init_mark_was_synchronous if (PrintGC) &#123; _cmsGen-&gt;printOccupancy(&quot;remark&quot;); &#125; break; &#125; default: fatal(&quot;No such CMS_op&quot;); &#125;&#125;void VM_CMS_Operation::verify_after_gc() &#123; if (VerifyAfterGC &amp;&amp; GenCollectedHeap::heap()-&gt;total_collections() &gt;= VerifyGCStartAt) &#123; HandleMark hm; FreelistLocker x(_collector); MutexLockerEx y(_collector-&gt;bitMapLock(), Mutex::_no_safepoint_check_flag); Universe::verify(true); &#125;&#125; &ensp; &ensp;&ensp; &ensp; 进入到vmop操作即do_CMS_operation(CMSCollector::CMS_op_checkpointRootsInitial),怀疑是操作前有cpu资源等待的情况，由于机器为32个虚拟核，而机器上的java实例达到了16个，cpu并非独享，查看jvm参数，没有开启并行initial mark，添加参数CMSParallelInitialMarkEnabled进行观察，同时添加-XX:CMSWaitDuration=5010 &ensp; &ensp;&ensp; &ensp; 同时发现parnew也有类似的情况12 2019-05-03T11:19:26.016+0800: 320262.210: [GC2019-05-03T11:19:26.017+0800: 320262.211: [ParNew: 847306K-&gt;8507K(943744K), 0.7853400 secs] 2462473K-&gt;1623871K(3040896K), 0.7866170 secs] [Times: user=0.18 sys=0.80, real=0.78 secs]&ensp; &ensp;&ensp; &ensp; 调取安全点日志1320262.188: GenCollectForAllocation [ 1782 0 0 ] [ 0 0 0 8 787 ] 0&ensp; &ensp;&ensp; &ensp; 可以看到没有线程wait to block,spin,block及sync的时间都正常，时间都集中在vmop中，也就是说安全点的操作并没有产生额外的耗时，结合gc的日志，可以看得出来gc线程本身的操作是正常的，那问题集中在gc日志的real时间及safepoint日志的vmop时间。虑到一样是cpu非独占的情况，查看jvm参数，发现ParallelGCThreads设置为20，上面提到机器是32虚拟核，16个java实例，估怀疑还是cpu资源抢占的问题，将ParallelGCThreads设置为8,进行观察&ensp; &ensp;&ensp; &ensp; 分析到这里其实可以知道已经非程序内部可以调整的问题，一开始以为与io阻塞相关，想先从hsperfdata进行实验,但发现已经添加了参数PerfDisableSharedMem,如果定位cpu抢占资源的情况是错的，那只能通过strace跟进进程系统调用 配置前配置后可以看到initial mark和remark都比之前的要少，而且initial mark的时间转为正常，没有再出现上述情况，但是发现young gc的总耗时变长,之前是一天5分钟左右，现在是11分钟，如下配置前配置后 查看堆内存情况配置前配置后 &ensp; &ensp;&ensp; &ensp;这样看就很明显了，查看jvm参数没有配置新生代内存占用大小或比例，添加xmn参数指定1g，解决young gc次数增加的情况。 &ensp; &ensp;&ensp; &ensp;另外parnew的长耗时问题，也得到改善，之前每天都有超过1s的情况，在新配置上线后降低了长耗时的出现频率。至少可判断猜想是正确的。]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>java基础</tag>
        <tag>JVM</tag>
        <tag>内存</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[创业团队那些事]]></title>
    <url>%2F2019%2F02%2F09%2F%E5%88%9B%E4%B8%9A%E5%9B%A2%E9%98%9F%E9%82%A3%E4%BA%9B%E4%BA%8B%2F</url>
    <content type="text"><![CDATA[&ensp; &ensp;&ensp; &ensp;近来由于忙着换工作和春节生活杂事安排很久没更新博客，原本想着年前写一篇docker或者spring cloud gateway的相关文章也是被搁下了。昨天送走了春节最后一波来访的亲戚，今天终于有时间可以写写东西。&ensp; &ensp;&ensp; &ensp;自从有换工作的念头后，其实就很想写一下自我总结，总结算上实习7年来在工作上的感想。其实每年以及每隔一段时间我都会在个人笔记上自我复盘，但这次想分享出来，权当是给看客茶余饭后打发时间杂文也行。&ensp; &ensp;&ensp; &ensp;前段日子在网上看到一句话&ensp; &ensp;&ensp; &ensp;当你觉得痛苦时，你只有两个选择，一个是被打倒，一个是被逼着成长&ensp; &ensp;&ensp; &ensp;类似的话语其实大家都听得不少，这句话我再次听到的时候很有感触，回想起自己从业以来每次遇到的痛苦时刻，有放弃，有坚持。 &ensp; &ensp;&ensp; &ensp;2015年8月，我从唯品会离职出来加入这家公司，当时工作3年有多，一腔热血，老板b君和当时已经加入他们且和我比较要好的同事y君过来聊了会，我毅然决定加入团队，即便是降薪过去。后来回想自己当时真的是年轻不懂事。转眼3年半过去了，公司从一开始做Pass到后来tob电商入驻平台再到后来做tob电商自营平台，期间经历过挺多苦难，但是就我个人感觉而言，当一切上了轨道，遇到的困难其实并没有一开始遇到的要难。&ensp; &ensp;&ensp; &ensp;一开始老板b君经常会拉着我们几个技术负责人做培训，包括他对行业的认知，产品的规划，个人的价值观和创业的大饼想象等。后来公司越来越大，b君也不怎么拉着人培训了，直到开始做自营，经常看到b君拉着物流、市场、采购的人做狼性培训。&ensp; &ensp;&ensp; &ensp;b君有些话让我感受比较深。 &ensp; &ensp;&ensp; &ensp;“我们过往都在选择容易的路在走，而往往只有痛苦的路才是正确的，我们不能绕过去”这句话本身我并没有太大的感觉，但是结合b君自身的经历和公司一些有能力的人，我不禁反思，为什么要选择难的路走，b君期望得到的和大家期望得到的，通过这条路真的可以得到快速实现吗？也许放在tob电商这个事是正确的，但是再往大的方向上看，为什么要选择tob电商，虽然近些年都说tob电商很大机率是风口，但是很明显市场并没有大家想象中那么热烈，对比一些红火行业来看。所以这句话也许适用b君及公司，因为b君觉得他没有退路了，但是却不定适用他手下的人，很难引起共鸣。最终b君很多事情的推动都被手下的人应付着。 &ensp; &ensp;&ensp; &ensp;“我都这么痛苦了，为什么你们不能再往前一步”后期b君对初始的核心团队成员是这样的想法，并传达给了大部分人。技术副总监办事不力，他跟技术副总监说了这话，技术的一些高层人员不愿放弃技术转纯管理岗，他对他们也说了这句话，等等。不得不承认，b君为了公司能活下去活得好，他牺牲了很多东西，全公司压力最大那个确实是他。公司越来越大，老板自然也不可能照顾到每个初创团队的成员，自然是公司需要什么，做得到就做，做不到别人顶上，大多数情况下是小公司找不到合适价位的人才。 &ensp; &ensp;&ensp; &ensp;“只要xxx还在，他手下整个团队换掉都没关系”，“到现在这阶段，没有说缺了谁不行”b君对团队的管理还是比较侧重抓头不抓尾，其实没什么毛病，只是没做好人才储备的情况下就比较麻烦，而且不是非常优秀的小公司很难做人才储备，尤其当公司的人力资源能力水平还处于不完善阶段，更加是难上加难。 &ensp; &ensp;&ensp; &ensp;目前这家公司发展还可以，我写b君的东西其实也思量了挺久，写不好就变成抱怨吐槽，其实没有哪家创业公司的老板是没能力的，但也没有人是十全十美的，没有问题的公司都已经挂掉了。写b君的东西是想表达在选择创业团队的时候，老板是重要考虑因素之一，不过可能很多人在求职过程中并接触不到，可以了解好公司的氛围和企业文化再做决定。 &ensp; &ensp;&ensp; &ensp;知乎上有一小篇文章叫《别做被小公司毁掉的年轻人》，文章最后说“小公司毁不掉你，毁掉自己只是那不思进取的自己”，说的也没错，但是这里想说的其实是，能有更好的选择，就别让自己吃那么多无谓的苦，让自己能在快乐中做贡献，对公司对个人都是好事。 &ensp; &ensp;&ensp; &ensp;个人的建议是除非看得特别透彻，综合考虑好个人自身的性格，做好了准备，才可以选择创业团队，要不然还是选择能让自己术业有专攻的平台会来得更好，做好沉淀，为将来更好的机会做好准备。创业公司的大饼是一种期望，有风险，像理财一样，个人也需要给自己划定风险承受能力范围。有更好的选择还是选择更好的，大多数人往往还是看不够透彻，做不够准备的。 &ensp; &ensp;&ensp; &ensp;创业团队有很多乱七八糟的坑，只有你想不到，没有尽头。运气特别好的上市，稍次的被收购，大多还是处于不上不下的尴尬层次，还有更多的是直接挂掉。但是我感谢在创业团队的经历，让我更加成熟。]]></content>
      <categories>
        <category>随笔</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[datax源码解析及分布式实现思路]]></title>
    <url>%2F2018%2F11%2F23%2Fdatax%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E5%8F%8A%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9E%E7%8E%B0%E6%80%9D%E8%B7%AF%2F</url>
    <content type="text"><![CDATA[&ensp; &ensp;&ensp; &ensp;相信很多人接触datax都会去了解它的分布式执行模式，很“幸运”，阿里开源出来的是阉割版，默认只支持单机模式，研发团队对外基本也不回应分布式相关的问题。故此，想让datax支持分布式功能，只能自己下些功夫。&ensp; &ensp;&ensp; &ensp;在github上也有人做了分布式的支持项目，如 TianLangStudio/DataXServer 后面再聊下这个项目的情况。&ensp; &ensp;&ensp; &ensp;开始之前，按官方文档的建议，了解一下以下概念: Job: Job是DataX用以描述从一个源头到一个目的端的同步作业，是DataX数据同步的最小业务单元。比如：从一张mysql的表同步到odps的一个表的特定分区。 Task: Task是为最大化而把Job拆分得到的最小执行单元。比如：读一张有1024个分表的mysql分库分表的Job，拆分成1024个读Task，用若干个并发执行。 TaskGroup: 描述的是一组Task集合。在同一个TaskGroupContainer执行下的Task集合称之为TaskGroup JobContainer: Job执行器，负责Job全局拆分、调度、前置语句和后置语句等工作的工作单元。类似Yarn中的JobTracker TaskGroupContainer: TaskGroup执行器，负责执行一组Task的工作单元，类似Yarn中的TaskTracker。 了解源码&ensp; &ensp;&ensp; &ensp;我们先看下datax的源码，从datax.py入手，datax.py 收集运行机器的相关信息组装参数调用com.alibaba.datax.core.Engine类，从类入口开始看主要流程分几个部分。 容器启动前操作 JOB容器启动操作 TaskGroup容器启动操作 Job跟Task的处理流程 插件相关类关系 &ensp; &ensp;&ensp; &ensp;主要流程差不多就这样了，需要注意的是，在单个容器里，研发团队的设计理念是希望建立reader和write的1：1的管道模型来处理数据。 分布式支持实现思路正派做法&ensp; &ensp;&ensp; &ensp;按以上的解析内容，最“正经”的方案应该是让datax 将task切分好分发给不同的TaskGroup容器执行，直接执行job文件一般都是使用的job容器，如果不指定的话。按源码调试的结果，task其实是job文件中content里的每个实例。一开始提到TianLangStudio/DataXServer其实就是基于hadoop yarn api和client包进行这个思路的实现，可惜很久没维护，文档也没写好，而且远程调用只有Thrift。&ensp; &ensp;&ensp; &ensp;基于“正经”方案的思路和我们的使用的习惯（目前我们是单个task一个job文件），其实可以使用一些支持服务发现及负载平衡的框架，如spring cloud，将job内容及相关参数提交给网关接口，使用自定义流量分发规则（考虑不同节点硬件资源），分发到对应节点上的服务上，服务再调起datax engin。假如需要切分task，则只需要在分发前建一层task切分的服务即可，节点上的服务根据接收到的任务类型来组装参数调用不同的datax容器。&ensp; &ensp;&ensp; &ensp;挫一点的做法就是使用azkaban，手工配置指定机器运行data job 邪门歪道&ensp; &ensp;&ensp; &ensp; 单个task不能再切分我认为是不合理的，首先reader和writer支持分布式的选择不多，其次，会有单点流量问题。所以其实我想要的是能不能将datax单一数据管道的模型给改造成支持分布式，让单个task也支持分布式。&ensp; &ensp;&ensp; &ensp; 了解了源码之后，我觉得可以是可以有如下切入点： 从job接收的时候就切分好数据块,master负责接收job/task，切分成任务块，每场任务块由一对reader和writer完成处理，就是基本datax task更小粒度或者说基于数据粒度上的切分 reader支持分布式，比如presto reader不切，在传输给writer的queue时切，多个writer接收。其实就是将queue做成支持分布式，比如使用kafka writer本身支持分布式，比如presto &ensp; &ensp;&ensp; &ensp; 如果纯粹地做数仓，我觉得reader和writer使用presto或其它支持分布式读写操作的技术等，然后再结合task负载均衡分配，基本可以满足了。如果需要做数据更新情况会比较复杂，需要考虑writer是否支持分布式更新及目标数据源是否支持并发插入而不容易产生锁。&ensp; &ensp;&ensp; &ensp; 目前我们的架构是基于项目的情况，选择最低成本能够实现的最优方案，就是使用spring cloud + datax，保持datax核心的完整性不修改，在上面加一层，reader和writer尽量地使用presto为主，es为辅。下个阶段才会考虑使用yarn和queue的改造。]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>数据平台</tag>
        <tag>ETL</tag>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[并发编程]]></title>
    <url>%2F2018%2F10%2F18%2F%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[&ensp; &ensp;&ensp; &ensp;并发编程是java的基础知识，但是也论深度，工作这些年与很多开发打过交道，有些人工作几年了也没有系统的认识，如果是做业务为主的开发，如果自己没有意识主动学习，往往就是基本使用、用封装好的工具或框架而不加思索。 就着以前学习过的《JAVA并发编程》的知识整理了并发编程的基本知识点]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>JVM</tag>
        <tag>JAVA基础</tag>
        <tag>并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JAVA动态编译/解析文本的一种简易方法]]></title>
    <url>%2F2018%2F10%2F07%2FJAVA%E5%8A%A8%E6%80%81%E7%BC%96%E8%AF%91-%E8%A7%A3%E6%9E%90%E6%96%87%E6%9C%AC%E7%9A%84%E7%AE%80%E6%98%93%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[&ensp; &ensp; 追着国庆假期的尾巴，更新一下博客，讲一下项目上之前遇到的文本动态编译/解析的问题，虽然比较简单，但是感觉适合场景还是挺多的。&ensp; &ensp; 团队自研BI系统，在数据源选择及查询的实现使用桥接模式，针对不同的数据源采用不同的查询方式，而目前我们平台支持的数据源的查询可以通过构建不同的文本请求体进行查询，例如mysql、presto、ElasticSearch等。在这里对文本动态构建的实现方案进行讲述。&ensp; &ensp; 我们的源文本都是基于xml标签编写，起因是BI系统一开始是基于mybatis对mysql数据库进行DAO操作。举个栗子：12345678910&lt;select id=&quot;test&quot; parameterType=&quot;map&quot; resultType=&quot;java.util.HashMap&quot;&gt;select id from table_test where 1=1 &lt;if test=&quot;startTime != null and startTime != &apos;&apos;&quot;&gt; and sale_date &gt;= #&#123;startTime&#125; &lt;/if&gt; &lt;if test=&quot;endTime != null and endTime != &apos;&apos;&quot;&gt; and #&#123;endTime&#125; &gt;= sale_date &lt;/if&gt;&lt;/select&gt; &ensp; &ensp; 在这个基础上我们了解了mybatis的解析过程，使用mybatis的底层实现进行动态sql语句文本编译,其实原理就是利用mybatis的xml标签解析sql实现。&ensp; &ensp; xml动态文本编译/解析有多种方法，但是基于以上的情况，我们抽取了mybatis的boundsql编译过程用来构建我们的文本请求体12345678910111213 //使用mybatis编译逻辑标签 Document doc = DOMUtils.parseXMLDocument(query); XPathParser xPathParser = new XPathParser(doc, false); Node node = doc.getFirstChild(); XNode xNode = new XNode(xPathParser, node, null); XMLScriptBuilder xmlScriptBuilder = new XMLScriptBuilder(configuration, xNode); SqlSource sqlSource = xmlScriptBuilder.parseScriptNode(); BoundSql boundSql = sqlSource.getBoundSql(param);&ensp; &ensp; 通过boundSql.getSql()可以获取编译后的文本（configuration是mybatis的基础配置类，由于这里并不用到数据库请求，所以创建一个新的单例对象传入就可以），但是需要注意的是mybatis这种编译方式是用来编译prepare statment的，什么意思呢，就是使用mybatis的标签变量声明规则，即变量是#{var}这种声明方式，会被编译成问号占位符，如果不想这样可以自己制定变量规则进行替换，比如${var}123 boundSql.getSql().indexOf(&quot;$&quot;) &gt; 0 ? replaceVariables(boundSql.getSql(),param) : boundSql.getSql(); &ensp; &ensp; 到此我们的presto动态语句可以写成1234567891011 &lt;select id=&quot;test&quot; parameterType=&quot;map&quot; resultType=&quot;java.util.HashMap&quot;&gt;select bill_id,total from platform_data.t_sales_bill where 1=1 &lt;if test=&quot;startTime != null and startTime != &apos;&apos;&quot;&gt; and sale_date &gt;= cast(#&#123;startTime&#125; as timestamp) &lt;/if&gt; &lt;if test=&quot;endTime != null and endTime != &apos;&apos;&quot;&gt; and cast(#&#123;endTime&#125; as timestamp) &gt;= sale_date &lt;/if&gt;&lt;/select&gt; &ensp; &ensp; es的请求体可以写成1234567891011121314151617181920212223242526272829 &lt;query&gt;&#123; &quot;query&quot; : &#123; &quot;bool&quot;:&#123; &quot;filter&quot;:[ &lt;if test=&quot;agentCodes!=null&quot;&gt; &#123;&quot;match&quot; : &#123; &quot;agentCode&quot; : &quot;$&#123;agentCodes&#125;&quot;&#125; &#125;, &lt;/if&gt; &#123;&quot;range&quot; : &#123; &quot;saleDate&quot; : &#123;&quot;gte&quot;:&quot;$&#123;startTime&#125;&quot;,&quot;lte&quot;:&quot;$&#123;endTime&#125;&quot;&#125; &#125; &#125; ] &#125; &#125;, &quot;aggs&quot;:&#123; &quot;sales_number&quot;:&#123; &quot;terms&quot; : &#123; &quot;field&quot; : &quot;goodsId&quot;, &quot;order&quot;:&#123; &quot;salesNumber&quot;:&quot;desc&quot; &#125; &#125;, &quot;aggs&quot;:&#123; &quot;salesNumber&quot;:&#123;&quot;sum&quot;:&#123; &quot;field&quot;:&quot;salesNumber&quot; &#125; &#125;, &quot;salesTotal&quot;:&#123;&quot;sum&quot;:&#123; &quot;field&quot;:&quot;salesTotal&quot; &#125; &#125; &#125; &#125; &#125;, &quot;sort&quot;: &#123; &quot;salesNumber&quot;: &#123; &quot;order&quot;: &quot;desc&quot; &#125;&#125; &#125;&lt;/query&gt;&ensp; &ensp; 同理其它可以使用文本构建查询的数据源都可以支持，比如Hql,spark-sql,ksql等，再扩展也可以支持动态脚本。为我们自助查询平台和BI平台奠定了基础。&ensp; &ensp; 以上，说得比较简单，希望对看到的人可以有帮助。]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>java基础</tag>
        <tag>mybatis</tag>
        <tag>动态解析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[个人基于大数据平台的设计与思考]]></title>
    <url>%2F2018%2F08%2F19%2F%E4%B8%AA%E4%BA%BA%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E7%9A%84%E8%AE%BE%E8%AE%A1%E4%B8%8E%E6%80%9D%E8%80%83%2F</url>
    <content type="text"><![CDATA[背景介绍&ensp; &ensp; 本人是在一家TOB电商平台的创业公司就职，目前负责整个数据部门的架构与业务跟进。之前从事过YY与唯品会的web开发工作，也有了解到一些大数据架构相关的设计。&ensp; &ensp; 目前数据部门的技术架构发展大体方向已经确定得差不多，于是在此梳理一下设计思路、历程与将要实现的内容。 一开始都是坑&ensp; &ensp; 一开始的数据需求都是来源于生意运营的报表，我由负责电商app web转向数据开发，说实话，一开始做报表我心里是拒绝的，但是创业团队为了公司能活下去，什么活不得做。领着几个兄弟搭建了公司的”数据中心”，其实就是个报表系统。当时对hadoop,hive,spark,etl等技术及概念懵懵懂懂。 &ensp; &ensp; 很快我们发现，第一轮的坑来了，面临两个问题：一，报表需求多，小伙伴们整天在写sql，代码组合数据；二，数据量慢慢大起来，有些地方性能比较差，报表要查很久，有时候影响线上性能，线上出问题总要挨白眼。 &ensp; &ensp; 经过了解对比，我们毅然决定开始自研BI系统(参照superset功能设计)和开启我们的ETL架构设计与实现的开头，独立一套数据环境。其实当时我们心中还有点窃喜，终于可以接触高大上的hadoop全家桶了，选取的技术有hadoop、hive、spark、sqoop和shell脚本来实现我们的第一版数据流程。嗯，这才有点数据中心的样子。 &ensp; &ensp; 然而，跑了一段时间后，随着了解越多知识，才知道我们的情况有多糟糕，当时数据量不到100g，只有两台8核16G的机器（手动捂脸），离线任务依靠时间弱依赖，就算只有两台，运维起来也要花不少时间，sqoop在小数据量小集群的应用场景下性能真的很一般啊，渐渐感觉到这套架构对我们来说也许”太早了”。自研BI方面，很考验写sql的功力，虽然由此我们对mysql的sql编写技巧有很大提升，用了很多奇淫巧技，但是，我们的研发现在都花很多时间写sql啊，而且大家对数据不敏感，反正就是完成开发任务就得了。这段时间确实人心很不稳。。。当然很感谢那时坚持陪着我奋斗的小伙伴们。 初版架构如下: 有坑就要填思考、计划、实现与招聘，我们在1个月内重塑了整个交互流程。 数据通过爬虫、收集日志与第三方公司进行业务结合等方式慢慢积累起来 招来第一位数据分析师，并由他负责BI的输出与日常报表需求 申请多了几台机器资源 用azkaban替换shell脚本管理，正式接上任务流 使用datax替换sqoop hadoop、hive及spark主要用来做少量智能化的业务，大部分数据聚合逻辑回迁数据库 这样的数据流程立马解放了开发小伙伴的双手，去做更能体现价值的事情，而且报表输出的质量也大大提高了，机器资源也暂时足够，维护起来还不算特别麻烦。心里舒了一口气。 架构如下: 业务不断发展，坑坑更健康&ensp; &ensp; 这个时候我们的业务数据量已经超过100-200G之间，数据中心的数据量也300g左右，数据库中的中间表特别多。&ensp; &ensp; 现在已经好几位分析师，各自负责自己的需求，经常有数据打架的情况发生，而且制作报表很多依然用的业务源表，有性能问题就使用中间表。&ensp; &ensp; 业务应用越来越多对数据聚合服务有需求，我们都是通过RPC接口来对外服务提供服务,我们经常得深入业务逻辑去提供聚合服务，而且服务对象多，所有服务在数据库聚合，经常影响数据中心整体的服务质量，也出现过多次应用雪崩的情况。&ensp; &ensp; 业务也出现了实时反馈的产品需求 不断学习探研改造我们又再一次进行架构改造 接入otter实现业务数据实时同步 使用canal + kafka + kafka streams 实现实时数据变更订阅，提供实时聚合服务 开始设计自己的数据字典与数据仓库 采用微服务设计理念，使用spring cloud 架构如下: 就着这样节奏又走了一段日子 总是会有不如意的地方&ensp; &ensp; 此时我们的机器资源也只有近10台一般配置的节点，随着微服务越来越多，而且与其它大数据的工具平台共用，很快又到瓶颈，而且进程多维护起来也是麻烦。&ensp; &ensp; 数据团队的人员由于资源限制没有再新增，而业务缺越来越多需要支持，在生产力方面，数据处理环节明显成为瓶颈。&ensp; &ensp; 此时在数据聚合方面，我们采用了redis作为缓存，但是依然存在缓存击破的情况，导致数据库偶尔会锁表，即使我们已经主从读写分离。 像刀一样，越磨越亮我们在新的阶段探研了新的技术 使用ambari管理各种集群 探索数据流任务管理平台，对比了kettle，apache nifi和spring cloud data flow 研究能够快速检索数据且能够横向扩展的技术，如elasticsearch,kafka等 过往我们都是存储及计算一体，像我们对mysql,hive的应用就是典型的先把数据迁移到哪里再进行计算，所以我们也探研了计算分离的技术方案，最终采用presto 对于快速发展的创业公司来说好用才是王道，大家舒服才是王道&ensp; &ensp;我们的数据量始终没有达到TB级别，可预见如果业务没有新的发展方向，就当前的产品的数据增长速度来看，可以把我们要做的数据平台定义为“小数据量的大数据平台”，机器资源也只是近10台（我知道市场正常搞大数据的机器集群一般都有几十上百台，再次手动捂脸）。最终确定我们架构的方向: 使用otter实时同步我们所有业务数据到我们自己的数据库，减少离线同步的管理和资源成本 使用canal 监听自己数据库的所有表变化，程序同步序列化数据到kafka中，由业务方使用kafka streams自行订阅，实现业务逻辑 使用azkaban + datax + presto ，实现分布式计算，分离存储与计算环节，完成etl流程 最终离线数据落地elasticsearch 业务方通过数据平台进行数据需求的自满足及溯源 我们当前的架构如下(蓝色箭头为源头输出，红色箭头指向为输入，黄色箭头为溯源流向，黄色闪电为依存关系): 而最终稳定版的架构如下: 智能化的业务&ensp; &ensp;近来公司重点发展智能化业务，需要我们支持机器学习相关的算法模型实现及调优，目前还是处于使用python脚本的实现方式及azkaban进行任务训练及提供脚本给程序调用。一方面还不是分布式计算，当然我们也可以用spark解决这个问题，第二方面，支持不了实时训练的场景，虽然我们当前也还没有这种需求。目前这块还是架构规划当中，可能会比较倾向于使用tensorflow,后续有进展再更新。 感想&ensp; &ensp; 我始终没觉得自己是一个大数据开发人员，在我看来，web开发与数据开发同样是后端研发，只不过业务不同，使用的技术不同，然而很多研发的基础是一样。语言基础，高并发，大数据量，大吞吐量，分布式，高可用，模式设计，基础算法，调优，使用的工具掌握及理解像redis,zk,es,kafka,mysql这些，运维基础，前端基础，像这些我觉得都是应该掌握的。&ensp; &ensp; 面试过很多大数据的开发，从初级到高级。很多人都只关心一个问题，你们的数据量有多大，你们的集群有多大。我承认这些这两个“指标”确实能说明一些东西，但是对于我面试过的人来说，我的结论是，数据量的大小对于只是一个使用工具的人来说，其实并不重要，因为你也只是用，你从来不深究，为什么要这样设计，为什么要这样实现，有没有办法做得更好，你不了解原理，你不熟悉工具技术，反而看不起数据量小的业务场景，这会让人觉得不成熟。&ensp; &ensp; 当然我也是认为如果有机会接触真正的大量数据的场景，还是得尽量接触，在保证自己有不断提升的觉悟为前提去接触。面试过很多游戏通信行业的真正大数据量场景下的小伙伴，真的不得不提一句，你公司的业务场景只是一方面，不“用”起来，只是负责某个环节的加工还不深究，这样的开发真的不算是大数据研发啊。&ensp; &ensp; peace &amp; love]]></content>
      <categories>
        <category>设计</category>
      </categories>
      <tags>
        <tag>数据平台</tag>
        <tag>架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[天然苏打水市场的了解与分析]]></title>
    <url>%2F2018%2F08%2F14%2F%E5%A4%A9%E7%84%B6%E8%8B%8F%E6%89%93%E6%B0%B4%E5%B8%82%E5%9C%BA%E7%9A%84%E4%BA%86%E8%A7%A3%E4%B8%8E%E6%80%9D%E8%80%83%2F</url>
    <content type="text"><![CDATA[背景近来有个朋友找到我说拿到某品牌的天然苏打水广东省省级代理，问我得怎样开展工作及市场上的情况是怎么样的。12产品定价15元一支品牌方给出了一年一千万件，即八千万支的销量目标。 table td {text-align:center} table thead td {background:#73B1E0;color:#FFF;} table th {border:1}由于个人是在TO B电商平台工作（苦逼码农一个），就着自己的资源和能力稍微进行一下分析。目标是找出工作推进的方案和尽量找出市场数据以及判断这个销量kpi是否合理。 梳理步骤 了解市场竞品数据 了解一般水饮新品推广方法 了解行业高端专业人士对这个事件的看法 了解市场竞品数据找遍关系圈并没有任何可以了解到天然苏打水相关的线下渠道，于是只能针对线上电商平台先下手。挑选了天然苏打水销量量较大的平台的销量较好的四个产品进行对比。结果如下: 产品 产品单价 规格 活动 京东销量 天猫销量 品牌 产品卖点 产地 公司 公司旗下产品 公司官网 新闻备注 品牌故事 舒达源克东天然苏打水 9.5 550ml 买2送1（送6支400ml） 1.9w评价 2758 舒达源 世界三大冷矿泉之一 克东 黑龙江舒达饮品有限公司 单一产品不同规格 跳转 新闻1 中国国家田径队官方用水 活力恩克东天然苏打水 3.66 500ml 无 3.3w评价 4542(单价4.5) 活力恩 火山岩層精淬礦泉 克东 海昌國際股份有限公司（彰化縣秀水鄉） 主打5度C系列，销量情况一般 跳转 无 无 火山鸣泉克东天然苏打水 7.3 470ml 无 1.7w评价 3578 火山鸣泉 火山岩層精淬礦泉 克东 火山鸣泉生态科技有限公司 单一产品不同规格不同包装 跳转 新闻1 新闻2 中国田径队官方饮用水 水易方克东天然苏打水 7.1 500ml 买5送1 1.5w评价 537 水易方 常见天然苏打水特性 克东 大连水易方科技发展有限公司 单一产品不同规格不同包装 跳转 新闻 无 就这样看可以得到一些信息12345* 京东是现在最大的销售渠道，天猫第二（其它平台几乎没有销量所以没对比）* 天然苏打水线上市场并不乐观,如果按这数据来看，一年100w件的销量目标都很有挑战性* 国内最有知名度的天然苏打水产地应该是克东，如果非克东产地的苏打水估计比较难引起消费者共鸣* 产品形象及品牌故事在市场竞争中影响并不大，消费者可能更看重实惠程度* 基本没看到哪个天然苏打水产品有打广告，更多应该是参加电商平台的促销活动 基本上线上销售相关信息了解就到这了，但是感觉还不够，进而找了各大数据平台搜索相关报告，收集到资料如下: 网上评价中国十大苏打水企业http://www.china-10.com/china/1002sds_index.html 中国会员经济数据报告http://tech.qq.com/a/20170719/007724.htm#p=1 尼尔森数据线上线下结合销售数据资讯http://www.nielsen.com/cn/zh/press-room/2015/Nielsen-global-survey-on-e-commerce-and-new-retailing.html 百度指数http://index.baidu.com/?tpl=trend&amp;word=%CB%D5%B4%F2%CB%AE 腾讯BIhttp://tbi.tencent.com/index?word=苏打水&amp;date=1&amp;type=0 36kr关于高端水的观点http://36kr.com/p/5073894.html 3mbang文库http://www.3mbang.com/p-171349.html 百度文库https://wenku.baidu.com/view/adb970a03968011ca200911f.htmlhttps://wenku.baidu.com/view/64a25f0869eae009581becfb.htmlhttp://www.chinairn.com/news/20160705/150700863.shtml ps:苏打水市场研究报告 很多咨询网站都有做，但是哪里都要钱的，一份就要好几k大洋，要不起，还是靠自己吧。 基于网上的资料可以看出来苏打水在中国的市场热度有上升的趋势，但是不大，天然苏打水就更小了。 一般水饮新品推广方法我找了我们公司运营部门副总监W君请教了一下，他原本是从宝洁出来的，至今工作多年，从开始的市场人员转为运营人员。从与他的交流上我总结了一下代理商一般水饮新品的推广方法如下: KA(大型卖场)如沃尔玛、华润万家、永旺（吉之岛）等。 KA是最容易进行新品试验的地方。每个KA都有自己招商的标准，对进场的产品会有不同的要求，KA每个点（如广州天河分店等）也各自有自己的要求。一般想谈合作可以直接到联系总部或者分点对应负责人直接谈就行了。 这里假设能够满足要求并进场。合作的对象有两种，一种是直接找总部谈合作，这种方式会要求产品本身有足够强的优势，总公司才会考虑帮你铺点，而且一般找总部谈的整个流程比较长，但是一旦确定产品OK，能够大面积铺开，另一种是找某个KA的分点负责人谈，这种的门槛会比较低，但是产品流通只限于该门店，如果想再扩大市场只能自己重新去谈其它KA分点。 合作的方式有两种，一种是直接给钱进场，KA不管你销量，反正它有钱收，另一种是根据销量来进行利润分成，这种一般只会针对成熟的产品或者非常有潜力的产品。 走KA的公司的运营比较简单，只需要有人负责促销活动的规划，聘请对应的促销人员派到各大卖场进行促销活动就可以了。 然而KA渠道基本就是走量，利润空间比较小。 城市有能力的中间商如广州宝祺来，专门做日化渠道，能够快速铺货到各大KA卖场，合作方式得自己谈，基本是直接给钱合作的。 这个渠道会比直接找KA利润更低，因为有中间商赚差价嘛。但是铺货速度跟能力绝对是杠杠的。 特殊渠道带有特殊性质的饮品，如能量饮料、苏打水，都有一些特殊的渠道可以卖，这个渠道比较看重经营方即卖饮品的公司渠道能力。比如红牛可以铺货进网吧、各大运动场所等。这个渠道我也没有资源可以继续了解，只是知道，特殊渠道是毛利可以爆发的渠道。 中小超市士多基本上品牌代理商不会自己直接去铺小店，成本高，效益低。 专业人士意见我找了我们公司采购部副总监请教，他是一路从恒大、沃尔玛等大公司由基层做到高层的。沟通下来我总结有以下几点： 新品不能急着铺货，只要你产品OK，销售渠道是比较容易疏通的 确定好主打市场，目标人群 做好市场调研，可以采用问券调查等方式。如果真的不清晰怎么做，可以拜访其它省级代理，咨询下人家的情况与做法 商品本身的主打特性要宣传到位，假如商品本身有什么特别性质的，如真的可以治疗什么疾病或者产源稀缺，那定价高一样可以卖得火爆 特殊渠道在定位高端产品的渠道中比较重要，往往是有利可图的渠道 15元的高端水在市场很少见，至少这位哥是没见过，当时在恒大做恒大冰泉也是定价高昂，现在一样卖到跟普通差不多，正常渠道销量也一般。所以这个定价的水产品市场不好做 总结针对销量目标来说，天然苏打水新品一年一千万件即八千箱的省级销售目标，从运营和专业人士的角度来看，都是很难达到，结合线上数据来看，也更加能说明这点。合理的有挑战性的目标大概是一百万件左右。假如有特殊渠道另说，因为特殊渠道的量就看主营公司的能力了，不好预估。推广新品的方法上面已经提到，但是推广前需要确定好目标人群、商品的亮点、品牌故事与背景和渠道。如果不清楚怎么做，可以去其它省级代理了解咨询，如果有的话。 吐槽基本上KA或者平台级的公司不会管你产品好不好卖，都想你投钱进场，反正不好卖也不关他们的事。包括我们公司那采购副总监，一边说着感觉市场不好做，一边想让我朋友来找我们公司合作，笑哭，哈哈]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring cloud stream 基于kafka的使用简析]]></title>
    <url>%2F2018%2F08%2F11%2Fspring-cloud-stream-%E5%9F%BA%E4%BA%8Ekafka%E7%9A%84%E4%BD%BF%E7%94%A8%E7%AE%80%E6%9E%90%2F</url>
    <content type="text"><![CDATA[流式数据故名思义，即数据像开了小河里的流水般不停流动，除非水源出现问题，否则没有结束时间。流式数据在行业内已经有非常多针对不同应用量级的成熟方案，这里就不加以详述。本次主要介绍spring cloud stream 基于kafka对流式数据的基本应用。而使用spring cloud stream之前，可以先理解一下spring cloud对数据流程的几个概念，分别是source（生产数据者），processor(数据加工者), sink(最终结果处理者)。 准备工作项目基本框架:当然是基于maven构建的spring-boot最省心省力啦添加依赖:1234567891011121314151617&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-stream-binder-kafka-streams&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-stream-binder-kafka&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- 用于代码中的一些便捷注解 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.18.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt; 公共配置:1234567891011121314151617181920spring: cloud: kafka: streams: binder: brokers: localhost:9092 zk-nodes: localhost:2181 #2.0以上就不需要该配置 configuration: default: key: serde: org.apache.kafka.common.serialization.Serdes$StringSerde value: serde: org.apache.kafka.common.serialization.Serdes$StringSerde cache: max: bytes: buffering: 0 #所有线程可以用于缓存的最大字节数,达到多少数据量之后聚合一次流中的数据，设置为0则实时聚合 commit: interval: ms: 1000 #版本数据确认消费时间ack 我们来模拟用户页面访问记录流 声明binding相关信息添加接口AnalyticsBinding1234567891011121314151617181920public interface AnalyticsBinding &#123; String PAGE_VIEWS_OUT = &quot;pvout&quot;; String PAGE_VIEWS_IN = &quot;pvin&quot;; String PAGE_COUNT_MV = &quot;pcmv&quot;; String PAGE_COUNT_OUT = &quot;pcout&quot;; String PAGE_COUNT_IN = &quot;pcin&quot;; @Input(PAGE_VIEWS_IN) KStream&lt;String,PageViewEvent&gt; pageViewsIn(); @Output(PAGE_COUNT_OUT) KStream&lt;String,Long&gt; pageCountOut(); @Input(PAGE_COUNT_IN) KTable&lt;String,Long&gt; pageCountIn(); @Output(PAGE_VIEWS_OUT) MessageChannel pageViewsOut();&#125; 添加配置在application.yml中声明以下配置12345678910111213141516171819202122232425262728293031323334353637spring: cloud: stream: bindings: pvout: destination: pvst group: pvst producer: header-mode: raw pvin: destination: pvst group: pvst consumer: header-mode: raw pcout: destination: pcst group: pcst producer: use-native-encoding: true pcin: destination: pcst group: pcst content-type: application/json consumer: use-native-encoding: true header-mode: raw kafka: streams: bindings: pcout: producer: key-serde: org.apache.kafka.common.serialization.Serdes$StringSerde value-serde: org.apache.kafka.common.serialization.Serdes$LongSerde pcin: consumer: key-serde: org.apache.kafka.common.serialization.Serdes$StringSerde value-serde: org.apache.kafka.common.serialization.Serdes$LongSerde destination对应kafka中的主题。serde就是serialization和deserialization，针对流中的key和value都需要指定，默认使用default中配置的内容，也可以针对主题单独设置。 source创建每秒随机产生用户访问页面及停留时间的数据 先创建事件类1234567@Data@AllArgsConstructor@NoArgsConstructorpublic class PageViewEvent &#123; private String userId,page; private long duration;&#125; 生成数据的实现123456789101112131415161718192021222324252627282930313233@Slf4j@Component@EnableBinding(AnalyticsBinding.class)public class PageViewEventSource implements ApplicationRunner &#123; private final MessageChannel pageViewsOut; public PageViewEventSource(AnalyticsBinding binding) &#123; this.pageViewsOut = binding.pageViewsOut(); &#125; @Override public void run(ApplicationArguments applicationArguments) throws Exception &#123; List&lt;String&gt; names = Arrays.asList(&quot;jlong&quot;,&quot;dyser&quot;,&quot;shacko&quot;,&quot;abilan&quot;,&quot;ooasdf&quot;,&quot;grussell&quot;); List&lt;String&gt; pages = Arrays.asList(&quot;blog&quot;,&quot;sitemap&quot;,&quot;initializr&quot;,&quot;news&quot;,&quot;colophon&quot;,&quot;about&quot;); Runnable runnable = () -&gt; &#123; String rPage = pages.get(new Random().nextInt(pages.size())); String rName = names.get(new Random().nextInt(names.size())); PageViewEvent pageViewEvent = new PageViewEvent(rName,rPage,Math.random() &gt; .5?10:1000); Message&lt;PageViewEvent&gt; message = MessageBuilder.withPayload(pageViewEvent) .setHeader(KafkaHeaders.MESSAGE_KEY,pageViewEvent.getUserId().getBytes()) .build(); try &#123; this.pageViewsOut.send(message); log.info(&quot;sent&quot; + message.toString()); &#125; catch (Exception e)&#123; log.error(e.getMessage()); &#125; &#125;; Executors.newScheduledThreadPool(1).scheduleAtFixedRate(runnable,1,1, TimeUnit.SECONDS); &#125;&#125; processor获取到事件数据之后基于聚合处理，创建新的数据流123456789101112131415@Slf4j@Componentpublic class PageViewEventProcessor &#123; @StreamListener @SendTo(AnalyticsBinding.PAGE_COUNT_OUT) public KStream&lt;String,Long&gt; process( @Input(AnalyticsBinding.PAGE_VIEWS_IN) KStream&lt;String,PageViewEvent&gt; events)&#123; return events .map((key,value) -&gt; new KeyValue&lt;&gt;(value.getUserId() + &quot;-&quot; + value.getPage(),&quot;0&quot;)) .groupByKey() //.windowedBy(TimeWindows.of(1000*60)) .count(Materialized.as(AnalyticsBinding.PAGE_COUNT_MV)) .toStream(); &#125;&#125; windowedBy可以根据时间窗口进行聚合，用法请详见文档。 sink获取聚合后的结果进行处理123456789@Slf4j@Componentpublic class PageCountSink &#123; @StreamListener public void process(@Input(AnalyticsBinding.PAGE_COUNT_IN)KTable&lt;String,Long&gt; counts)&#123; counts.toStream().foreach((key,value) -&gt; log.info(&quot;PCIN -----:&quot; + key + &quot;=&quot; + value)); &#125;&#125; 至此一个从数据生产到结果消费的简单数据流处理就完成了 解析这个例子是基于spring cloud 完整的流数据处理，有source,processor,sink的概念是spring cloud data flow的设计理念，这里不展开阐述。processor环节非必需的，可以只有source和sink的实现。假如不需要进行流的处理，只需要消息内容，可以在@StreamListener的方法声明中不使用@Input声明，而是直接通过@StreamListener(主题名称)来进行监听，方法接收消息参数使用Message msg，如下: 123456789@StreamListener(Processor.INPUT) public void receive1(Message&lt;String&gt; msg)&#123; System.out.println(msg.getPayload()); //消息体 Acknowledgment acknowledgment = msg.getHeaders().get(KafkaHeaders.ACKNOWLEDGMENT, Acknowledgment.class); if (acknowledgment != null) &#123; System.out.println(&quot;Acknowledgment provided&quot;); acknowledgment.acknowledge();//手动ack &#125; &#125; 多流聚合在实际应用中不只存在单流数据的处理，也经常会遇到多流聚合处理。我们来添加多一种事件的实现，这里模拟销售数据。相关的实现如下 SalesEvent1234567@Data@AllArgsConstructor@NoArgsConstructorpublic class SalesEvent &#123; private String userId,goods; private int amount;&#125; SalesEventSource12345678910111213141516171819202122232425262728293031@Slf4j@Component@EnableBinding(AnalyticsBinding.class)public class SalesEventSource implements ApplicationRunner &#123; private final MessageChannel salesOut; public SalesEventSource(AnalyticsBinding binding) &#123; this.salesOut = binding.salesOut(); &#125; @Override public void run(ApplicationArguments applicationArguments) throws Exception &#123; List&lt;String&gt; names = Arrays.asList(&quot;jlong&quot;,&quot;dyser&quot;,&quot;shacko&quot;,&quot;abilan&quot;,&quot;ooasdf&quot;,&quot;grussell&quot;); List&lt;String&gt; goods = Arrays.asList(&quot;apple&quot;,&quot;oringe&quot;,&quot;banana&quot;,&quot;lemon&quot;,&quot;shit&quot;,&quot;book&quot;); Runnable runnable = () -&gt; &#123; String rGoods = goods.get(new Random().nextInt(goods.size())); String rName = names.get(new Random().nextInt(names.size())); SalesEvent salesEvent = new SalesEvent(rName,rGoods,Math.random() &gt; .5?5:10); Message&lt;SalesEvent&gt; message = MessageBuilder.withPayload(salesEvent) .setHeader(KafkaHeaders.MESSAGE_KEY,salesEvent.getUserId().getBytes()) .build(); try &#123; this.salesOut.send(message); log.info(&quot;sent&quot; + message.toString()); &#125; catch (Exception e)&#123; log.error(e.getMessage()); &#125; &#125;; Executors.newScheduledThreadPool(1).scheduleAtFixedRate(runnable,1,1, TimeUnit.SECONDS); &#125;&#125; SalesEventProcessor123456789101112131415@Slf4j@Component@EnableBinding(AnalyticsBinding.class)public class SalesEventProcessor &#123; @StreamListener @SendTo(AnalyticsBinding.SALES_COUNT_OUT) public KStream&lt;String,Long&gt; process(@Input(AnalyticsBinding.SALES_IN)KStream&lt;String,SalesEvent&gt; events)&#123; return events .map((key,value) -&gt; new KeyValue&lt;&gt;(value.getUserId() + &quot;-&quot; + value.getGoods(),&quot;0&quot;)) .groupByKey() //.windowedBy(TimeWindows.of(1000*60)) .count(Materialized.as(AnalyticsBinding.SALES_COUNT_MV)) .toStream(); &#125;&#125; SaleCountSink123456789101112131415161718@Slf4j@Component@EnableBinding(AnalyticsBinding.class)public class SaleCountSink &#123; @StreamListener public void process(@Input(AnalyticsBinding.SALES_COUNT_IN)KTable&lt;String,Long&gt; salesCounts, @Input(AnalyticsBinding.PAGE_COUNT_IN)KTable&lt;String,Long&gt; pageCounts)&#123; salesCounts.toStream().map((k,v) -&gt; new KeyValue&lt;&gt;(k.split(&quot;-&quot;)[0],k.split(&quot;-&quot;)[1] + &quot;-&quot; + v)) .join(pageCounts.toStream().map((k,v) -&gt; &#123; System.out.println(&quot;-------&quot; + k +&quot; : &quot; + v ); return new KeyValue&lt;&gt;(k.split(&quot;-&quot;)[0],k.split(&quot;-&quot;)[1] + &quot;-&quot; + v);&#125;), (v1, v2) -&gt; v1 + &quot;:&quot; + v2, JoinWindows.of(10000) ) .foreach((k,v) -&gt; System.out.println(k+ &quot;---&quot; + v)); &#125;&#125; 注意：同个应用中对同个流的监听实例只能有一个，SaleCountSink使用了@Input(AnalyticsBinding.PAGE_COUNT_IN)KTable&lt;String,Long&gt;与PageCountSink有冲突，要嘛把PageCountSink中的监听去掉，要嘛重命名其中一个相关的监听配置 AnalyticsBinding 完整代码12345678910111213141516171819202122232425262728293031323334353637public interface AnalyticsBinding &#123; String PAGE_VIEWS_OUT = &quot;pvout&quot;; String PAGE_VIEWS_IN = &quot;pvin&quot;; String PAGE_COUNT_MV = &quot;pcmv&quot;; String PAGE_COUNT_OUT = &quot;pcout&quot;; String PAGE_COUNT_IN = &quot;pcin&quot;; String SALES_OUT = &quot;salesout&quot;; String SALES_IN = &quot;salesin&quot;; String SALES_COUNT_MV = &quot;scmv&quot;; String SALES_COUNT_OUT = &quot;scout&quot;; String SALES_COUNT_IN = &quot;scin&quot;; @Input(PAGE_VIEWS_IN) KStream&lt;String,PageViewEvent&gt; pageViewsIn(); @Output(PAGE_COUNT_OUT) KStream&lt;String,Long&gt; pageCountOut(); @Input(PAGE_COUNT_IN) KTable&lt;String,Long&gt; pageCountIn(); @Output(PAGE_VIEWS_OUT) MessageChannel pageViewsOut(); @Output(SALES_OUT) MessageChannel salesOut(); @Input(SALES_IN) KStream&lt;String,SalesEvent&gt; salesIn(); @Output(SALES_COUNT_OUT) KStream&lt;String,Long&gt; salesCountOut(); @Input(SALES_COUNT_IN) KTable&lt;String,Long&gt; salesCountIn();&#125; application.yml完整配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990server: port: 8388spring: application: name: input-demo cloud: instance-count: 1 instance-index: 0 stream: bindings: pvout: destination: pvst group: pvst producer: header-mode: raw pvin: destination: pvst group: pvst consumer: header-mode: raw pcout: destination: pcst group: pcst producer: use-native-encoding: true pcin: destination: pcst group: pcst content-type: application/json consumer: use-native-encoding: true header-mode: raw salesout: destination: sost group: sost producer: header-mode: raw salesin: destination: sost group: sost consumer: header-mode: raw scout: destination: scst group: scst producer: use-native-encoding: true scin: destination: scst group: scst content-type: application/json consumer: use-native-encoding: true header-mode: raw kafka: streams: binder: configuration: default: key: serde: org.apache.kafka.common.serialization.Serdes$StringSerde value: serde: org.apache.kafka.common.serialization.Serdes$StringSerde cache: max: bytes: buffering: 0 commit: interval: ms: 1000 brokers: localhost:9092 zk-nodes: localhost:2181 bindings: pcout: producer: key-serde: org.apache.kafka.common.serialization.Serdes$StringSerde value-serde: org.apache.kafka.common.serialization.Serdes$LongSerde pcin: consumer: key-serde: org.apache.kafka.common.serialization.Serdes$StringSerde value-serde: org.apache.kafka.common.serialization.Serdes$LongSerde scout: producer: key-serde: org.apache.kafka.common.serialization.Serdes$StringSerde value-serde: org.apache.kafka.common.serialization.Serdes$LongSerde scin: consumer: key-serde: org.apache.kafka.common.serialization.Serdes$StringSerde value-serde: org.apache.kafka.common.serialization.Serdes$LongSerde 多流合并的理念是把流两两之间的key处理成一样进行join处理，join的实现方法大家可以自行阅读文档。如果是三个流以上，需要先将两个流合并之后生成一个流再与第三流合并处理。 相关文档 spring cloud data flow spring cloud stream spring cloud stream kafka streams应用官方视频讲解 KTable与KStream的关系 kafka官方文档 kafka streams window的概念翻译版 kafka权威指南]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>实时流</tag>
        <tag>spring</tag>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[内存与JVM]]></title>
    <url>%2F2018%2F07%2F23%2F%E5%86%85%E5%AD%98%E4%B8%8EJVM%2F</url>
    <content type="text"><![CDATA[自己一边看书一边实践一边整理下来的知识思维导向图，个人感觉能够掌握自动内存管理机制、高效并发并加以应用，理解虚拟机执行子系统、程序编译与代码优化，才可以说熟悉JVM。]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>java基础</tag>
        <tag>JVM</tag>
        <tag>内存</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zk分布式任务队列交互设计]]></title>
    <url>%2F2018%2F07%2F22%2Fzk%E5%88%86%E5%B8%83%E5%BC%8F%E4%BB%BB%E5%8A%A1%E9%98%9F%E5%88%97%E4%BA%A4%E4%BA%92%E8%AE%BE%E8%AE%A1%2F</url>
    <content type="text"><![CDATA[项目地址：https://github.com/super-sean/task-pipeline 背景近来公司业务上越来越多的跨进程比较耗时计算的场景出现，想用异步通信来解决长时间资源占用及等待问题，而基于多方的探讨，不考虑采用mina和netty这种异步通信的框架，最后决定使用zookeeper来实现 目的异步进行耗时较长的复杂计算请求，可随时获取请求执行进度 实现思路 将这种请求的发起者当作是请求任务的生产者，每个请求其实就是一个计算任务。 后端接收请求的服务就是消费者，获得请求之后进行计算，并更新计算进度。 当任务完成时，请求发起者可以通过监听任务状态回调实现自己的逻辑。 过程中，请求发起者也可以主动获取计算讲求的进度。 实现设计基于实现思路，设计zk的path结构如下 /master为程序高可用实现预留路径 /apps为业务连接节点，底下结构为/app/node，比如你有个业务叫a,有两个业务节点b1和b2，那就有/a/b1和/a/b2 路径。由业务节点启动时注册 /workers底下结构逻辑与/apps一致，只不过节点为服务端的节点，由服务端节点启动时注册 /tasks由业务提交注册的计算任务,以业务区分目录，以app-node-timestamp格式来命名taskid,每个节点拥有params,status和result三个节点 params 为请求参数，以文本格式存储，例如可以使用json格式传输 status 为task状态，默认有submit,running,done,noworker（无计算服务）,missapp（app节点断线）,consumed（已消费），resubmit（重分配）几种状态，worker可以添加自定义中间过程状态，任务提交时默认为submit状态。 result 为初始不存在，当status变更为done时添加，内容为文本格式，例如可以使用json，包括type和value,先只支持两种，第一种为直接返回为{“type”:”content”,”value”:”something”},考虑zk单个节点的容量问题，可能返回较大数据量，使用redis作为结果缓存层，返回{“type”:”redis_key”,”value”:”one redis key”} 当然不用redis也行，当数据量更大的时候可使用其它工具，这里先选用redis history目录下为完成的任务，定时持久化清理。 /assign由系统根据业务app分配作业给worker，以node-taskid来标识作业history目录下为执行完的作业，定时持久化清理 模块设计 调度系统 实现基于zk的路径交互，负责与业务和服务两端交互 业务端接口包封装 对于业务端来说，只需要提交服务端接口标识，接口参数之后返回taskId,根据需要通过taskId进行结果回调监听，支持查询task状态，需要屏蔽底层操作，透明化复杂操作。 服务端接口包封装 对于服务端来说，只需要继承某个类，声明服务标识，实现监听task队列的方法，处理被推送过来的任务，并根据需要更新自定义task状态，处理完成后在方法选择返回的内容类型即可 流程设计正常交互流程(由于用的uml画图工具问题，画得不是很规范，见谅…)正常交互流程worker断线重新分配任务流程 核心模块类图基本操作都抽象成名为operation的类，基于不同角色做扩展，目前情况如下baseOperation为zk的基本操作，operation为倾向原子性业务操作，分角色扩展的operation如serverOperation为封装角色实现本身的组合操作监听器主要有以下监听器实现每个角色都是基于以上两个核心模块加以逻辑处理来实现自己的功能 其它相关设计Task分发策略worker每当被分发task，便权重添加1，处理完则减1分发Task时选择权重最小的节点若权重都一样，则选择第一个节点 server主从实现使用curator包的LeaderLatch zk path acl权限管理使用三个角色，tp_server,tp_worker,tp_app目前没有做细粒度控制，只是tp_server创建的给另外两个角色授权，tp_worker创建的给tp_server授权，tp_app创建的给tp_server授权]]></content>
      <categories>
        <category>设计</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>zookeeper</tag>
        <tag>队列</tag>
      </tags>
  </entry>
</search>
