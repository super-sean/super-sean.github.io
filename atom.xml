<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Sean&#39;s Blog</title>
  
  <subtitle>随性随心</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://super-sean.github.io/"/>
  <updated>2019-05-15T09:22:34.708Z</updated>
  <id>https://super-sean.github.io/</id>
  
  <author>
    <name>Sean</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>基于solr服务提供通用配置化接口服务</title>
    <link href="https://super-sean.github.io/2019/05/15/%E5%9F%BA%E4%BA%8Esolr%E6%9C%8D%E5%8A%A1%E6%8F%90%E4%BE%9B%E9%80%9A%E7%94%A8%E9%85%8D%E7%BD%AE%E5%8C%96%E6%8E%A5%E5%8F%A3%E6%9C%8D%E5%8A%A1/"/>
    <id>https://super-sean.github.io/2019/05/15/基于solr服务提供通用配置化接口服务/</id>
    <published>2019-05-15T06:24:00.000Z</published>
    <updated>2019-05-15T09:22:34.708Z</updated>
    
    <content type="html"><![CDATA[<h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>&ensp; &ensp;&ensp; &ensp;公司内部有基于solr搜索平台服务，在做需求的过程中，对接了搜索平台，发现可以将搜索平台的交互抽象并使用配置化的方式进行数据请求，这样一来，可以通过配置化的方式达到数据查询需求的快速实现，提高开发效率，于是进行了技术方案的设计与评估。  </p><h3 id="技术方案"><a href="#技术方案" class="headerlink" title="技术方案"></a>技术方案</h3><h4 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h4><img src="/2019/05/15/基于solr服务提供通用配置化接口服务/architecture.png" title="architecture">  <h4 id="时序图"><a href="#时序图" class="headerlink" title="时序图"></a>时序图</h4><img src="/2019/05/15/基于solr服务提供通用配置化接口服务/sequence.png" title="sequence">  <h4 id="类图"><a href="#类图" class="headerlink" title="类图"></a>类图</h4><img src="/2019/05/15/基于solr服务提供通用配置化接口服务/class_diagram.png" title="class_diagram">  <h4 id="配置模板"><a href="#配置模板" class="headerlink" title="配置模板"></a>配置模板</h4><img src="/2019/05/15/基于solr服务提供通用配置化接口服务/config_model.png" title="config_model">  <h3 id="项目落地情况"><a href="#项目落地情况" class="headerlink" title="项目落地情况"></a>项目落地情况</h3><p>&ensp; &ensp;&ensp; &ensp;经过一个3天快速开发及2天自测，开发好了第一个版本，service+http服务，不带可视化配置支持，紧接着对接了一个新需求，有直接对接http接口的，也有对接service的，在对接过程中情况如下  </p><h4 id="好处-优点"><a href="#好处-优点" class="headerlink" title="好处/优点"></a>好处/优点</h4><ul><li>业务服务不用多次对接数据源层的实现，可以做到只要导入数据即可通过通用接口查询，节省调试的时间</li><li>因为配置化，支持热变更，快速调整入参及结果，节省联调时间</li><li>添加通用额外业务实体关联配置支持扩展源数据  </li><li>最大的好处直接提供配置即可提供http接口，无需开发</li><li>配置模板一般比较简单，复杂需求才有可能会稍微比较复杂  </li></ul><h4 id="坏处-缺点"><a href="#坏处-缺点" class="headerlink" title="坏处/缺点"></a>坏处/缺点</h4><ul><li>前期服务还未完善前，联调链变长，会有在业务开发和搜索平台中间多一层服务需要调试的错觉</li><li>基于solr本身的特点，在数据分页的方式上会有特殊要求，是基于游标滚动的形式翻页，导致前端需要支持多一种分页查询的方法  </li><li>还不能支持过于复杂的聚合查询,比如group by 字段A ,聚合查询count(带条件 字段B) 这样的查询目前还支持不了，只能支持group by 字段A ，count(B的各种值)，比如按分类（字段A）的聚合后推荐状态为1(字段B)的个数这样的支持不了，但是可以支持按分类（字段A）的聚合后不同推荐状态(字段B)的个数  </li><li>目前还没有可视化的配置支持，接口一但多起来便会很难管理  </li><li>业务如果对通用接口做熔断，只能涉及到的操作都统一处理，除非可以做到按参数熔断，公司目前的熔断器还不支持  </li><li>solr的数据更新延迟问题  <h4 id="感想"><a href="#感想" class="headerlink" title="感想"></a>感想</h4>&ensp; &ensp;&ensp; &ensp;看起来貌似问题多多，但是好处的吸引力很大，而且遇到的问题貌似并没有不可解决的</li></ul><h3 id="项目计划"><a href="#项目计划" class="headerlink" title="项目计划"></a>项目计划</h3><ul><li>支持可视化配置，区分业务模块及api Id,后期支持对业务及api id限流</li><li>支持dataset的缓存策略配置</li><li>结合前端，可自研BI系统，这样连前端的后台活动类开发工作都可以减少</li><li>支持修改更新配置操作，支持事务操作  </li><li>支持不同数据源</li></ul><h3 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h3><p>&ensp; &ensp;&ensp; &ensp;查询某个集合的原始字段,通过stat_date_s及nj_id_l两个字段过滤及自定义排序<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">&quot;id&quot;:xxx,</span><br><span class="line">&quot;key&quot;:&quot;xxx&quot;,</span><br><span class="line">&quot;searchToken&quot;:&quot;xxx&quot;,</span><br><span class="line">&quot;type&quot;:&quot;list&quot;,</span><br><span class="line">&quot;fields&quot;:[</span><br><span class="line">],</span><br><span class="line">&quot;queries&quot;:[</span><br><span class="line"> &#123;&quot;fieldName&quot;:&quot;stat_date_s&quot;,&quot;type&quot;:&quot;mix&quot;&#125;,</span><br><span class="line"> &#123;&quot;fieldName&quot;:&quot;nj_id_l&quot;,&quot;type&quot;:&quot;field&quot;&#125; </span><br><span class="line">],</span><br><span class="line">&quot;sorts&quot;:[</span><br><span class="line"> &#123;&quot;fieldName&quot;:&quot;nj_id_l&quot;,&quot;type&quot;:&quot;asc&quot;&#125;,</span><br><span class="line">&#123;&quot;fieldName&quot;:&quot;stat_date_s&quot;,&quot;type&quot;:&quot;asc&quot;&#125;</span><br><span class="line">],</span><br><span class="line"> &quot;facets&quot;:&#123;&#125;,</span><br><span class="line"> &quot;extInfo&quot;:[ </span><br><span class="line"> ],</span><br><span class="line"> &quot;fieldValueTransfer&quot;:[</span><br><span class="line"> ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure> </p><p>&ensp; &ensp;&ensp; &ensp;复杂一点的列表查询<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">&quot;id&quot;:xxx,</span><br><span class="line">&quot;key&quot;:&quot;xxx&quot;,</span><br><span class="line">&quot;searchToken&quot;:&quot;xxx&quot;,</span><br><span class="line">&quot;type&quot;:&quot;list&quot;,</span><br><span class="line">&quot;fields&quot;:[</span><br><span class="line">&#123;&quot;fieldName&quot;:&quot;id&quot;,&quot;alias&quot;:&quot;recordId&quot;&#125;,</span><br><span class="line">&#123;&quot;fieldName&quot;:&quot;nj_id_l&quot;,&quot;alias&quot;:&quot;anchorId&quot;&#125;,</span><br><span class="line">...</span><br><span class="line">],</span><br><span class="line">&quot;queries&quot;:[</span><br><span class="line"> &#123;&quot;fieldName&quot;:&quot;stat_date_s&quot;,&quot;alias&quot;:&quot;statDate&quot;,&quot;type&quot;:&quot;field&quot;&#125;,</span><br><span class="line"> ... </span><br><span class="line">],</span><br><span class="line">&quot;sorts&quot;:[</span><br><span class="line"> &#123;&quot;fieldName&quot;:&quot;nj_id_l&quot;,&quot;type&quot;:&quot;asc&quot;&#125;</span><br><span class="line">],</span><br><span class="line"> &quot;facets&quot;:&#123;&#125;,</span><br><span class="line"> &quot;extInfo&quot;:[</span><br><span class="line"> &#123;</span><br><span class="line"> &quot;connectFieldName&quot;:&quot;anchorId&quot;,</span><br><span class="line"> &quot;type&quot;:&quot;user&quot;,</span><br><span class="line"> &quot;field&quot;:[</span><br><span class="line"> &#123;&quot;fieldName&quot;:&quot;name&quot;&#125;,</span><br><span class="line"> &#123;&quot;fieldName&quot;:&quot;thumb&quot;&#125; </span><br><span class="line"> ]</span><br><span class="line"> &#125;</span><br><span class="line"> ],</span><br><span class="line"> &quot;fieldValueTransfer&quot;:[</span><br><span class="line"> &#123;</span><br><span class="line"> &quot;fieldName&quot;:&quot;anchorGroup&quot;,</span><br><span class="line"> &quot;items&quot;:[</span><br><span class="line"> &#123;&quot;og&quot;:&quot;xxx主播&quot;,&quot;biz&quot;:0&#125;,</span><br><span class="line"> &#123;&quot;og&quot;:&quot;xxxx主播&quot;,&quot;biz&quot;:1&#125; </span><br><span class="line">            ]</span><br><span class="line"> &#125;</span><br><span class="line"> ]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">//看下http接口的请求及返回  </span><br><span class="line">参数</span><br><span class="line">&#123;</span><br><span class="line">&quot;statDate&quot;:&quot;2019-05-07T00:00:00Z&quot;,</span><br><span class="line">&quot;regTime&quot;:&#123;&quot;start&quot;:&quot;2013-07-30&quot;,&quot;end&quot;:&quot;2013-08-30&quot;&#125;,    </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">返回</span><br><span class="line">&#123;</span><br><span class="line">  &quot;code&quot;: 0,</span><br><span class="line">  &quot;data&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;anchorIndex&quot;: xxx,</span><br><span class="line">      &quot;replayCountDaily&quot;: 0,</span><br><span class="line">      &quot;anchorCover&quot;: &quot;xxx&quot;,</span><br><span class="line">      &quot;hasPay&quot;: xx,</span><br><span class="line">      &quot;fansCount&quot;: xxx,</span><br><span class="line">      &quot;anchorGroup&quot;: &quot;&quot;,</span><br><span class="line">      &quot;source&quot;: &quot;&quot;,</span><br><span class="line">      &quot;anchorId&quot;: xxx,</span><br><span class="line">      &quot;anchorName&quot;: &quot;xxx&quot;,</span><br><span class="line">      &quot;anchorLevel&quot;: &quot;xxx&quot;,</span><br><span class="line">      &quot;recordId&quot;: &quot;xxx&quot;,</span><br><span class="line">      &quot;regTime&quot;: &quot;xxx&quot;,</span><br><span class="line">      &quot;anchorCategory&quot;: &quot;xxx&quot;,</span><br><span class="line">      &quot;replayCount&quot;: 0,</span><br><span class="line">      &quot;voiceCount&quot;: xxx,</span><br><span class="line">      &quot;replayCountWeekly&quot;: 0,</span><br><span class="line">      &quot;band&quot;: xxx,</span><br><span class="line">      &quot;lived&quot;: 0,</span><br><span class="line">      &quot;recommendStatus&quot;: &quot;&quot;,</span><br><span class="line">      &quot;lastUpdateTime&quot;: &quot;xxx&quot;,</span><br><span class="line">      &quot;firstVoiceTime&quot;: &quot;xxx&quot;</span><br><span class="line">    &#125;,...</span><br><span class="line">  ],</span><br><span class="line">  &quot;msg&quot;: &quot;OK&quot;,</span><br><span class="line">  &quot;page&quot;: &#123;</span><br><span class="line">    &quot;cursor&quot;: &quot;xxx&quot;,</span><br><span class="line">    &quot;isLastPage&quot;: true,</span><br><span class="line">    &quot;pageSize&quot;: 30,</span><br><span class="line">    &quot;totalCount&quot;: 13,</span><br><span class="line">    &quot;type&quot;: &quot;cursor&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure> </p><p>&ensp; &ensp;&ensp; &ensp;聚合查询<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">&quot;id&quot;: xxx,</span><br><span class="line">&quot;key&quot;: &quot;xxx&quot;,</span><br><span class="line">&quot;searchToken&quot;: &quot;xxx&quot;,</span><br><span class="line">&quot;type&quot;: &quot;agg&quot;,</span><br><span class="line">&quot;fields&quot;: [],</span><br><span class="line">&quot;queries&quot;: [&#123;</span><br><span class="line">&quot;fieldName&quot;: &quot;stat_date_s&quot;,</span><br><span class="line">&quot;alias&quot;: &quot;statDate&quot;,</span><br><span class="line">&quot;type&quot;: &quot;field&quot;</span><br><span class="line">&#125;,</span><br><span class="line">&#123;</span><br><span class="line">&quot;fieldName&quot;: &quot;user_type_ti&quot;,</span><br><span class="line">&quot;alias&quot;: &quot;userType&quot;,</span><br><span class="line">&quot;type&quot;: &quot;field&quot;</span><br><span class="line">&#125;</span><br><span class="line">],</span><br><span class="line">&quot;sorts&quot;: [],</span><br><span class="line">&quot;facets&quot;: &#123;</span><br><span class="line">&quot;groupByFieldName&quot;: &quot;xxxx&quot;,</span><br><span class="line">&quot;groupByFieldAlias&quot;: &quot;xxxx&quot;,</span><br><span class="line">&quot;alias&quot;: [&#123;</span><br><span class="line">&quot;fieldName&quot;: &quot;status_0_count&quot;,</span><br><span class="line">&quot;alias&quot;: &quot;recommendCount&quot;</span><br><span class="line">&#125;,</span><br><span class="line">&#123;</span><br><span class="line">&quot;fieldName&quot;: &quot;status_1_count&quot;,</span><br><span class="line">&quot;alias&quot;: &quot;forbiddenCount&quot;</span><br><span class="line">&#125;</span><br><span class="line">],</span><br><span class="line">&quot;items&quot;: [&#123;</span><br><span class="line">&quot;type&quot;: &quot;agg&quot;,</span><br><span class="line">&quot;fieldName&quot;: &quot;status_s&quot;,</span><br><span class="line">&quot;aggName&quot;: &quot;status&quot;</span><br><span class="line">&#125;]</span><br><span class="line">&#125;,</span><br><span class="line">&quot;extInfo&quot;: []</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">http请求无参数,返回结果</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">  &quot;code&quot;: 0,</span><br><span class="line">  &quot;data&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;anchorClassTotal&quot;: xxx,</span><br><span class="line">      &quot;anchorClass&quot;: &quot;xxx&quot;,</span><br><span class="line">      &quot;noStatusCount&quot;: xxx</span><br><span class="line">    &#125;,...</span><br><span class="line">  ],</span><br><span class="line">  &quot;msg&quot;: &quot;OK&quot;,</span><br><span class="line">  &quot;page&quot;: &#123;</span><br><span class="line">    &quot;cursor&quot;: &quot;xxx&quot;,</span><br><span class="line">    &quot;isLastPage&quot;: false,</span><br><span class="line">    &quot;pageNo&quot;: 0,</span><br><span class="line">    &quot;pageSize&quot;: 30,</span><br><span class="line">    &quot;totalCount&quot;: xxx,</span><br><span class="line">    &quot;type&quot;: &quot;pagination&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure> </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h3&gt;&lt;p&gt;&amp;ensp; &amp;ensp;&amp;ensp; &amp;ensp;公司内部有基于solr搜索平台服务，在做需求的过程中，对接了搜索平台，发现可以将搜索平台
      
    
    </summary>
    
      <category term="设计" scheme="https://super-sean.github.io/categories/%E8%AE%BE%E8%AE%A1/"/>
    
    
      <category term="数据平台" scheme="https://super-sean.github.io/tags/%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0/"/>
    
      <category term="架构" scheme="https://super-sean.github.io/tags/%E6%9E%B6%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>long-gc案例分析</title>
    <link href="https://super-sean.github.io/2019/05/04/long-gc%E6%A1%88%E4%BE%8B%E5%88%86%E6%9E%90/"/>
    <id>https://super-sean.github.io/2019/05/04/long-gc案例分析/</id>
    <published>2019-05-04T09:41:00.000Z</published>
    <updated>2019-05-15T02:40:21.585Z</updated>
    
    <content type="html"><![CDATA[<h3 id="long-gc优化"><a href="#long-gc优化" class="headerlink" title="long gc优化"></a>long gc优化</h3><p>&ensp; &ensp;&ensp; &ensp;近来发现负责研发的项目总是会收到long-gc的告警，比如：  </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">major GC: - 2 (No GC) start: 2019-05-06 06:18:47.678, end: 2019-05-06 06:18:53.125 </span><br><span class="line">[Par Survivor Space] init:209664K; used:19.7%(41348K) -&gt; 19.7%(41348K); committed: 100.0%(209664K) -&gt; 100.0%(209664K) </span><br><span class="line">[Code Cache] init:2496K; used:19.7%(48450K) -&gt; 19.7%(48430K); committed: 19.9%(49088K) -&gt; 19.9%(49088K) </span><br><span class="line">[Compressed Class Space] init:0K; used:0.7%(7721K) -&gt; 0.7%(7721K); committed: 0.7%(8040K) -&gt; 0.7%(8040K) </span><br><span class="line">[Metaspace] init:0K; used:68569K -&gt; 68574K); committed: 69932K -&gt; 69932K) </span><br><span class="line">[Par Eden Space] init:1677824K; used:57.3%(961524K) -&gt; 59.6%(1001110K); committed: 100.0%(1677824K) -&gt; 100.0%(1677824K) </span><br><span class="line">[CMS Old Gen] init:1048576K; used:23.8%(250428K) -&gt; 13.4%(140549K); committed: 100.0%(1048576K) -&gt; 100.0%(1048576K) </span><br><span class="line">duration:5447ms, throughput:99.9% </span><br><span class="line"></span><br></pre></td></tr></table></figure> <p>&ensp; &ensp;&ensp; &ensp;可以直接看到用的parnew + cms的收集器组合,也能看得出来主要回收行为发生在 old gen，所以就提取gc的日志来看，如下:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">2019-05-06T06:18:47.678+0800: 16712.771: [GC (CMS Initial Mark) [1 CMS-initial-mark: 250428K(1048576K)] 1253301K(2936064K), 0.0643432 secs] [Times: user=1.12 sys=0.00, real=0.06 secs]</span><br><span class="line">2019-05-06T06:18:47.742+0800: 16712.836: Total time for which application threads were stopped: 0.0655335 seconds, Stopping threads took: 0.0001332 seconds</span><br><span class="line">2019-05-06T06:18:47.742+0800: 16712.836: [CMS-concurrent-mark-start]</span><br><span class="line">2019-05-06T06:18:47.820+0800: 16712.913: [CMS-concurrent-mark: 0.077/0.077 secs] [Times: user=0.41 sys=0.00, real=0.07 secs]</span><br><span class="line">2019-05-06T06:18:47.820+0800: 16712.913: [CMS-concurrent-preclean-start]</span><br><span class="line">2019-05-06T06:18:47.831+0800: 16712.924: [CMS-concurrent-preclean: 0.010/0.011 secs] [Times: user=0.01 sys=0.00, real=0.01 secs]</span><br><span class="line">2019-05-06T06:18:47.831+0800: 16712.924: [CMS-concurrent-abortable-preclean-start]</span><br><span class="line">2019-05-06T06:18:49.745+0800: 16714.839: Total time for which application threads were stopped: 0.0014635 seconds, Stopping threads took: 0.0001513 seconds</span><br><span class="line"> CMS: abort preclean due to time </span><br><span class="line">2019-05-06T06:18:52.845+0800: 16717.939: [CMS-concurrent-abortable-preclean: 4.912/5.014 secs] [Times: user=5.40 sys=0.83, real=5.02 secs]</span><br><span class="line">2019-05-06T06:18:52.846+0800: 16717.940: [GC (CMS Final Remark) [YG occupancy: 1042070 K (1887488 K)]</span><br><span class="line">2019-05-06T06:18:52.847+0800: 16717.940: [Rescan (parallel) , 0.1073388 secs]</span><br><span class="line">2019-05-06T06:18:52.954+0800: 16718.047: [weak refs processing, 0.0108072 secs]</span><br><span class="line">2019-05-06T06:18:52.965+0800: 16718.058: [class unloading, 0.0341564 secs]2019-05-06T06:18:52.999+0800: 16718.092: [scrub symbol table, 0.0079842 secs]</span><br><span class="line">2019-05-06T06:18:53.007+0800: 16718.100: [scrub string table, 0.0021272 secs][1 CMS-remark: 250428K(1048576K)] 1292498K(2936064K), 0.1678019 secs] [Times: user=1.54 sys=0.00, real=0.17 secs]</span><br><span class="line">2019-05-06T06:18:53.014+0800: 16718.108: Total time for which application threads were stopped: 0.1689968 seconds, Stopping threads took: 0.0001364 seconds</span><br><span class="line">2019-05-06T06:18:53.015+0800: 16718.108: [CMS-concurrent-sweep-start]</span><br><span class="line">2019-05-06T06:18:53.125+0800: 16718.219: [CMS-concurrent-sweep: 0.111/0.111 secs] [Times: user=0.13 sys=0.03, real=0.11 secs]</span><br><span class="line">2019-05-06T06:18:53.125+0800: 16718.219: [CMS-concurrent-reset-start]</span><br><span class="line">2019-05-06T06:18:53.128+0800: 16718.222: [CMS-concurrent-reset: 0.003/0.003 secs] [Times: user=0.01 sys=0.00, real=0.00 secs]</span><br></pre></td></tr></table></figure> </p><p>&ensp; &ensp;&ensp; &ensp;眼尖的人可能已经看出来，事实上会stw的过程并没有很长,重点主要看CMS-initial-mark 和 CMS-remark 的记录，可以看到时间比较正常，所以看来CAT的long-gc告警是针对整个gc耗时的。接着看可以发现abortable-preclean的耗时比较长，如果对CMS gc每个阶段的工作都比较清楚，很快就可以找到方法解决。那我们的目标就是降低preclean的时长且不影响remark的时长，并且不会对gc的总体时长及频率带来影响。<br>&ensp; &ensp;&ensp; &ensp;既然abortable-preclean长达5秒，那就先把preclean的最长时间限制设置短，添加-XX:CMSMaxAbortablePrecleanTime=1000参数。添加之后如果不做其它操作，有可能会带来remark的时间增加，所以基于preclean的特性，自然想到remark之前减少remark的工作负担，那就添加参数<br>-XX:CMSScheduleRemarkEdenPenetration=20<br>&ensp; &ensp;&ensp; &ensp;CMSScheduleRemarkEdenSizeThreshold、CMSScheduleRemarkEdenPenetration，默认值分别是2M、50%。两个参数组合起来的意思是预清理后，eden空间使用超过2M时启动可中断的并发预清理（CMS-concurrent-abortable-preclean），直到eden空间使用率达到50%时中断，进入remark阶段。我们设置成20，让Preclean更快地进入remark阶段<br>-XX:+CMSScavengeBeforeRemark 在remark强制触发一次mirror gc<br>&ensp; &ensp;&ensp; &ensp;这样配置的结果其实也可以预见，总的pause time会增加，按天来算的话，但是假设单次gc的时间加上强制触发的时间比之前的单次gc时间要短且总的puase time不会增加很多，那就达到我们的目的了。那多少才算多，具体得看应用的情况了。<br>&ensp; &ensp;&ensp; &ensp;看一下配置前后的gc情况<br>未配置参数前<br><img src="/2019/05/04/long-gc案例分析/crawler_old_cms_stage_avg.png" title="old"><br>配置参数后<br><img src="/2019/05/04/long-gc案例分析/crawler_new_cms_stage_avg.png" title="new"><br>而总的pause时间并没有增加，所以该问题得到了解决  </p><h3 id="优化后遇到的另一个问题"><a href="#优化后遇到的另一个问题" class="headerlink" title="优化后遇到的另一个问题"></a>优化后遇到的另一个问题</h3><p>&ensp; &ensp;&ensp; &ensp;在同一个项目进行配置后过了几天，突然出现不断进行CMS GC的情况，分析GC日志情况如下<br>堆内存情况<br><img src="/2019/05/04/long-gc案例分析/crawler_old_heap.png" title="old"><br>GC cause<br><img src="/2019/05/04/long-gc案例分析/crawler_old_GC_cause.png" title="cause_old"><br>&ensp; &ensp;&ensp; &ensp;看到这两个模块的情况，基于上可以推测是新生代和老年代内存配置问题，检查jvm内存参数配置，发现配置了<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">  </span><br><span class="line">-XX:MaxHeapSize=3221225472</span><br><span class="line">-XX:MaxNewSize=2147483648</span><br></pre></td></tr></table></figure><br>&ensp; &ensp;&ensp; &ensp;也就是说配置了新生代与老年代的比例大约是2:1，官方默认配置在x86机器是应该是1:8，网上大部分资料都推荐是1:2,如果新生代配置比老年代小，有新生代晋升比较快的情况会导致CMS处理不过来,将参数调整为MaxHeapSize为4G，MaxNewSize略小于2G就不再出现  </p><h3 id="神奇的长initial-Mark及YGC过长的sys时间"><a href="#神奇的长initial-Mark及YGC过长的sys时间" class="headerlink" title="神奇的长initial Mark及YGC过长的sys时间"></a>神奇的长initial Mark及YGC过长的sys时间</h3><p>&ensp; &ensp;&ensp; &ensp;在GC日志中发偶尔initial Mark偶尔会比较长，有出现1s以上的情况<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">2019-05-10T13:03:18.282+0800: 61533.941: [GC2019-05-10T13:03:18.283+0800: 61533.942: [ParNew: 848736K-&gt;9204K(943744K), 0.0091360 secs] 2526438K-&gt;1686979K(3040896K), 0.0105130 secs] [Times: user=0.10 sys=0.01, real=0.01 secs]</span><br><span class="line">2019-05-10T13:03:18.293+0800: 61533.952: Total time for which application threads were stopped: 0.0152630 seconds</span><br><span class="line">2019-05-10T13:03:18.296+0800: 61533.956: [GC [1 CMS-initial-mark: 1677774K(2097152K)] 1687161K(3040896K), 1.4645810 secs] [Times: user=0.00 sys=1.49, real=1.47 secs]</span><br><span class="line">2019-05-10T13:03:19.761+0800: 61535.421: Total time for which application threads were stopped: 1.4685620 seconds</span><br><span class="line">2019-05-10T13:03:19.762+0800: 61535.421: [CMS-concurrent-mark-start]</span><br><span class="line">2019-05-10T13:03:19.765+0800: 61535.425: Total time for which application threads were stopped: 0.0031970 seconds</span><br><span class="line">2019-05-10T13:03:19.780+0800: 61535.439: Total time for which application threads were stopped: 0.0044250 seconds</span><br><span class="line">2019-05-10T13:03:19.880+0800: 61535.540: [CMS-concurrent-mark: 0.111/0.119 secs] [Times: user=1.30 sys=0.30, real=0.12 secs]</span><br><span class="line">2019-05-10T13:03:19.881+0800: 61535.540: [CMS-concurrent-preclean-start]</span><br><span class="line">2019-05-10T13:03:19.900+0800: 61535.560: [CMS-concurrent-preclean: 0.019/0.020 secs] [Times: user=0.06 sys=0.00, real=0.02 secs]</span><br><span class="line">2019-05-10T13:03:19.901+0800: 61535.560: [CMS-concurrent-abortable-preclean-start]</span><br><span class="line"> CMS: abort preclean due to time 2019-05-10T13:03:20.905+0800: 61536.564: [CMS-concurrent-abortable-preclean: 0.999/1.004 secs] [Times: user=1.80 sys=0.20, real=1.00 secs]</span><br><span class="line">2019-05-10T13:03:20.909+0800: 61536.568: [GC[YG occupancy: 470719 K (943744 K)]2019-05-10T13:03:20.909+0800: 61536.568: [GC2019-05-10T13:03:20.909+0800: 61536.569: [ParNew: 470719K-&gt;11056K(943744K), 0.0087720 secs] 2148494K-&gt;1688888K(3040896K), 0.0100970 secs] [Times: user=0.10 sys=0.01, real=0.01 secs]</span><br><span class="line">2019-05-10T13:03:20.919+0800: 61536.579: [Rescan (parallel) , 0.0042770 secs]2019-05-10T13:03:20.923+0800: 61536.583: [weak refs processing, 0.0237130 secs]2019-05-10T13:03:20.947+0800: 61536.607: [class unloading, 0.0255570 secs]2019-05-10T13:03:20.973+0800: 61536.632: [scrub symbol table, 0.0084850 secs]2019-05-10T13:03:20.981+0800: 61536.641: [scrub string table, 0.0014630 secs] [1 CMS-remark: 1677831K(2097152K)] 1688888K(3040896K), 0.1002410 secs] [Times: user=0.25 sys=0.01, real=0.10 secs]</span><br><span class="line">2019-05-10T13:03:21.010+0800: 61536.669: Total time for which application threads were stopped: 0.1046380 seconds</span><br><span class="line">2019-05-10T13:03:21.010+0800: 61536.669: [CMS-concurrent-sweep-start]</span><br><span class="line">2019-05-10T13:03:21.013+0800: 61536.673: Total time for which application threads were stopped: 0.0034750 seconds</span><br><span class="line">2019-05-10T13:03:21.016+0800: 61536.675: Total time for which application threads were stopped: 0.0027740 seconds</span><br><span class="line">2019-05-10T13:03:21.019+0800: 61536.678: Total time for which application threads were stopped: 0.0025430 seconds</span><br><span class="line">2019-05-10T13:03:21.021+0800: 61536.680: Total time for which application threads were stopped: 0.0022570 seconds</span><br><span class="line">2019-05-10T13:03:21.023+0800: 61536.683: Total time for which application threads were stopped: 0.0019970 seconds</span><br><span class="line">2019-05-10T13:03:21.025+0800: 61536.684: Total time for which application threads were stopped: 0.0019480 seconds</span><br><span class="line">2019-05-10T13:03:21.027+0800: 61536.687: Total time for which application threads were stopped: 0.0021600 seconds</span><br><span class="line">2019-05-10T13:03:21.029+0800: 61536.689: Total time for which application threads were stopped: 0.0021560 seconds</span><br><span class="line">2019-05-10T13:03:21.031+0800: 61536.691: Total time for which application threads were stopped: 0.0020060 seconds</span><br><span class="line">2019-05-10T13:03:21.033+0800: 61536.693: Total time for which application threads were stopped: 0.0021040 seconds</span><br><span class="line">2019-05-10T13:03:21.040+0800: 61536.700: Total time for which application threads were stopped: 0.0041470 seconds</span><br><span class="line">2019-05-10T13:03:22.343+0800: 61538.003: [CMS-concurrent-sweep: 1.309/1.333 secs] [Times: user=2.36 sys=0.23, real=1.33 secs]</span><br><span class="line">2019-05-10T13:03:22.343+0800: 61538.003: [CMS-concurrent-reset-start]</span><br><span class="line">2019-05-10T13:03:22.353+0800: 61538.013: [CMS-concurrent-reset: 0.010/0.010 secs] [Times: user=0.02 sys=0.01, real=0.01 secs]</span><br></pre></td></tr></table></figure><br>&ensp; &ensp;&ensp; &ensp;查看安全点日志,并没有发现异常<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">  </span><br><span class="line">61533.938: GenCollectForAllocation          [    1780          0              0    ]      [     0     0     0     3    11    ]  0</span><br></pre></td></tr></table></figure><br>&ensp; &ensp;&ensp; &ensp;所以既没有vmop，也没有应用线程号召安全点阻塞的情况，user为0，real却为1.47，同时sys为1.49<br>一般来说real时间远大于user时间有可能由两方面导致，一是比较重的 I/O 行为包括网络连接及磁盘操作,另一个是CPU资源紧缺.通过zbx观察机器对应时间的io、tcp连接及cpu情况，都比较正常，参考文章（<a href="https://blog.gceasy.io/2016/12/08/real-time-greater-than-user-and-sys-time/" target="_blank" rel="noopener">点击查看</a>）。基于sys &gt; user的情况的分析文章(<a href="https://blog.gceasy.io/2016/12/11/sys-time-greater-than-user-time/" target="_blank" rel="noopener">点击查看</a>)<br>&ensp; &ensp;&ensp; &ensp;查看hotspot源码<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line">void VM_CMS_Initial_Mark::doit() &#123;</span><br><span class="line">  if (lost_race()) &#123;</span><br><span class="line">    // Nothing to do.</span><br><span class="line">    return;</span><br><span class="line">  &#125;</span><br><span class="line">  HS_DTRACE_PROBE(hs_private, cms__initmark__begin);</span><br><span class="line"></span><br><span class="line">  GenCollectedHeap* gch = GenCollectedHeap::heap();</span><br><span class="line">  GCCauseSetter gccs(gch, GCCause::_cms_initial_mark);</span><br><span class="line"></span><br><span class="line">  VM_CMS_Operation::verify_before_gc();</span><br><span class="line"></span><br><span class="line">  IsGCActiveMark x; // stop-world GC active</span><br><span class="line">  _collector-&gt;do_CMS_operation(CMSCollector::CMS_op_checkpointRootsInitial);</span><br><span class="line"></span><br><span class="line">  VM_CMS_Operation::verify_after_gc();</span><br><span class="line">  HS_DTRACE_PROBE(hs_private, cms__initmark__end);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void VM_CMS_Operation::verify_before_gc() &#123;</span><br><span class="line">  if (VerifyBeforeGC &amp;&amp;</span><br><span class="line">      GenCollectedHeap::heap()-&gt;total_collections() &gt;= VerifyGCStartAt) &#123;</span><br><span class="line">    HandleMark hm;</span><br><span class="line">    FreelistLocker x(_collector);</span><br><span class="line">    MutexLockerEx  y(_collector-&gt;bitMapLock(), Mutex::_no_safepoint_check_flag);</span><br><span class="line">    Universe::heap()-&gt;prepare_for_verify();</span><br><span class="line">    Universe::verify(true);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void CMSCollector::do_CMS_operation(CMS_op_type op) &#123;</span><br><span class="line">  gclog_or_tty-&gt;date_stamp(PrintGC &amp;&amp; PrintGCDateStamps);</span><br><span class="line">  TraceCPUTime tcpu(PrintGCDetails, true, gclog_or_tty);</span><br><span class="line">  TraceTime t(&quot;GC&quot;, PrintGC, !PrintGCDetails, gclog_or_tty);</span><br><span class="line">  TraceCollectorStats tcs(counters());</span><br><span class="line"></span><br><span class="line">  switch (op) &#123;</span><br><span class="line">    case CMS_op_checkpointRootsInitial: &#123;</span><br><span class="line">      SvcGCMarker sgcm(SvcGCMarker::OTHER);</span><br><span class="line">      checkpointRootsInitial(true);       // asynch</span><br><span class="line">      if (PrintGC) &#123;</span><br><span class="line">        _cmsGen-&gt;printOccupancy(&quot;initial-mark&quot;);</span><br><span class="line">      &#125;</span><br><span class="line">      break;</span><br><span class="line">    &#125;</span><br><span class="line">    case CMS_op_checkpointRootsFinal: &#123;</span><br><span class="line">      SvcGCMarker sgcm(SvcGCMarker::OTHER);</span><br><span class="line">      checkpointRootsFinal(true,    // asynch</span><br><span class="line">                           false,   // !clear_all_soft_refs</span><br><span class="line">                           false);  // !init_mark_was_synchronous</span><br><span class="line">      if (PrintGC) &#123;</span><br><span class="line">        _cmsGen-&gt;printOccupancy(&quot;remark&quot;);</span><br><span class="line">      &#125;</span><br><span class="line">      break;</span><br><span class="line">    &#125;</span><br><span class="line">    default:</span><br><span class="line">      fatal(&quot;No such CMS_op&quot;);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void VM_CMS_Operation::verify_after_gc() &#123;</span><br><span class="line">  if (VerifyAfterGC &amp;&amp;</span><br><span class="line">      GenCollectedHeap::heap()-&gt;total_collections() &gt;= VerifyGCStartAt) &#123;</span><br><span class="line">    HandleMark hm;</span><br><span class="line">    FreelistLocker x(_collector);</span><br><span class="line">    MutexLockerEx  y(_collector-&gt;bitMapLock(), Mutex::_no_safepoint_check_flag);</span><br><span class="line">    Universe::verify(true);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure> </p><p>&ensp; &ensp;&ensp; &ensp; 进入到vmop操作即do_CMS_operation(CMSCollector::CMS_op_checkpointRootsInitial),怀疑是操作前有cpu资源等待的情况，由于机器为32个虚拟核，而机器上的java实例达到了16个，cpu并非独享，查看jvm参数，没有开启并行initial mark，添加参数CMSParallelInitialMarkEnabled进行观察，同时添加-XX:CMSWaitDuration=5010  </p><p>&ensp; &ensp;&ensp; &ensp; 同时发现parnew也有类似的情况<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">  </span><br><span class="line">2019-05-03T11:19:26.016+0800: 320262.210: [GC2019-05-03T11:19:26.017+0800: 320262.211: [ParNew: 847306K-&gt;8507K(943744K), 0.7853400 secs] 2462473K-&gt;1623871K(3040896K), 0.7866170 secs] [Times: user=0.18 sys=0.80, real=0.78 secs]</span><br></pre></td></tr></table></figure><br>&ensp; &ensp;&ensp; &ensp; 调取安全点日志<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">320262.188: GenCollectForAllocation          [    1782          0              0    ]      [     0     0     0     8   787    ]  0</span><br></pre></td></tr></table></figure><br>&ensp; &ensp;&ensp; &ensp; 可以看到没有线程wait to block,spin,block及sync的时间都正常，时间都集中在vmop中，也就是说安全点的操作并没有产生额外的耗时，结合gc的日志，可以看得出来gc线程本身的操作是正常的，那问题集中在gc日志的real时间及safepoint日志的vmop时间。虑到一样是cpu非独占的情况，查看jvm参数，发现ParallelGCThreads设置为20，上面提到机器是32虚拟核，16个java实例，估怀疑还是cpu资源抢占的问题，将ParallelGCThreads设置为8,进行观察<br>&ensp; &ensp;&ensp; &ensp; 分析到这里其实可以知道已经非程序内部可以调整的问题，一开始以为与io阻塞相关，想先从hsperfdata进行实验,但发现已经添加了参数PerfDisableSharedMem,如果定位cpu抢占资源的情况是错的，那只能通过strace跟进进程系统调用</p><p>配置前<br><img src="/2019/05/04/long-gc案例分析/voice_old_cms.png" title="old"><br>配置后<br><img src="/2019/05/04/long-gc案例分析/voice_new_cms.png" title="new"><br>可以看到initial mark和remark都比之前的要少，而且initial mark的时间转为正常，没有再出现上述情况，但是发现young gc的总耗时变长,之前是一天5分钟左右，现在是11分钟，如下<br>配置前<br><img src="/2019/05/04/long-gc案例分析/voice_old_young.png" title="old"><br>配置后<br><img src="/2019/05/04/long-gc案例分析/voice_new_young.png" title="new">  </p><p>查看堆内存情况<br>配置前<br><img src="/2019/05/04/long-gc案例分析/voice_old_heap.png" title="old"><br>配置后<br><img src="/2019/05/04/long-gc案例分析/voice_new_heap.png" title="new">  </p><p>&ensp; &ensp;&ensp; &ensp;这样看就很明显了，查看jvm参数没有配置新生代内存占用大小或比例，添加xmn参数指定1g，解决young gc次数增加的情况。  </p><p>&ensp; &ensp;&ensp; &ensp;另外parnew的长耗时问题，也得到改善，之前每天都有超过1s的情况，在新配置上线后降低了长耗时的出现频率。至少可判断猜想是正确的。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;long-gc优化&quot;&gt;&lt;a href=&quot;#long-gc优化&quot; class=&quot;headerlink&quot; title=&quot;long gc优化&quot;&gt;&lt;/a&gt;long gc优化&lt;/h3&gt;&lt;p&gt;&amp;ensp; &amp;ensp;&amp;ensp; &amp;ensp;近来发现负责研发的项目总是会收到
      
    
    </summary>
    
      <category term="JAVA" scheme="https://super-sean.github.io/categories/JAVA/"/>
    
    
      <category term="java" scheme="https://super-sean.github.io/tags/java/"/>
    
      <category term="JVM" scheme="https://super-sean.github.io/tags/JVM/"/>
    
  </entry>
  
  <entry>
    <title>创业团队那些事</title>
    <link href="https://super-sean.github.io/2019/02/09/%E5%88%9B%E4%B8%9A%E5%9B%A2%E9%98%9F%E9%82%A3%E4%BA%9B%E4%BA%8B/"/>
    <id>https://super-sean.github.io/2019/02/09/创业团队那些事/</id>
    <published>2019-02-09T14:57:00.000Z</published>
    <updated>2019-02-11T02:38:03.279Z</updated>
    
    <content type="html"><![CDATA[<p>&ensp; &ensp;&ensp; &ensp;近来由于忙着换工作和春节生活杂事安排很久没更新博客，原本想着年前写一篇docker或者spring cloud gateway的相关文章也是被搁下了。昨天送走了春节最后一波来访的亲戚，今天终于有时间可以写写东西。<br>&ensp; &ensp;&ensp; &ensp;自从有换工作的念头后，其实就很想写一下自我总结，总结算上实习7年来在工作上的感想。其实每年以及每隔一段时间我都会在个人笔记上自我复盘，但这次想分享出来，权当是给看客茶余饭后打发时间杂文也行。<br>&ensp; &ensp;&ensp; &ensp;前段日子在网上看到一句话<br>&ensp; &ensp;&ensp; &ensp;<code>当你觉得痛苦时，你只有两个选择，一个是被打倒，一个是被逼着成长</code><br>&ensp; &ensp;&ensp; &ensp;类似的话语其实大家都听得不少，这句话我再次听到的时候很有感触，回想起自己从业以来每次遇到的痛苦时刻，有放弃，有坚持。</p><p>&ensp; &ensp;&ensp; &ensp;2015年8月，我从唯品会离职出来加入这家公司，当时工作3年有多，一腔热血，老板b君和当时已经加入他们且和我比较要好的同事y君过来聊了会，我毅然决定加入团队，即便是降薪过去。后来回想自己当时真的是年轻不懂事。转眼3年半过去了，公司从一开始做Pass到后来tob电商入驻平台再到后来做tob电商自营平台，期间经历过挺多苦难，但是就我个人感觉而言，当一切上了轨道，遇到的困难其实并没有一开始遇到的要难。<br>&ensp; &ensp;&ensp; &ensp;一开始老板b君经常会拉着我们几个技术负责人做培训，包括他对行业的认知，产品的规划，个人的价值观和创业的大饼想象等。后来公司越来越大，b君也不怎么拉着人培训了，直到开始做自营，经常看到b君拉着物流、市场、采购的人做狼性培训。<br>&ensp; &ensp;&ensp; &ensp;b君有些话让我感受比较深。  </p><p>&ensp; &ensp;&ensp; &ensp;“我们过往都在选择容易的路在走，而往往只有痛苦的路才是正确的，我们不能绕过去”这句话本身我并没有太大的感觉，但是结合b君自身的经历和公司一些有能力的人，我不禁反思，为什么要选择难的路走，b君期望得到的和大家期望得到的，通过这条路真的可以得到快速实现吗？也许放在tob电商这个事是正确的，但是再往大的方向上看，为什么要选择tob电商，虽然近些年都说tob电商很大机率是风口，但是很明显市场并没有大家想象中那么热烈，对比一些红火行业来看。所以这句话也许适用b君及公司，因为b君觉得他没有退路了，但是却不定适用他手下的人，很难引起共鸣。最终b君很多事情的推动都被手下的人应付着。  </p><p>&ensp; &ensp;&ensp; &ensp;“我都这么痛苦了，为什么你们不能再往前一步”后期b君对初始的核心团队成员是这样的想法，并传达给了大部分人。技术副总监办事不力，他跟技术副总监说了这话，技术的一些高层人员不愿放弃技术转纯管理岗，他对他们也说了这句话，等等。不得不承认，b君为了公司能活下去活得好，他牺牲了很多东西，全公司压力最大那个确实是他。公司越来越大，老板自然也不可能照顾到每个初创团队的成员，自然是公司需要什么，做得到就做，做不到别人顶上，大多数情况下是小公司找不到合适价位的人才。  </p><p>&ensp; &ensp;&ensp; &ensp;“只要xxx还在，他手下整个团队换掉都没关系”，“到现在这阶段，没有说缺了谁不行”b君对团队的管理还是比较侧重抓头不抓尾，其实没什么毛病，只是没做好人才储备的情况下就比较麻烦，而且不是非常优秀的小公司很难做人才储备，尤其当公司的人力资源能力水平还处于不完善阶段，更加是难上加难。 </p><p>&ensp; &ensp;&ensp; &ensp;目前这家公司发展还可以，我写b君的东西其实也思量了挺久，写不好就变成抱怨吐槽，其实没有哪家创业公司的老板是没能力的，但也没有人是十全十美的，没有问题的公司都已经挂掉了。写b君的东西是想表达在选择创业团队的时候，老板是重要考虑因素之一，不过可能很多人在求职过程中并接触不到，可以了解好公司的氛围和企业文化再做决定。  </p><p>&ensp; &ensp;&ensp; &ensp;知乎上有一小篇文章叫《别做被小公司毁掉的年轻人》，文章最后说“小公司毁不掉你，毁掉自己只是那不思进取的自己”，说的也没错，但是这里想说的其实是，能有更好的选择，就别让自己吃那么多无谓的苦，让自己能在快乐中做贡献，对公司对个人都是好事。</p><p>&ensp; &ensp;&ensp; &ensp;个人的建议是除非看得特别透彻，综合考虑好个人自身的性格，做好了准备，才可以选择创业团队，要不然还是选择能让自己术业有专攻的平台会来得更好，做好沉淀，为将来更好的机会做好准备。创业公司的大饼是一种期望，有风险，像理财一样，个人也需要给自己划定风险承受能力范围。有更好的选择还是选择更好的，大多数人往往还是看不够透彻，做不够准备的。  </p><p>&ensp; &ensp;&ensp; &ensp;创业团队有很多乱七八糟的坑，只有你想不到，没有尽头。运气特别好的上市，稍次的被收购，大多还是处于不上不下的尴尬层次，还有更多的是直接挂掉。但是我感谢在创业团队的经历，让我更加成熟。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&amp;ensp; &amp;ensp;&amp;ensp; &amp;ensp;近来由于忙着换工作和春节生活杂事安排很久没更新博客，原本想着年前写一篇docker或者spring cloud gateway的相关文章也是被搁下了。昨天送走了春节最后一波来访的亲戚，今天终于有时间可以写写东西。&lt;br&gt;&amp;
      
    
    </summary>
    
      <category term="随笔" scheme="https://super-sean.github.io/categories/%E9%9A%8F%E7%AC%94/"/>
    
    
  </entry>
  
  <entry>
    <title>datax源码解析及分布式实现思路</title>
    <link href="https://super-sean.github.io/2018/11/23/datax%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E5%8F%8A%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9E%E7%8E%B0%E6%80%9D%E8%B7%AF/"/>
    <id>https://super-sean.github.io/2018/11/23/datax源码解析及分布式实现思路/</id>
    <published>2018-11-23T01:59:00.000Z</published>
    <updated>2018-11-23T05:56:43.191Z</updated>
    
    <content type="html"><![CDATA[<p>&ensp; &ensp;&ensp; &ensp;相信很多人接触datax都会去了解它的分布式执行模式，很“幸运”，阿里开源出来的是阉割版，默认只支持单机模式，研发团队对外基本也不回应分布式相关的问题。故此，想让datax支持分布式功能，只能自己下些功夫。<br>&ensp; &ensp;&ensp; &ensp;在github上也有人做了分布式的支持项目，如 <a href="https://github.com/TianLangStudio/DataXServer" target="_blank" rel="noopener">TianLangStudio/DataXServer</a> 后面再聊下这个项目的情况。<br>&ensp; &ensp;&ensp; &ensp;开始之前，按官方文档的建议，了解一下以下概念:</p><ul><li>Job: Job是DataX用以描述从一个源头到一个目的端的同步作业，是DataX数据同步的最小业务单元。比如：从一张mysql的表同步到odps的一个表的特定分区。</li><li>Task: Task是为最大化而把Job拆分得到的最小执行单元。比如：读一张有1024个分表的mysql分库分表的Job，拆分成1024个读Task，用若干个并发执行。</li><li>TaskGroup: 描述的是一组Task集合。在同一个TaskGroupContainer执行下的Task集合称之为TaskGroup</li><li>JobContainer: Job执行器，负责Job全局拆分、调度、前置语句和后置语句等工作的工作单元。类似Yarn中的JobTracker</li><li>TaskGroupContainer: TaskGroup执行器，负责执行一组Task的工作单元，类似Yarn中的TaskTracker。  </li></ul><h3 id="了解源码"><a href="#了解源码" class="headerlink" title="了解源码"></a>了解源码</h3><p>&ensp; &ensp;&ensp; &ensp;我们先看下datax的源码，从datax.py入手，datax.py 收集运行机器的相关信息组装参数调用com.alibaba.datax.core.Engine类，从类入口开始看主要流程分几个部分。  </p><h4 id="容器启动前操作"><a href="#容器启动前操作" class="headerlink" title="容器启动前操作"></a>容器启动前操作</h4><img src="/2018/11/23/datax源码解析及分布式实现思路/1.png" title="容器启动前操作">  <h4 id="JOB容器启动操作"><a href="#JOB容器启动操作" class="headerlink" title="JOB容器启动操作"></a>JOB容器启动操作</h4><img src="/2018/11/23/datax源码解析及分布式实现思路/2.png" title="JOB容器启动操作">  <h4 id="TaskGroup容器启动操作"><a href="#TaskGroup容器启动操作" class="headerlink" title="TaskGroup容器启动操作"></a>TaskGroup容器启动操作</h4><img src="/2018/11/23/datax源码解析及分布式实现思路/3.png" title="TaskGroup容器启动操作">  <h4 id="Job跟Task的处理流程"><a href="#Job跟Task的处理流程" class="headerlink" title="Job跟Task的处理流程"></a>Job跟Task的处理流程</h4><img src="/2018/11/23/datax源码解析及分布式实现思路/4.png" title="Job跟Task的处理流程">  <h4 id="插件相关类关系"><a href="#插件相关类关系" class="headerlink" title="插件相关类关系"></a>插件相关类关系</h4><img src="/2018/11/23/datax源码解析及分布式实现思路/5.png" title="插件相关类关系">  <p>&ensp; &ensp;&ensp; &ensp;主要流程差不多就这样了，需要注意的是，在单个容器里，研发团队的设计理念是希望建立reader和write的1：1的管道模型来处理数据。</p><h3 id="分布式支持实现思路"><a href="#分布式支持实现思路" class="headerlink" title="分布式支持实现思路"></a>分布式支持实现思路</h3><h4 id="正派做法"><a href="#正派做法" class="headerlink" title="正派做法"></a>正派做法</h4><p>&ensp; &ensp;&ensp; &ensp;按以上的解析内容，最“正经”的方案应该是让datax 将task切分好分发给不同的TaskGroup容器执行，直接执行job文件一般都是使用的job容器，如果不指定的话。按源码调试的结果，task其实是job文件中content里的每个实例。一开始提到TianLangStudio/DataXServer其实就是基于hadoop yarn api和client包进行这个思路的实现，可惜很久没维护，文档也没写好，而且远程调用只有Thrift。<br>&ensp; &ensp;&ensp; &ensp;基于“正经”方案的思路和我们的使用的习惯（目前我们是单个task一个job文件），其实可以使用一些支持服务发现及负载平衡的框架，如spring cloud，将job内容及相关参数提交给网关接口，使用自定义流量分发规则（考虑不同节点硬件资源），分发到对应节点上的服务上，服务再调起datax engin。假如需要切分task，则只需要在分发前建一层task切分的服务即可，节点上的服务根据接收到的任务类型来组装参数调用不同的datax容器。<br>&ensp; &ensp;&ensp; &ensp;挫一点的做法就是使用azkaban，手工配置指定机器运行data job</p><h4 id="邪门歪道"><a href="#邪门歪道" class="headerlink" title="邪门歪道"></a>邪门歪道</h4><p>&ensp; &ensp;&ensp; &ensp; 单个task不能再切分我认为是不合理的，首先reader和writer支持分布式的选择不多，其次，会有单点流量问题。所以其实我想要的是能不能将datax单一数据管道的模型给改造成支持分布式，让单个task也支持分布式。<br>&ensp; &ensp;&ensp; &ensp; 了解了源码之后，我觉得可以是可以有如下切入点：</p><ul><li>从job接收的时候就切分好数据块,master负责接收job/task，切分成任务块，每场任务块由一对reader和writer完成处理，就是基本datax task更小粒度或者说基于数据粒度上的切分</li><li>reader支持分布式，比如presto</li><li>reader不切，在传输给writer的queue时切，多个writer接收。其实就是将queue做成支持分布式，比如使用kafka</li><li>writer本身支持分布式，比如presto</li></ul><p>&ensp; &ensp;&ensp; &ensp; 如果纯粹地做数仓，我觉得reader和writer使用presto或其它支持分布式读写操作的技术等，然后再结合task负载均衡分配，基本可以满足了。如果需要做数据更新情况会比较复杂，需要考虑writer是否支持分布式更新及目标数据源是否支持并发插入而不容易产生锁。<br>&ensp; &ensp;&ensp; &ensp; 目前我们的架构是基于项目的情况，选择最低成本能够实现的最优方案，就是使用spring cloud + datax，保持datax核心的完整性不修改，在上面加一层，reader和writer尽量地使用presto为主，es为辅。下个阶段才会考虑使用yarn和queue的改造。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&amp;ensp; &amp;ensp;&amp;ensp; &amp;ensp;相信很多人接触datax都会去了解它的分布式执行模式，很“幸运”，阿里开源出来的是阉割版，默认只支持单机模式，研发团队对外基本也不回应分布式相关的问题。故此，想让datax支持分布式功能，只能自己下些功夫。&lt;br&gt;&amp;ens
      
    
    </summary>
    
      <category term="大数据" scheme="https://super-sean.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="数据平台" scheme="https://super-sean.github.io/tags/%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0/"/>
    
      <category term="ETL" scheme="https://super-sean.github.io/tags/ETL/"/>
    
      <category term="分布式" scheme="https://super-sean.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>并发编程</title>
    <link href="https://super-sean.github.io/2018/10/18/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"/>
    <id>https://super-sean.github.io/2018/10/18/并发编程/</id>
    <published>2018-10-18T01:54:00.000Z</published>
    <updated>2018-10-18T02:09:43.539Z</updated>
    
    <content type="html"><![CDATA[<p>&ensp; &ensp;&ensp; &ensp;并发编程是java的基础知识，但是也论深度，工作这些年与很多开发打过交道，有些人工作几年了也没有系统的认识，如果是做业务为主的开发，如果自己没有意识主动学习，往往就是基本使用、用封装好的工具或框架而不加思索。  </p><p>就着以前学习过的《JAVA并发编程》的知识整理了并发编程的基本知识点<br><img src="/2018/10/18/并发编程/JAVA并发编程.png" title="JAVA并发编程"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&amp;ensp; &amp;ensp;&amp;ensp; &amp;ensp;并发编程是java的基础知识，但是也论深度，工作这些年与很多开发打过交道，有些人工作几年了也没有系统的认识，如果是做业务为主的开发，如果自己没有意识主动学习，往往就是基本使用、用封装好的工具或框架而不加思索。  &lt;/p&gt;

      
    
    </summary>
    
      <category term="JAVA" scheme="https://super-sean.github.io/categories/JAVA/"/>
    
    
      <category term="JVM" scheme="https://super-sean.github.io/tags/JVM/"/>
    
      <category term="JAVA基础" scheme="https://super-sean.github.io/tags/JAVA%E5%9F%BA%E7%A1%80/"/>
    
      <category term="并发编程" scheme="https://super-sean.github.io/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>JAVA动态编译/解析文本的一种简易方法</title>
    <link href="https://super-sean.github.io/2018/10/07/JAVA%E5%8A%A8%E6%80%81%E7%BC%96%E8%AF%91-%E8%A7%A3%E6%9E%90%E6%96%87%E6%9C%AC%E7%9A%84%E7%AE%80%E6%98%93%E6%96%B9%E6%B3%95/"/>
    <id>https://super-sean.github.io/2018/10/07/JAVA动态编译-解析文本的简易方法/</id>
    <published>2018-10-07T14:34:00.000Z</published>
    <updated>2018-10-07T16:07:18.772Z</updated>
    
    <content type="html"><![CDATA[<p>&ensp; &ensp; 追着国庆假期的尾巴，更新一下博客，讲一下项目上之前遇到的文本动态编译/解析的问题，虽然比较简单，但是感觉适合场景还是挺多的。<br>&ensp; &ensp; 团队自研BI系统，在数据源选择及查询的实现使用桥接模式，针对不同的数据源采用不同的查询方式，而目前我们平台支持的数据源的查询可以通过构建不同的文本请求体进行查询，例如mysql、presto、ElasticSearch等。在这里对文本动态构建的实现方案进行讲述。<br>&ensp; &ensp; 我们的源文本都是基于xml标签编写，起因是BI系统一开始是基于mybatis对mysql数据库进行DAO操作。举个栗子：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;select id=&quot;test&quot; parameterType=&quot;map&quot; resultType=&quot;java.util.HashMap&quot;&gt;</span><br><span class="line">select id from table_test </span><br><span class="line"> where 1=1</span><br><span class="line">        &lt;if test=&quot;startTime != null and startTime != &apos;&apos;&quot;&gt;</span><br><span class="line">            and sale_date &gt;= #&#123;startTime&#125;</span><br><span class="line">        &lt;/if&gt;</span><br><span class="line">        &lt;if test=&quot;endTime != null and endTime != &apos;&apos;&quot;&gt;</span><br><span class="line">            and #&#123;endTime&#125; &gt;= sale_date</span><br><span class="line">        &lt;/if&gt;</span><br><span class="line">&lt;/select&gt;</span><br></pre></td></tr></table></figure>  </p><p>&ensp; &ensp; 在这个基础上我们了解了mybatis的解析过程，使用mybatis的底层实现进行动态sql语句文本编译,其实原理就是利用mybatis的xml标签解析sql实现。<br>&ensp; &ensp; xml动态文本编译/解析有多种方法，但是基于以上的情况，我们抽取了mybatis的boundsql编译过程用来构建我们的文本请求体<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"> </span><br><span class="line">//使用mybatis编译逻辑标签</span><br><span class="line">   Document doc = DOMUtils.parseXMLDocument(query);</span><br><span class="line"></span><br><span class="line">   XPathParser xPathParser = new XPathParser(doc, false);</span><br><span class="line">   Node node = doc.getFirstChild();</span><br><span class="line"></span><br><span class="line">   XNode xNode = new XNode(xPathParser, node, null);</span><br><span class="line">   XMLScriptBuilder xmlScriptBuilder = new XMLScriptBuilder(configuration, xNode);</span><br><span class="line"></span><br><span class="line">   SqlSource sqlSource = xmlScriptBuilder.parseScriptNode();</span><br><span class="line"></span><br><span class="line">   BoundSql boundSql = sqlSource.getBoundSql(param);</span><br></pre></td></tr></table></figure><br>&ensp; &ensp; 通过boundSql.getSql()可以获取编译后的文本（configuration是mybatis的基础配置类，由于这里并不用到数据库请求，所以创建一个新的单例对象传入就可以），但是需要注意的是mybatis这种编译方式是用来编译prepare statment的，什么意思呢，就是使用mybatis的标签变量声明规则，即变量是#{var}这种声明方式，会被编译成问号占位符，如果不想这样可以自己制定变量规则进行替换，比如${var}<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">  </span><br><span class="line">boundSql.getSql().indexOf(&quot;$&quot;) &gt; 0 ? replaceVariables(boundSql.getSql(),param) :   </span><br><span class="line">boundSql.getSql();</span><br></pre></td></tr></table></figure>  </p><p>&ensp; &ensp; 到此我们的presto动态语句可以写成<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"> </span><br><span class="line">    &lt;select id=&quot;test&quot; parameterType=&quot;map&quot; resultType=&quot;java.util.HashMap&quot;&gt;</span><br><span class="line">select bill_id,total from platform_data.t_sales_bill </span><br><span class="line"> where 1=1</span><br><span class="line">        &lt;if test=&quot;startTime != null and startTime != &apos;&apos;&quot;&gt;</span><br><span class="line">            and sale_date &gt;= cast(#&#123;startTime&#125; as timestamp)</span><br><span class="line">        &lt;/if&gt;</span><br><span class="line">        &lt;if test=&quot;endTime != null and endTime != &apos;&apos;&quot;&gt;</span><br><span class="line">            and cast(#&#123;endTime&#125; as timestamp) &gt;= sale_date</span><br><span class="line">        &lt;/if&gt;</span><br><span class="line">&lt;/select&gt;</span><br></pre></td></tr></table></figure> </p><p>&ensp; &ensp; es的请求体可以写成<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"> </span><br><span class="line">&lt;query&gt;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot; : &#123; &quot;bool&quot;:&#123; &quot;filter&quot;:[</span><br><span class="line">  &lt;if test=&quot;agentCodes!=null&quot;&gt;</span><br><span class="line">  &#123;&quot;match&quot; : &#123; &quot;agentCode&quot; : &quot;$&#123;agentCodes&#125;&quot;&#125; &#125;,</span><br><span class="line">  &lt;/if&gt;</span><br><span class="line">  &#123;&quot;range&quot; : &#123; &quot;saleDate&quot; : &#123;&quot;gte&quot;:&quot;$&#123;startTime&#125;&quot;,&quot;lte&quot;:&quot;$&#123;endTime&#125;&quot;&#125; &#125; &#125;</span><br><span class="line">  ] &#125; &#125;,</span><br><span class="line">  &quot;aggs&quot;:&#123;</span><br><span class="line">  &quot;sales_number&quot;:&#123;</span><br><span class="line">  &quot;terms&quot; : &#123;</span><br><span class="line">                    &quot;field&quot; : &quot;goodsId&quot;,</span><br><span class="line">                    &quot;order&quot;:&#123;</span><br><span class="line">                    &quot;salesNumber&quot;:&quot;desc&quot;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;,</span><br><span class="line">  &quot;aggs&quot;:&#123;</span><br><span class="line">  &quot;salesNumber&quot;:&#123;&quot;sum&quot;:&#123; &quot;field&quot;:&quot;salesNumber&quot; &#125; &#125;,</span><br><span class="line">  &quot;salesTotal&quot;:&#123;&quot;sum&quot;:&#123; &quot;field&quot;:&quot;salesTotal&quot; &#125; &#125; </span><br><span class="line">  &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;sort&quot;: &#123; &quot;salesNumber&quot;: &#123; &quot;order&quot;: &quot;desc&quot; &#125;&#125;</span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">&#125;</span><br><span class="line">&lt;/query&gt;</span><br></pre></td></tr></table></figure><br>&ensp; &ensp; 同理其它可以使用文本构建查询的数据源都可以支持，比如Hql,spark-sql,ksql等，再扩展也可以支持动态脚本。为我们自助查询平台和BI平台奠定了基础。<br>&ensp; &ensp; 以上，说得比较简单，希望对看到的人可以有帮助。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&amp;ensp; &amp;ensp; 追着国庆假期的尾巴，更新一下博客，讲一下项目上之前遇到的文本动态编译/解析的问题，虽然比较简单，但是感觉适合场景还是挺多的。&lt;br&gt;&amp;ensp; &amp;ensp; 团队自研BI系统，在数据源选择及查询的实现使用桥接模式，针对不同的数据源采用不同的查询
      
    
    </summary>
    
      <category term="JAVA" scheme="https://super-sean.github.io/categories/JAVA/"/>
    
    
      <category term="java基础" scheme="https://super-sean.github.io/tags/java%E5%9F%BA%E7%A1%80/"/>
    
      <category term="mybatis" scheme="https://super-sean.github.io/tags/mybatis/"/>
    
      <category term="动态解析" scheme="https://super-sean.github.io/tags/%E5%8A%A8%E6%80%81%E8%A7%A3%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>个人基于大数据平台的设计与思考</title>
    <link href="https://super-sean.github.io/2018/08/19/%E4%B8%AA%E4%BA%BA%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E7%9A%84%E8%AE%BE%E8%AE%A1%E4%B8%8E%E6%80%9D%E8%80%83/"/>
    <id>https://super-sean.github.io/2018/08/19/个人基于大数据平台的设计与思考/</id>
    <published>2018-08-19T15:19:00.000Z</published>
    <updated>2018-08-21T07:12:52.424Z</updated>
    
    <content type="html"><![CDATA[<h3 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h3><p>&ensp; &ensp; 本人是在一家TOB电商平台的创业公司就职，目前负责整个数据部门的架构与业务跟进。之前从事过YY与唯品会的web开发工作，也有了解到一些大数据架构相关的设计。<br>&ensp; &ensp; 目前数据部门的技术架构发展大体方向已经确定得差不多，于是在此梳理一下设计思路、历程与将要实现的内容。</p><h3 id="一开始都是坑"><a href="#一开始都是坑" class="headerlink" title="一开始都是坑"></a>一开始都是坑</h3><p>&ensp; &ensp; 一开始的数据需求都是来源于生意运营的报表，我由负责电商app web转向数据开发，说实话，一开始做报表我心里是拒绝的，但是创业团队为了公司能活下去，什么活不得做。领着几个兄弟搭建了公司的”数据中心”，其实就是个报表系统。当时对hadoop,hive,spark,etl等技术及概念懵懵懂懂。  </p><p>&ensp; &ensp; 很快我们发现，第一轮的坑来了，面临两个问题：一，报表需求多，小伙伴们整天在写sql，代码组合数据；二，数据量慢慢大起来，有些地方性能比较差，报表要查很久，有时候影响线上性能，线上出问题总要挨白眼。</p><p>&ensp; &ensp; 经过了解对比，我们毅然决定开始自研BI系统(参照superset功能设计)和开启我们的ETL架构设计与实现的开头，独立一套数据环境。其实当时我们心中还有点窃喜，终于可以接触高大上的hadoop全家桶了，选取的技术有hadoop、hive、spark、sqoop和shell脚本来实现我们的第一版数据流程。嗯，这才有点数据中心的样子。</p><p>&ensp; &ensp; 然而，跑了一段时间后，随着了解越多知识，才知道我们的情况有多糟糕，当时数据量不到100g，只有两台8核16G的机器（手动捂脸），离线任务依靠时间弱依赖，就算只有两台，运维起来也要花不少时间，sqoop在小数据量小集群的应用场景下性能真的很一般啊，渐渐感觉到这套架构对我们来说也许”太早了”。自研BI方面，很考验写sql的功力，虽然由此我们对mysql的sql编写技巧有很大提升，用了很多奇淫巧技，但是，我们的研发现在都花很多时间写sql啊，而且大家对数据不敏感，反正就是完成开发任务就得了。这段时间确实人心很不稳。。。当然很感谢那时坚持陪着我奋斗的小伙伴们。  </p><p>初版架构如下:<br><img src="/2018/08/19/个人基于大数据平台的设计与思考/data-architecture1.png" title="data-architecture1"></p><h3 id="有坑就要填"><a href="#有坑就要填" class="headerlink" title="有坑就要填"></a>有坑就要填</h3><p>思考、计划、实现与招聘，我们在1个月内重塑了整个交互流程。</p><ul><li>数据通过爬虫、收集日志与第三方公司进行业务结合等方式慢慢积累起来  </li><li>招来第一位数据分析师，并由他负责BI的输出与日常报表需求  </li><li>申请多了几台机器资源  </li><li>用azkaban替换shell脚本管理，正式接上任务流  </li><li>使用datax替换sqoop  </li><li>hadoop、hive及spark主要用来做少量智能化的业务，大部分数据聚合逻辑回迁数据库  </li></ul><p>这样的数据流程立马解放了开发小伙伴的双手，去做更能体现价值的事情，而且报表输出的质量也大大提高了，机器资源也暂时足够，维护起来还不算特别麻烦。心里舒了一口气。  </p><p>架构如下:<br><img src="/2018/08/19/个人基于大数据平台的设计与思考/data-architecture2.png" title="data-architecture2"></p><h3 id="业务不断发展，坑坑更健康"><a href="#业务不断发展，坑坑更健康" class="headerlink" title="业务不断发展，坑坑更健康"></a>业务不断发展，坑坑更健康</h3><p>&ensp; &ensp; 这个时候我们的业务数据量已经超过100-200G之间，数据中心的数据量也300g左右，数据库中的中间表特别多。<br>&ensp; &ensp; 现在已经好几位分析师，各自负责自己的需求，经常有数据打架的情况发生，而且制作报表很多依然用的业务源表，有性能问题就使用中间表。<br>&ensp; &ensp; 业务应用越来越多对数据聚合服务有需求，我们都是通过RPC接口来对外服务提供服务,我们经常得深入业务逻辑去提供聚合服务，而且服务对象多，所有服务在数据库聚合，经常影响数据中心整体的服务质量，也出现过多次应用雪崩的情况。<br>&ensp; &ensp; 业务也出现了实时反馈的产品需求  </p><h3 id="不断学习探研改造"><a href="#不断学习探研改造" class="headerlink" title="不断学习探研改造"></a>不断学习探研改造</h3><p>我们又再一次进行架构改造  </p><ul><li>接入otter实现业务数据实时同步  </li><li>使用canal + kafka + kafka streams 实现实时数据变更订阅，提供实时聚合服务</li><li>开始设计自己的数据字典与数据仓库</li><li>采用微服务设计理念，使用spring cloud  </li></ul><p>架构如下:<br><img src="/2018/08/19/个人基于大数据平台的设计与思考/data-architecture3.png" title="data-architecture3">  </p><p>就着这样节奏又走了一段日子</p><h3 id="总是会有不如意的地方"><a href="#总是会有不如意的地方" class="headerlink" title="总是会有不如意的地方"></a>总是会有不如意的地方</h3><p>&ensp; &ensp; 此时我们的机器资源也只有近10台一般配置的节点，随着微服务越来越多，而且与其它大数据的工具平台共用，很快又到瓶颈，而且进程多维护起来也是麻烦。<br>&ensp; &ensp; 数据团队的人员由于资源限制没有再新增，而业务缺越来越多需要支持，在生产力方面，数据处理环节明显成为瓶颈。<br>&ensp; &ensp; 此时在数据聚合方面，我们采用了redis作为缓存，但是依然存在缓存击破的情况，导致数据库偶尔会锁表，即使我们已经主从读写分离。</p><h3 id="像刀一样，越磨越亮"><a href="#像刀一样，越磨越亮" class="headerlink" title="像刀一样，越磨越亮"></a>像刀一样，越磨越亮</h3><p>我们在新的阶段探研了新的技术  </p><ul><li>使用ambari管理各种集群</li><li>探索数据流任务管理平台，对比了kettle，apache nifi和spring cloud data flow</li><li>研究能够快速检索数据且能够横向扩展的技术，如elasticsearch,kafka等</li><li>过往我们都是存储及计算一体，像我们对mysql,hive的应用就是典型的先把数据迁移到哪里再进行计算，所以我们也探研了计算分离的技术方案，最终采用presto </li></ul><h3 id="对于快速发展的创业公司来说好用才是王道，大家舒服才是王道"><a href="#对于快速发展的创业公司来说好用才是王道，大家舒服才是王道" class="headerlink" title="对于快速发展的创业公司来说好用才是王道，大家舒服才是王道"></a>对于快速发展的创业公司来说好用才是王道，大家舒服才是王道</h3><p>&ensp; &ensp;我们的数据量始终没有达到TB级别，可预见如果业务没有新的发展方向，就当前的产品的数据增长速度来看，可以把我们要做的数据平台定义为“小数据量的大数据平台”，机器资源也只是近10台（我知道市场正常搞大数据的机器集群一般都有几十上百台，再次手动捂脸）。<br>最终确定我们架构的方向:  </p><ul><li>使用otter实时同步我们所有业务数据到我们自己的数据库，减少离线同步的管理和资源成本  </li><li>使用canal 监听自己数据库的所有表变化，程序同步序列化数据到kafka中，由业务方使用kafka streams自行订阅，实现业务逻辑</li><li>使用azkaban + datax + presto ，实现分布式计算，分离存储与计算环节，完成etl流程  </li><li>最终离线数据落地elasticsearch</li><li>业务方通过数据平台进行数据需求的自满足及溯源  </li></ul><p>我们当前的架构如下(蓝色箭头为源头输出，红色箭头指向为输入，黄色箭头为溯源流向，黄色闪电为依存关系):<br><img src="/2018/08/19/个人基于大数据平台的设计与思考/data-architecture4.png" title="data-architecture4">  </p><p>而最终稳定版的架构如下:<br><img src="/2018/08/19/个人基于大数据平台的设计与思考/data-architecture5.png" title="data-architecture5">  </p><h3 id="智能化的业务"><a href="#智能化的业务" class="headerlink" title="智能化的业务"></a>智能化的业务</h3><p>&ensp; &ensp;近来公司重点发展智能化业务，需要我们支持机器学习相关的算法模型实现及调优，目前还是处于使用python脚本的实现方式及azkaban进行任务训练及提供脚本给程序调用。一方面还不是分布式计算，当然我们也可以用spark解决这个问题，第二方面，支持不了实时训练的场景，虽然我们当前也还没有这种需求。目前这块还是架构规划当中，可能会比较倾向于使用tensorflow,后续有进展再更新。</p><h3 id="感想"><a href="#感想" class="headerlink" title="感想"></a>感想</h3><p>&ensp; &ensp; 我始终没觉得自己是一个大数据开发人员，在我看来，web开发与数据开发同样是后端研发，只不过业务不同，使用的技术不同，然而很多研发的基础是一样。语言基础，高并发，大数据量，大吞吐量，分布式，高可用，模式设计，基础算法，调优，使用的工具掌握及理解像redis,zk,es,kafka,mysql这些，运维基础，前端基础，像这些我觉得都是应该掌握的。<br>&ensp; &ensp; 面试过很多大数据的开发，从初级到高级。很多人都只关心一个问题，你们的数据量有多大，你们的集群有多大。我承认这些这两个“指标”确实能说明一些东西，但是对于我面试过的人来说，我的结论是，数据量的大小对于只是一个使用工具的人来说，其实并不重要，因为你也只是用，你从来不深究，为什么要这样设计，为什么要这样实现，有没有办法做得更好，你不了解原理，你不熟悉工具技术，反而看不起数据量小的业务场景，这会让人觉得不成熟。<br>&ensp; &ensp; 当然我也是认为如果有机会接触真正的大量数据的场景，还是得尽量接触，在保证自己有不断提升的觉悟为前提去接触。面试过很多游戏通信行业的真正大数据量场景下的小伙伴，真的不得不提一句，你公司的业务场景只是一方面，不“用”起来，只是负责某个环节的加工还不深究，这样的开发真的不算是大数据研发啊。<br>&ensp; &ensp; <strong>peace &amp; love</strong></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;背景介绍&quot;&gt;&lt;a href=&quot;#背景介绍&quot; class=&quot;headerlink&quot; title=&quot;背景介绍&quot;&gt;&lt;/a&gt;背景介绍&lt;/h3&gt;&lt;p&gt;&amp;ensp; &amp;ensp; 本人是在一家TOB电商平台的创业公司就职，目前负责整个数据部门的架构与业务跟进。之前从事过YY与
      
    
    </summary>
    
      <category term="设计" scheme="https://super-sean.github.io/categories/%E8%AE%BE%E8%AE%A1/"/>
    
    
      <category term="数据平台" scheme="https://super-sean.github.io/tags/%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0/"/>
    
      <category term="架构" scheme="https://super-sean.github.io/tags/%E6%9E%B6%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>天然苏打水市场的了解与分析</title>
    <link href="https://super-sean.github.io/2018/08/14/%E5%A4%A9%E7%84%B6%E8%8B%8F%E6%89%93%E6%B0%B4%E5%B8%82%E5%9C%BA%E7%9A%84%E4%BA%86%E8%A7%A3%E4%B8%8E%E6%80%9D%E8%80%83/"/>
    <id>https://super-sean.github.io/2018/08/14/天然苏打水市场的了解与思考/</id>
    <published>2018-08-14T07:41:00.000Z</published>
    <updated>2019-02-11T02:39:21.277Z</updated>
    
    <content type="html"><![CDATA[<h4 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h4><p>近来有个朋友找到我说拿到某品牌的天然苏打水广东省省级代理，问我得怎样开展工作及市场上的情况是怎么样的。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">产品定价15元一支</span><br><span class="line">品牌方给出了一年一千万件，即八千万支的销量目标。</span><br></pre></td></tr></table></figure></p><p><style><br>  table td {text-align:center}<br>  table thead td {background:#73B1E0;color:#FFF;}<br>  table th {border:1}<br></style><br>由于个人是在TO B电商平台工作（苦逼码农一个），就着自己的资源和能力稍微进行一下分析。目标是找出工作推进的方案和尽量找出市场数据以及判断这个销量kpi是否合理。</p><h4 id="梳理步骤"><a href="#梳理步骤" class="headerlink" title="梳理步骤"></a>梳理步骤</h4><ul><li>了解市场竞品数据</li><li>了解一般水饮新品推广方法</li><li>了解行业高端专业人士对这个事件的看法</li></ul><h4 id="了解市场竞品数据"><a href="#了解市场竞品数据" class="headerlink" title="了解市场竞品数据"></a>了解市场竞品数据</h4><p>找遍关系圈并没有任何可以了解到天然苏打水相关的线下渠道，于是只能针对线上电商平台先下手。挑选了天然苏打水销量量较大的平台的销量较好的四个产品进行对比。结果如下: </p><table><thead><tr><th style="text-align:center">产品</th><th style="text-align:center">产品单价</th><th style="text-align:center">规格</th><th style="text-align:center">活动</th><th style="text-align:center">京东销量</th><th style="text-align:center">天猫销量</th><th style="text-align:center">品牌</th><th style="text-align:center">产品卖点</th><th style="text-align:center">产地</th><th style="text-align:center">公司</th><th style="text-align:center">公司旗下产品</th><th style="text-align:center">公司官网</th><th style="text-align:center">新闻备注</th><th style="text-align:center">品牌故事</th></tr></thead><tbody><tr><td style="text-align:center">舒达源克东天然苏打水</td><td style="text-align:center">9.5</td><td style="text-align:center">550ml</td><td style="text-align:center">买2送1（送6支400ml）</td><td style="text-align:center">1.9w评价</td><td style="text-align:center">2758</td><td style="text-align:center">舒达源</td><td style="text-align:center">世界三大冷矿泉之一</td><td style="text-align:center">克东</td><td style="text-align:center">黑龙江舒达饮品有限公司</td><td style="text-align:center">单一产品不同规格</td><td style="text-align:center"><a href="http://www.shudayuan.cn/index.php?a=lists&amp;catid=30" target="_blank" rel="noopener">跳转</a></td><td style="text-align:center"><a href="http://www.prnews.cn/press_release/346678.htm" target="_blank" rel="noopener">新闻1</a></td><td style="text-align:center">中国国家田径队官方用水</td></tr><tr><td style="text-align:center">活力恩克东天然苏打水</td><td style="text-align:center">3.66</td><td style="text-align:center">500ml</td><td style="text-align:center">无</td><td style="text-align:center">3.3w评价</td><td style="text-align:center">4542(单价4.5)</td><td style="text-align:center">活力恩</td><td style="text-align:center">火山岩層精淬礦泉</td><td style="text-align:center">克东</td><td style="text-align:center">海昌國際股份有限公司（彰化縣秀水鄉）</td><td style="text-align:center">主打5度C系列，销量情况一般</td><td style="text-align:center"><a href="http://www.horien.tw/webc/html/about/index.aspx" target="_blank" rel="noopener">跳转</a></td><td style="text-align:center">无</td><td style="text-align:center">无</td></tr><tr><td style="text-align:center">火山鸣泉克东天然苏打水</td><td style="text-align:center">7.3</td><td style="text-align:center">470ml</td><td style="text-align:center">无</td><td style="text-align:center">1.7w评价</td><td style="text-align:center">3578</td><td style="text-align:center">火山鸣泉</td><td style="text-align:center">火山岩層精淬礦泉</td><td style="text-align:center">克东</td><td style="text-align:center">火山鸣泉生态科技有限公司</td><td style="text-align:center">单一产品不同规格不同包装</td><td style="text-align:center"><a href="http://www.lava-spring.com/BrandCenter.html" target="_blank" rel="noopener">跳转</a></td><td style="text-align:center"><a href="http://www.sohu.com/a/168012658_479961" target="_blank" rel="noopener">新闻1</a>  <a href="http://www.ccidnet.com/2017/0707/10291070.shtml" target="_blank" rel="noopener">新闻2</a></td><td style="text-align:center">中国田径队官方饮用水</td></tr><tr><td style="text-align:center">水易方克东天然苏打水</td><td style="text-align:center">7.1</td><td style="text-align:center">500ml</td><td style="text-align:center">买5送1</td><td style="text-align:center">1.5w评价</td><td style="text-align:center">537</td><td style="text-align:center">水易方</td><td style="text-align:center">常见天然苏打水特性</td><td style="text-align:center">克东</td><td style="text-align:center">大连水易方科技发展有限公司</td><td style="text-align:center">单一产品不同规格不同包装</td><td style="text-align:center"><a href="http://www.shuiyifang.net/web/cn/qyjj/index.html" target="_blank" rel="noopener">跳转</a></td><td style="text-align:center"><a href="http://www.shuiyifang.net/web/cn/xwzx/index.html" target="_blank" rel="noopener">新闻</a></td><td style="text-align:center">无</td></tr></tbody></table><p>就这样看可以得到一些信息<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">* 京东是现在最大的销售渠道，天猫第二（其它平台几乎没有销量所以没对比）</span><br><span class="line">* 天然苏打水线上市场并不乐观,如果按这数据来看，一年100w件的销量目标都很有挑战性</span><br><span class="line">* 国内最有知名度的天然苏打水产地应该是克东，如果非克东产地的苏打水估计比较难引起消费者共鸣</span><br><span class="line">* 产品形象及品牌故事在市场竞争中影响并不大，消费者可能更看重实惠程度</span><br><span class="line">* 基本没看到哪个天然苏打水产品有打广告，更多应该是参加电商平台的促销活动</span><br></pre></td></tr></table></figure></p><p>基本上线上销售相关信息了解就到这了，但是感觉还不够，进而找了各大数据平台搜索相关报告，收集到资料如下:  </p><ul><li><p>网上评价中国十大苏打水企业<br><a href="http://www.china-10.com/china/1002sds_index.html" target="_blank" rel="noopener">http://www.china-10.com/china/1002sds_index.html</a></p></li><li><p>中国会员经济数据报告<br><a href="http://tech.qq.com/a/20170719/007724.htm#p=1" target="_blank" rel="noopener">http://tech.qq.com/a/20170719/007724.htm#p=1</a></p></li><li><p>尼尔森数据线上线下结合销售数据资讯<br><a href="http://www.nielsen.com/cn/zh/press-room/2015/Nielsen-global-survey-on-e-commerce-and-new-retailing.html" target="_blank" rel="noopener">http://www.nielsen.com/cn/zh/press-room/2015/Nielsen-global-survey-on-e-commerce-and-new-retailing.html</a></p></li><li><p>百度指数<br><a href="http://index.baidu.com/?tpl=trend&amp;word=%CB%D5%B4%F2%CB%AE" target="_blank" rel="noopener">http://index.baidu.com/?tpl=trend&amp;word=%CB%D5%B4%F2%CB%AE</a></p></li><li><p>腾讯BI<br><a href="http://tbi.tencent.com/index?word=苏打水&amp;date=1&amp;type=0" target="_blank" rel="noopener">http://tbi.tencent.com/index?word=苏打水&amp;date=1&amp;type=0</a></p></li><li><p>36kr关于高端水的观点<br><a href="http://36kr.com/p/5073894.html" target="_blank" rel="noopener">http://36kr.com/p/5073894.html</a></p></li><li><p>3mbang文库<br><a href="http://www.3mbang.com/p-171349.html" target="_blank" rel="noopener">http://www.3mbang.com/p-171349.html</a></p></li><li><p>百度文库<br><a href="https://wenku.baidu.com/view/adb970a03968011ca200911f.html" target="_blank" rel="noopener">https://wenku.baidu.com/view/adb970a03968011ca200911f.html</a><br><a href="https://wenku.baidu.com/view/64a25f0869eae009581becfb.html" target="_blank" rel="noopener">https://wenku.baidu.com/view/64a25f0869eae009581becfb.html</a><br><a href="http://www.chinairn.com/news/20160705/150700863.shtml" target="_blank" rel="noopener">http://www.chinairn.com/news/20160705/150700863.shtml</a></p></li></ul><p>ps:苏打水市场研究报告 很多咨询网站都有做，但是哪里都要钱的，一份就要好几k大洋，要不起，还是靠自己吧。</p><p>基于网上的资料可以看出来苏打水在中国的市场热度有上升的趋势，但是不大，天然苏打水就更小了。</p><h4 id="一般水饮新品推广方法"><a href="#一般水饮新品推广方法" class="headerlink" title="一般水饮新品推广方法"></a>一般水饮新品推广方法</h4><p>我找了我们公司运营部门副总监W君请教了一下，他原本是从宝洁出来的，至今工作多年，从开始的市场人员转为运营人员。从与他的交流上我总结了一下代理商一般水饮新品的推广方法如下:</p><h5 id="KA-大型卖场"><a href="#KA-大型卖场" class="headerlink" title="KA(大型卖场)"></a>KA(大型卖场)</h5><p>如沃尔玛、华润万家、永旺（吉之岛）等。  </p><p>KA是最容易进行新品试验的地方。每个KA都有自己招商的标准，对进场的产品会有不同的要求，KA每个点（如广州天河分店等）也各自有自己的要求。一般想谈合作可以直接到联系总部或者分点对应负责人直接谈就行了。  </p><p>这里假设能够满足要求并进场。合作的对象有两种，一种是直接找总部谈合作，这种方式会要求产品本身有足够强的优势，总公司才会考虑帮你铺点，而且一般找总部谈的整个流程比较长，但是一旦确定产品OK，能够大面积铺开，另一种是找某个KA的分点负责人谈，这种的门槛会比较低，但是产品流通只限于该门店，如果想再扩大市场只能自己重新去谈其它KA分点。</p><p>合作的方式有两种，一种是直接给钱进场，KA不管你销量，反正它有钱收，另一种是根据销量来进行利润分成，这种一般只会针对成熟的产品或者非常有潜力的产品。</p><p>走KA的公司的运营比较简单，只需要有人负责促销活动的规划，聘请对应的促销人员派到各大卖场进行促销活动就可以了。</p><p>然而KA渠道基本就是走量，利润空间比较小。</p><h5 id="城市有能力的中间商"><a href="#城市有能力的中间商" class="headerlink" title="城市有能力的中间商"></a>城市有能力的中间商</h5><p>如广州宝祺来，专门做日化渠道，能够快速铺货到各大KA卖场，合作方式得自己谈，基本是直接给钱合作的。</p><p>这个渠道会比直接找KA利润更低，因为有中间商赚差价嘛。但是铺货速度跟能力绝对是杠杠的。</p><h5 id="特殊渠道"><a href="#特殊渠道" class="headerlink" title="特殊渠道"></a>特殊渠道</h5><p>带有特殊性质的饮品，如能量饮料、苏打水，都有一些特殊的渠道可以卖，这个渠道比较看重经营方即卖饮品的公司渠道能力。比如红牛可以铺货进网吧、各大运动场所等。这个渠道我也没有资源可以继续了解，只是知道，特殊渠道是毛利可以爆发的渠道。</p><h5 id="中小超市士多"><a href="#中小超市士多" class="headerlink" title="中小超市士多"></a>中小超市士多</h5><p>基本上品牌代理商不会自己直接去铺小店，成本高，效益低。</p><h4 id="专业人士意见"><a href="#专业人士意见" class="headerlink" title="专业人士意见"></a>专业人士意见</h4><p>我找了我们公司采购部副总监请教，他是一路从恒大、沃尔玛等大公司由基层做到高层的。沟通下来我总结有以下几点：</p><ul><li>新品不能急着铺货，只要你产品OK，销售渠道是比较容易疏通的</li><li>确定好主打市场，目标人群</li><li>做好市场调研，可以采用问券调查等方式。如果真的不清晰怎么做，可以拜访其它省级代理，咨询下人家的情况与做法</li><li>商品本身的主打特性要宣传到位，假如商品本身有什么特别性质的，如真的可以治疗什么疾病或者产源稀缺，那定价高一样可以卖得火爆</li><li>特殊渠道在定位高端产品的渠道中比较重要，往往是有利可图的渠道</li><li>15元的高端水在市场很少见，至少这位哥是没见过，当时在恒大做恒大冰泉也是定价高昂，现在一样卖到跟普通差不多，正常渠道销量也一般。所以这个定价的水产品市场不好做</li></ul><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>针对销量目标来说，天然苏打水新品一年一千万件即八千箱的省级销售目标，从运营和专业人士的角度来看，都是很难达到，结合线上数据来看，也更加能说明这点。合理的有挑战性的目标大概是一百万件左右。假如有特殊渠道另说，因为特殊渠道的量就看主营公司的能力了，不好预估。<br>推广新品的方法上面已经提到，但是推广前需要确定好目标人群、商品的亮点、品牌故事与背景和渠道。如果不清楚怎么做，可以去其它省级代理了解咨询，如果有的话。</p><h4 id="吐槽"><a href="#吐槽" class="headerlink" title="吐槽"></a>吐槽</h4><p>基本上KA或者平台级的公司不会管你产品好不好卖，都想你投钱进场，反正不好卖也不关他们的事。包括我们公司那采购副总监，一边说着感觉市场不好做，一边想让我朋友来找我们公司合作，笑哭，哈哈</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h4&gt;&lt;p&gt;近来有个朋友找到我说拿到某品牌的天然苏打水广东省省级代理，问我得怎样开展工作及市场上的情况是怎么样的。&lt;br&gt;&lt;figure class=&quot;
      
    
    </summary>
    
      <category term="随笔" scheme="https://super-sean.github.io/categories/%E9%9A%8F%E7%AC%94/"/>
    
    
      <category term="数据分析" scheme="https://super-sean.github.io/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>spring cloud stream 基于kafka的使用简析</title>
    <link href="https://super-sean.github.io/2018/08/11/spring-cloud-stream-%E5%9F%BA%E4%BA%8Ekafka%E7%9A%84%E4%BD%BF%E7%94%A8%E7%AE%80%E6%9E%90/"/>
    <id>https://super-sean.github.io/2018/08/11/spring-cloud-stream-基于kafka的使用简析/</id>
    <published>2018-08-11T01:26:00.000Z</published>
    <updated>2018-08-11T05:53:56.712Z</updated>
    
    <content type="html"><![CDATA[<h4 id="流式数据"><a href="#流式数据" class="headerlink" title="流式数据"></a>流式数据</h4><p>故名思义，即数据像开了小河里的流水般不停流动，除非水源出现问题，否则没有结束时间。<br>流式数据在行业内已经有非常多针对不同应用量级的成熟方案，这里就不加以详述。本次主要介绍spring cloud stream 基于kafka对流式数据的基本应用。而使用spring cloud stream之前，可以先理解一下spring cloud对数据流程的几个概念，分别是source（生产数据者），processor(数据加工者), sink(最终结果处理者)。</p><h4 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h4><p><strong>项目基本框架</strong>:当然是基于maven构建的spring-boot最省心省力啦<br><strong>添加依赖</strong>:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">&lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;</span><br><span class="line">&lt;artifactId&gt;spring-cloud-stream-binder-kafka-streams&lt;/artifactId&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br><span class="line"></span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">&lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;</span><br><span class="line">&lt;artifactId&gt;spring-cloud-stream-binder-kafka&lt;/artifactId&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 用于代码中的一些便捷注解 --&gt;</span><br><span class="line">      &lt;dependency&gt;</span><br><span class="line">&lt;groupId&gt;org.projectlombok&lt;/groupId&gt;</span><br><span class="line">&lt;artifactId&gt;lombok&lt;/artifactId&gt;</span><br><span class="line">&lt;version&gt;1.18.0&lt;/version&gt;</span><br><span class="line">&lt;scope&gt;provided&lt;/scope&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure></p><p><strong>公共配置</strong>:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">spring:</span><br><span class="line">  cloud:</span><br><span class="line">  kafka:</span><br><span class="line">          streams:</span><br><span class="line">            binder:</span><br><span class="line">              brokers: localhost:9092</span><br><span class="line">              zk-nodes: localhost:2181 #2.0以上就不需要该配置</span><br><span class="line">              configuration:</span><br><span class="line">                default:</span><br><span class="line">                  key:</span><br><span class="line">                    serde: org.apache.kafka.common.serialization.Serdes$StringSerde</span><br><span class="line">                  value:</span><br><span class="line">                    serde: org.apache.kafka.common.serialization.Serdes$StringSerde</span><br><span class="line">                cache:</span><br><span class="line">                  max:</span><br><span class="line">                    bytes:</span><br><span class="line">                      buffering: 0 #所有线程可以用于缓存的最大字节数,达到多少数据量之后聚合一次流中的数据，设置为0则实时聚合</span><br><span class="line">                commit:</span><br><span class="line">                  interval:</span><br><span class="line">                    ms: 1000 #版本数据确认消费时间ack</span><br></pre></td></tr></table></figure></p><p>我们来模拟用户页面访问记录流</p><h4 id="声明binding相关信息"><a href="#声明binding相关信息" class="headerlink" title="声明binding相关信息"></a>声明binding相关信息</h4><p>添加接口AnalyticsBinding<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">public interface AnalyticsBinding &#123;</span><br><span class="line">    String PAGE_VIEWS_OUT = &quot;pvout&quot;;</span><br><span class="line">    String PAGE_VIEWS_IN = &quot;pvin&quot;;</span><br><span class="line">    String PAGE_COUNT_MV = &quot;pcmv&quot;;</span><br><span class="line">    String PAGE_COUNT_OUT = &quot;pcout&quot;;</span><br><span class="line">    String PAGE_COUNT_IN = &quot;pcin&quot;;</span><br><span class="line"></span><br><span class="line">    @Input(PAGE_VIEWS_IN)</span><br><span class="line">    KStream&lt;String,PageViewEvent&gt; pageViewsIn();</span><br><span class="line"></span><br><span class="line">    @Output(PAGE_COUNT_OUT)</span><br><span class="line">    KStream&lt;String,Long&gt; pageCountOut();</span><br><span class="line"></span><br><span class="line">    @Input(PAGE_COUNT_IN)</span><br><span class="line">    KTable&lt;String,Long&gt; pageCountIn();</span><br><span class="line"></span><br><span class="line">    @Output(PAGE_VIEWS_OUT)</span><br><span class="line">    MessageChannel pageViewsOut();</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h4 id="添加配置"><a href="#添加配置" class="headerlink" title="添加配置"></a>添加配置</h4><p>在application.yml中声明以下配置<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">spring:</span><br><span class="line">  cloud:</span><br><span class="line">     stream:</span><br><span class="line">        bindings:</span><br><span class="line">          pvout:</span><br><span class="line">            destination: pvst</span><br><span class="line">            group: pvst</span><br><span class="line">            producer:</span><br><span class="line">              header-mode: raw</span><br><span class="line">          pvin:</span><br><span class="line">            destination: pvst</span><br><span class="line">            group: pvst</span><br><span class="line">            consumer:</span><br><span class="line">              header-mode: raw</span><br><span class="line">          pcout:</span><br><span class="line">            destination: pcst</span><br><span class="line">            group: pcst</span><br><span class="line">            producer:</span><br><span class="line">              use-native-encoding: true</span><br><span class="line">          pcin:</span><br><span class="line">            destination: pcst</span><br><span class="line">            group: pcst</span><br><span class="line">            content-type: application/json</span><br><span class="line">            consumer:</span><br><span class="line">              use-native-encoding: true</span><br><span class="line">              header-mode: raw</span><br><span class="line">        kafka:</span><br><span class="line">          streams:</span><br><span class="line">            bindings:</span><br><span class="line">              pcout:</span><br><span class="line">                producer:</span><br><span class="line">                  key-serde: org.apache.kafka.common.serialization.Serdes$StringSerde</span><br><span class="line">                  value-serde: org.apache.kafka.common.serialization.Serdes$LongSerde</span><br><span class="line">              pcin:</span><br><span class="line">                consumer:</span><br><span class="line">                  key-serde: org.apache.kafka.common.serialization.Serdes$StringSerde</span><br><span class="line">                  value-serde: org.apache.kafka.common.serialization.Serdes$LongSerde</span><br></pre></td></tr></table></figure></p><p>destination对应kafka中的主题。<br>serde就是serialization和deserialization，针对流中的key和value都需要指定，默认使用default中配置的内容，也可以针对主题单独设置。  </p><h4 id="source"><a href="#source" class="headerlink" title="source"></a>source</h4><p>创建每秒随机产生用户访问页面及停留时间的数据  </p><p>先创建事件类<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">@Data</span><br><span class="line">@AllArgsConstructor</span><br><span class="line">@NoArgsConstructor</span><br><span class="line">public class PageViewEvent &#123;</span><br><span class="line">    private String userId,page;</span><br><span class="line">    private long duration;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>生成数据的实现<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">@Slf4j</span><br><span class="line">@Component</span><br><span class="line">@EnableBinding(AnalyticsBinding.class)</span><br><span class="line">public class PageViewEventSource implements ApplicationRunner &#123;</span><br><span class="line"></span><br><span class="line">    private  final MessageChannel pageViewsOut;</span><br><span class="line"></span><br><span class="line">    public PageViewEventSource(AnalyticsBinding binding) &#123;</span><br><span class="line">        this.pageViewsOut = binding.pageViewsOut();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void run(ApplicationArguments applicationArguments) throws Exception &#123;</span><br><span class="line">        List&lt;String&gt; names = Arrays.asList(&quot;jlong&quot;,&quot;dyser&quot;,&quot;shacko&quot;,&quot;abilan&quot;,&quot;ooasdf&quot;,&quot;grussell&quot;);</span><br><span class="line">        List&lt;String&gt; pages = Arrays.asList(&quot;blog&quot;,&quot;sitemap&quot;,&quot;initializr&quot;,&quot;news&quot;,&quot;colophon&quot;,&quot;about&quot;);</span><br><span class="line"></span><br><span class="line">        Runnable runnable = () -&gt; &#123;</span><br><span class="line">            String rPage = pages.get(new Random().nextInt(pages.size()));</span><br><span class="line">            String rName = names.get(new Random().nextInt(names.size()));</span><br><span class="line">            PageViewEvent pageViewEvent = new PageViewEvent(rName,rPage,Math.random() &gt; .5?10:1000);</span><br><span class="line">            Message&lt;PageViewEvent&gt; message = MessageBuilder.withPayload(pageViewEvent)</span><br><span class="line">                .setHeader(KafkaHeaders.MESSAGE_KEY,pageViewEvent.getUserId().getBytes())</span><br><span class="line">                .build();</span><br><span class="line">            try &#123;</span><br><span class="line">                this.pageViewsOut.send(message);</span><br><span class="line">                log.info(&quot;sent&quot; + message.toString());</span><br><span class="line">            &#125; catch (Exception e)&#123;</span><br><span class="line">                log.error(e.getMessage());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;;</span><br><span class="line">        Executors.newScheduledThreadPool(1).scheduleAtFixedRate(runnable,1,1, TimeUnit.SECONDS);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h4 id="processor"><a href="#processor" class="headerlink" title="processor"></a>processor</h4><p>获取到事件数据之后基于聚合处理，创建新的数据流<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">@Slf4j</span><br><span class="line">@Component</span><br><span class="line">public class PageViewEventProcessor &#123;</span><br><span class="line">    @StreamListener</span><br><span class="line">    @SendTo(AnalyticsBinding.PAGE_COUNT_OUT)</span><br><span class="line">    public  KStream&lt;String,Long&gt; process(</span><br><span class="line">            @Input(AnalyticsBinding.PAGE_VIEWS_IN) KStream&lt;String,PageViewEvent&gt; events)&#123;</span><br><span class="line">        return events</span><br><span class="line">                .map((key,value) -&gt; new KeyValue&lt;&gt;(value.getUserId() + &quot;-&quot; + value.getPage(),&quot;0&quot;))</span><br><span class="line">                .groupByKey()</span><br><span class="line">                //.windowedBy(TimeWindows.of(1000*60)) </span><br><span class="line">                .count(Materialized.as(AnalyticsBinding.PAGE_COUNT_MV))</span><br><span class="line">                .toStream();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>windowedBy可以根据时间窗口进行聚合，用法请详见文档。  </p><h4 id="sink"><a href="#sink" class="headerlink" title="sink"></a>sink</h4><p>获取聚合后的结果进行处理<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">@Slf4j</span><br><span class="line">@Component</span><br><span class="line">public class PageCountSink &#123;</span><br><span class="line"></span><br><span class="line">    @StreamListener</span><br><span class="line">    public void process(@Input(AnalyticsBinding.PAGE_COUNT_IN)KTable&lt;String,Long&gt; counts)&#123;</span><br><span class="line">        counts.toStream().foreach((key,value) -&gt; log.info(&quot;PCIN -----:&quot; + key + &quot;=&quot; + value));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>至此一个从数据生产到结果消费的简单数据流处理就完成了</p><h4 id="解析"><a href="#解析" class="headerlink" title="解析"></a>解析</h4><p>这个例子是基于spring cloud 完整的流数据处理，有source,processor,sink的概念是spring cloud data flow的设计理念，这里不展开阐述。<br>processor环节非必需的，可以只有source和sink的实现。<br>假如不需要进行流的处理，只需要消息内容，可以在@StreamListener的方法声明中不使用@Input声明，而是直接通过@StreamListener(主题名称)来进行监听，<br>方法接收消息参数使用Message<t> msg，如下:</t></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">@StreamListener(Processor.INPUT)</span><br><span class="line">public void receive1(Message&lt;String&gt; msg)&#123;</span><br><span class="line">System.out.println(msg.getPayload()); //消息体</span><br><span class="line">Acknowledgment acknowledgment = msg.getHeaders().get(KafkaHeaders.ACKNOWLEDGMENT, Acknowledgment.class);</span><br><span class="line">if (acknowledgment != null) &#123;</span><br><span class="line">System.out.println(&quot;Acknowledgment provided&quot;);</span><br><span class="line">acknowledgment.acknowledge();//手动ack</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="多流聚合"><a href="#多流聚合" class="headerlink" title="多流聚合"></a>多流聚合</h4><p>在实际应用中不只存在单流数据的处理，也经常会遇到多流聚合处理。<br>我们来添加多一种事件的实现，这里模拟销售数据。相关的实现如下  </p><p>SalesEvent<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">@Data</span><br><span class="line">@AllArgsConstructor</span><br><span class="line">@NoArgsConstructor</span><br><span class="line">public class SalesEvent &#123;</span><br><span class="line">    private String userId,goods;</span><br><span class="line">    private int amount;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>SalesEventSource<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">@Slf4j</span><br><span class="line">@Component</span><br><span class="line">@EnableBinding(AnalyticsBinding.class)</span><br><span class="line">public class SalesEventSource implements ApplicationRunner &#123;</span><br><span class="line">    private  final MessageChannel salesOut;</span><br><span class="line"></span><br><span class="line">    public SalesEventSource(AnalyticsBinding binding) &#123;</span><br><span class="line">        this.salesOut = binding.salesOut();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void run(ApplicationArguments applicationArguments) throws Exception &#123;</span><br><span class="line">        List&lt;String&gt; names = Arrays.asList(&quot;jlong&quot;,&quot;dyser&quot;,&quot;shacko&quot;,&quot;abilan&quot;,&quot;ooasdf&quot;,&quot;grussell&quot;);</span><br><span class="line">        List&lt;String&gt; goods = Arrays.asList(&quot;apple&quot;,&quot;oringe&quot;,&quot;banana&quot;,&quot;lemon&quot;,&quot;shit&quot;,&quot;book&quot;);</span><br><span class="line">        Runnable runnable = () -&gt; &#123;</span><br><span class="line">            String rGoods = goods.get(new Random().nextInt(goods.size()));</span><br><span class="line">            String rName = names.get(new Random().nextInt(names.size()));</span><br><span class="line">            SalesEvent salesEvent = new SalesEvent(rName,rGoods,Math.random() &gt; .5?5:10);</span><br><span class="line">            Message&lt;SalesEvent&gt; message = MessageBuilder.withPayload(salesEvent)</span><br><span class="line">                    .setHeader(KafkaHeaders.MESSAGE_KEY,salesEvent.getUserId().getBytes())</span><br><span class="line">                    .build();</span><br><span class="line">            try &#123;</span><br><span class="line">                this.salesOut.send(message);</span><br><span class="line">                log.info(&quot;sent&quot; + message.toString());</span><br><span class="line">            &#125; catch (Exception e)&#123;</span><br><span class="line">                log.error(e.getMessage());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;;</span><br><span class="line">        Executors.newScheduledThreadPool(1).scheduleAtFixedRate(runnable,1,1, TimeUnit.SECONDS);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>SalesEventProcessor<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">@Slf4j</span><br><span class="line">@Component</span><br><span class="line">@EnableBinding(AnalyticsBinding.class)</span><br><span class="line">public class SalesEventProcessor &#123;</span><br><span class="line">    @StreamListener</span><br><span class="line">    @SendTo(AnalyticsBinding.SALES_COUNT_OUT)</span><br><span class="line">    public KStream&lt;String,Long&gt; process(@Input(AnalyticsBinding.SALES_IN)KStream&lt;String,SalesEvent&gt; events)&#123;</span><br><span class="line">        return events</span><br><span class="line">                .map((key,value) -&gt; new KeyValue&lt;&gt;(value.getUserId() + &quot;-&quot; + value.getGoods(),&quot;0&quot;))</span><br><span class="line">                .groupByKey()</span><br><span class="line">                //.windowedBy(TimeWindows.of(1000*60))</span><br><span class="line">                .count(Materialized.as(AnalyticsBinding.SALES_COUNT_MV))</span><br><span class="line">                .toStream();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>SaleCountSink<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">@Slf4j</span><br><span class="line">@Component</span><br><span class="line">@EnableBinding(AnalyticsBinding.class)</span><br><span class="line">public class SaleCountSink &#123;</span><br><span class="line"></span><br><span class="line">    @StreamListener</span><br><span class="line">    public void process(@Input(AnalyticsBinding.SALES_COUNT_IN)KTable&lt;String,Long&gt; salesCounts,</span><br><span class="line">                        @Input(AnalyticsBinding.PAGE_COUNT_IN)KTable&lt;String,Long&gt; pageCounts)&#123;</span><br><span class="line">        salesCounts.toStream().map((k,v) -&gt; new KeyValue&lt;&gt;(k.split(&quot;-&quot;)[0],k.split(&quot;-&quot;)[1] + &quot;-&quot; + v))</span><br><span class="line">                .join(pageCounts.toStream().map((k,v) -&gt; &#123;</span><br><span class="line">                            System.out.println(&quot;-------&quot; + k +&quot; : &quot; + v );</span><br><span class="line">                            return new KeyValue&lt;&gt;(k.split(&quot;-&quot;)[0],k.split(&quot;-&quot;)[1] + &quot;-&quot; + v);&#125;),</span><br><span class="line">                        (v1, v2) -&gt; v1 + &quot;:&quot; + v2,</span><br><span class="line">                        JoinWindows.of(10000)</span><br><span class="line">                        )</span><br><span class="line">                .foreach((k,v) -&gt; System.out.println(k+ &quot;---&quot; + v));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>注意：同个应用中对同个流的监听实例只能有一个，SaleCountSink使用了@Input(AnalyticsBinding.PAGE_COUNT_IN)KTable&lt;String,Long&gt;<br>与PageCountSink有冲突，要嘛把PageCountSink中的监听去掉，要嘛重命名其中一个相关的监听配置</p><p>AnalyticsBinding 完整代码<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">public interface AnalyticsBinding &#123;</span><br><span class="line">    String PAGE_VIEWS_OUT = &quot;pvout&quot;;</span><br><span class="line">    String PAGE_VIEWS_IN = &quot;pvin&quot;;</span><br><span class="line">    String PAGE_COUNT_MV = &quot;pcmv&quot;;</span><br><span class="line">    String PAGE_COUNT_OUT = &quot;pcout&quot;;</span><br><span class="line">    String PAGE_COUNT_IN = &quot;pcin&quot;;</span><br><span class="line">    String SALES_OUT = &quot;salesout&quot;;</span><br><span class="line">    String SALES_IN = &quot;salesin&quot;;</span><br><span class="line">    String SALES_COUNT_MV = &quot;scmv&quot;;</span><br><span class="line">    String SALES_COUNT_OUT = &quot;scout&quot;;</span><br><span class="line">    String SALES_COUNT_IN = &quot;scin&quot;;</span><br><span class="line"></span><br><span class="line">    @Input(PAGE_VIEWS_IN)</span><br><span class="line">    KStream&lt;String,PageViewEvent&gt; pageViewsIn();</span><br><span class="line"></span><br><span class="line">    @Output(PAGE_COUNT_OUT)</span><br><span class="line">    KStream&lt;String,Long&gt; pageCountOut();</span><br><span class="line"></span><br><span class="line">    @Input(PAGE_COUNT_IN)</span><br><span class="line">    KTable&lt;String,Long&gt; pageCountIn();</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    @Output(PAGE_VIEWS_OUT)</span><br><span class="line">    MessageChannel pageViewsOut();</span><br><span class="line"></span><br><span class="line">    @Output(SALES_OUT)</span><br><span class="line">    MessageChannel salesOut();</span><br><span class="line"></span><br><span class="line">    @Input(SALES_IN)</span><br><span class="line">    KStream&lt;String,SalesEvent&gt; salesIn();</span><br><span class="line"></span><br><span class="line">    @Output(SALES_COUNT_OUT)</span><br><span class="line">    KStream&lt;String,Long&gt; salesCountOut();</span><br><span class="line"></span><br><span class="line">    @Input(SALES_COUNT_IN)</span><br><span class="line">    KTable&lt;String,Long&gt; salesCountIn();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>application.yml完整配置<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line">server:</span><br><span class="line">  port: 8388</span><br><span class="line"></span><br><span class="line">spring:</span><br><span class="line">  application:</span><br><span class="line">    name: input-demo</span><br><span class="line">  cloud:</span><br><span class="line">     instance-count: 1</span><br><span class="line">     instance-index: 0</span><br><span class="line">     stream:</span><br><span class="line">        bindings:</span><br><span class="line">          pvout:</span><br><span class="line">            destination: pvst</span><br><span class="line">            group: pvst</span><br><span class="line">            producer:</span><br><span class="line">              header-mode: raw</span><br><span class="line">          pvin:</span><br><span class="line">            destination: pvst</span><br><span class="line">            group: pvst</span><br><span class="line">            consumer:</span><br><span class="line">              header-mode: raw</span><br><span class="line">          pcout:</span><br><span class="line">            destination: pcst</span><br><span class="line">            group: pcst</span><br><span class="line">            producer:</span><br><span class="line">              use-native-encoding: true</span><br><span class="line">          pcin:</span><br><span class="line">            destination: pcst</span><br><span class="line">            group: pcst</span><br><span class="line">            content-type: application/json</span><br><span class="line">            consumer:</span><br><span class="line">              use-native-encoding: true</span><br><span class="line">              header-mode: raw</span><br><span class="line">          salesout:</span><br><span class="line">            destination: sost</span><br><span class="line">            group: sost</span><br><span class="line">            producer:</span><br><span class="line">              header-mode: raw</span><br><span class="line">          salesin:</span><br><span class="line">            destination: sost</span><br><span class="line">            group: sost</span><br><span class="line">            consumer:</span><br><span class="line">              header-mode: raw</span><br><span class="line">          scout:</span><br><span class="line">            destination: scst</span><br><span class="line">            group: scst</span><br><span class="line">            producer:</span><br><span class="line">              use-native-encoding: true</span><br><span class="line">          scin:</span><br><span class="line">            destination: scst</span><br><span class="line">            group: scst</span><br><span class="line">            content-type: application/json</span><br><span class="line">            consumer:</span><br><span class="line">              use-native-encoding: true</span><br><span class="line">              header-mode: raw</span><br><span class="line">        kafka:</span><br><span class="line">          streams:</span><br><span class="line">            binder:</span><br><span class="line">              configuration:</span><br><span class="line">                default:</span><br><span class="line">                  key:</span><br><span class="line">                    serde: org.apache.kafka.common.serialization.Serdes$StringSerde</span><br><span class="line">                  value:</span><br><span class="line">                    serde: org.apache.kafka.common.serialization.Serdes$StringSerde</span><br><span class="line">                cache:</span><br><span class="line">                  max:</span><br><span class="line">                    bytes:</span><br><span class="line">                      buffering: 0</span><br><span class="line">                commit:</span><br><span class="line">                  interval:</span><br><span class="line">                    ms: 1000 </span><br><span class="line">              brokers: localhost:9092</span><br><span class="line">              zk-nodes: localhost:2181</span><br><span class="line">            bindings:</span><br><span class="line">              pcout:</span><br><span class="line">                producer:</span><br><span class="line">                  key-serde: org.apache.kafka.common.serialization.Serdes$StringSerde</span><br><span class="line">                  value-serde: org.apache.kafka.common.serialization.Serdes$LongSerde</span><br><span class="line">              pcin:</span><br><span class="line">                consumer:</span><br><span class="line">                  key-serde: org.apache.kafka.common.serialization.Serdes$StringSerde</span><br><span class="line">                  value-serde: org.apache.kafka.common.serialization.Serdes$LongSerde         </span><br><span class="line">              scout:</span><br><span class="line">                producer:</span><br><span class="line">                  key-serde: org.apache.kafka.common.serialization.Serdes$StringSerde</span><br><span class="line">                  value-serde: org.apache.kafka.common.serialization.Serdes$LongSerde</span><br><span class="line">              scin:</span><br><span class="line">                consumer:</span><br><span class="line">                  key-serde: org.apache.kafka.common.serialization.Serdes$StringSerde</span><br><span class="line">                  value-serde: org.apache.kafka.common.serialization.Serdes$LongSerde</span><br></pre></td></tr></table></figure></p><p>多流合并的理念是把流两两之间的key处理成一样进行join处理，join的实现方法大家可以自行阅读文档。如果是三个流以上，需要先将两个流合并之后生成一个流再与第三流合并处理。</p><h4 id="相关文档"><a href="#相关文档" class="headerlink" title="相关文档"></a>相关文档</h4><ul><li><a href="https://docs.spring.io/spring-cloud-dataflow/docs/1.6.0.RELEASE/reference/htmlsingle/" target="_blank" rel="noopener">spring cloud data flow</a></li><li><a href="https://docs.spring.io/spring-cloud-stream/docs/Brooklyn.RELEASE/reference/html/index.html" target="_blank" rel="noopener">spring cloud stream</a></li><li><a href="https://spring.io/blog/2018/04/04/spring-tips-spring-cloud-stream-kafka-streams" target="_blank" rel="noopener">spring cloud stream kafka streams应用官方视频讲解</a></li><li><a href="https://www.jianshu.com/p/45ba430e59f6" target="_blank" rel="noopener">KTable与KStream的关系</a></li><li><a href="http://kafka.apache.org/documentation/" target="_blank" rel="noopener">kafka官方文档</a></li><li><a href="https://www.cnblogs.com/devos/p/5616086.html" target="_blank" rel="noopener">kafka streams window的概念翻译版</a></li><li>kafka权威指南</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;流式数据&quot;&gt;&lt;a href=&quot;#流式数据&quot; class=&quot;headerlink&quot; title=&quot;流式数据&quot;&gt;&lt;/a&gt;流式数据&lt;/h4&gt;&lt;p&gt;故名思义，即数据像开了小河里的流水般不停流动，除非水源出现问题，否则没有结束时间。&lt;br&gt;流式数据在行业内已经有非常多针对不
      
    
    </summary>
    
      <category term="大数据" scheme="https://super-sean.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="实时流" scheme="https://super-sean.github.io/tags/%E5%AE%9E%E6%97%B6%E6%B5%81/"/>
    
      <category term="spring" scheme="https://super-sean.github.io/tags/spring/"/>
    
      <category term="kafka" scheme="https://super-sean.github.io/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>内存与JVM</title>
    <link href="https://super-sean.github.io/2018/07/23/%E5%86%85%E5%AD%98%E4%B8%8EJVM/"/>
    <id>https://super-sean.github.io/2018/07/23/内存与JVM/</id>
    <published>2018-07-23T15:57:00.000Z</published>
    <updated>2018-08-11T03:19:05.556Z</updated>
    
    <content type="html"><![CDATA[<p>自己一边看书一边实践一边整理下来的知识思维导向图，个人感觉能够掌握自动内存管理机制、高效并发并加以应用，理解虚拟机执行子系统、程序编译与代码优化，才可以说熟悉JVM。<br><img src="/2018/07/23/内存与JVM/内存与JVM.png" title="内存与JVM"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;自己一边看书一边实践一边整理下来的知识思维导向图，个人感觉能够掌握自动内存管理机制、高效并发并加以应用，理解虚拟机执行子系统、程序编译与代码优化，才可以说熟悉JVM。&lt;br&gt;&lt;img src=&quot;/2018/07/23/内存与JVM/内存与JVM.png&quot; title=&quot;内存
      
    
    </summary>
    
      <category term="JAVA" scheme="https://super-sean.github.io/categories/JAVA/"/>
    
    
      <category term="java基础" scheme="https://super-sean.github.io/tags/java%E5%9F%BA%E7%A1%80/"/>
    
      <category term="JVM" scheme="https://super-sean.github.io/tags/JVM/"/>
    
      <category term="内存" scheme="https://super-sean.github.io/tags/%E5%86%85%E5%AD%98/"/>
    
  </entry>
  
  <entry>
    <title>zk分布式任务队列交互设计</title>
    <link href="https://super-sean.github.io/2018/07/22/zk%E5%88%86%E5%B8%83%E5%BC%8F%E4%BB%BB%E5%8A%A1%E9%98%9F%E5%88%97%E4%BA%A4%E4%BA%92%E8%AE%BE%E8%AE%A1/"/>
    <id>https://super-sean.github.io/2018/07/22/zk分布式任务队列交互设计/</id>
    <published>2018-07-22T15:12:00.000Z</published>
    <updated>2018-08-02T04:06:17.379Z</updated>
    
    <content type="html"><![CDATA[<p>项目地址：<a href="https://github.com/super-sean/task-pipeline" target="_blank" rel="noopener">https://github.com/super-sean/task-pipeline</a> </p><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>近来公司业务上越来越多的跨进程比较耗时计算的场景出现，想用异步通信来解决长时间资源占用及等待问题，而基于多方的探讨，不考虑采用<em>mina</em>和<em>netty</em>这种异步通信的框架，最后决定使用<strong>zookeeper</strong>来实现</p><h3 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h3><p>异步进行耗时较长的复杂计算请求，可随时获取请求执行进度</p><h3 id="实现思路"><a href="#实现思路" class="headerlink" title="实现思路"></a>实现思路</h3><ul><li>将这种请求的发起者当作是请求任务的生产者，每个请求其实就是一个计算任务。</li><li>后端接收请求的服务就是消费者，获得请求之后进行计算，并更新计算进度。</li><li>当任务完成时，请求发起者可以通过监听任务状态回调实现自己的逻辑。</li><li>过程中，请求发起者也可以主动获取计算讲求的进度。</li></ul><h3 id="实现设计"><a href="#实现设计" class="headerlink" title="实现设计"></a>实现设计</h3><p>基于实现思路，设计zk的path结构如下<br><img src="/2018/07/22/zk分布式任务队列交互设计/zk_path设计.png" title="zk_path设计"></p><p><em>/master</em><br>为程序高可用实现预留路径  </p><p><em>/apps</em><br>为业务连接节点，底下结构为/app/node，比如你有个业务叫a,有两个业务节点b1和b2，那就有/a/b1和/a/b2 路径。由业务节点启动时注册  </p><p><em>/workers</em><br>底下结构逻辑与/apps一致，只不过节点为服务端的节点，由服务端节点启动时注册  </p><p><em>/tasks</em><br>由业务提交注册的计算任务,以业务区分目录，以app-node-timestamp格式来命名taskid,每个节点拥有params,status和result三个节点  </p><ul><li>params 为请求参数，以文本格式存储，例如可以使用json格式传输</li><li>status 为task状态，默认有submit,running,done,noworker（无计算服务）,missapp（app节点断线）,consumed（已消费），resubmit（重分配）几种状态，worker可以添加自定义中间过程状态，任务提交时默认为submit状态。</li><li>result 为初始不存在，当status变更为done时添加，内容为文本格式，例如可以使用json，包括type和value,先只支持两种，第一种为直接返回为{“type”:”content”,”value”:”something”},考虑zk单个节点的容量问题，可能返回较大数据量，使用redis作为结果缓存层，返回{“type”:”redis_key”,”value”:”one redis key”} 当然不用redis也行，当数据量更大的时候可使用其它工具，这里先选用redis</li></ul><p>history目录下为完成的任务，定时持久化清理。 </p><p><em>/assign</em><br>由系统根据业务app分配作业给worker，以node-taskid来标识作业<br>history目录下为执行完的作业，定时持久化清理</p><h3 id="模块设计"><a href="#模块设计" class="headerlink" title="模块设计"></a>模块设计</h3><ol><li>调度系统<br> 实现基于zk的路径交互，负责与业务和服务两端交互</li><li>业务端接口包封装<br> 对于业务端来说，只需要提交服务端接口标识，接口参数之后返回taskId,根据需要通过taskId进行结果回调监听，支持查询task状态，需要屏蔽底层操作，透明化复杂操作。  </li><li>服务端接口包封装<br> 对于服务端来说，只需要继承某个类，声明服务标识，实现监听task队列的方法，处理被推送过来的任务，并根据需要更新自定义task状态，处理完成后在方法选择返回的内容类型即可  <img src="/2018/07/22/zk分布式任务队列交互设计/模块功能概览.png" title="模块功能概览">  </li></ol><h3 id="流程设计"><a href="#流程设计" class="headerlink" title="流程设计"></a>流程设计</h3><h4 id="正常交互流程"><a href="#正常交互流程" class="headerlink" title="正常交互流程"></a>正常交互流程</h4><p>(由于用的uml画图工具问题，画得不是很规范，见谅…)<br>正常交互流程<br><img src="/2018/07/22/zk分布式任务队列交互设计/normal_seq.png" title="正常交互流程"><br>worker断线重新分配任务流程<br><img src="/2018/07/22/zk分布式任务队列交互设计/worker_down_seq.png" title="worker断线重新分配任务流程">  </p><h3 id="核心模块类图"><a href="#核心模块类图" class="headerlink" title="核心模块类图"></a>核心模块类图</h3><p>基本操作都抽象成名为operation的类，基于不同角色做扩展，目前情况如下<br><img src="/2018/07/22/zk分布式任务队列交互设计/operation类图关系.png" title="operation类图关系"><br>baseOperation为zk的基本操作，operation为倾向原子性业务操作，分角色扩展的operation如serverOperation为封装角色实现本身的组合操作<br>监听器主要有以下监听器实现<br><img src="/2018/07/22/zk分布式任务队列交互设计/监听器的抽象类.png" title="监听器的抽象类"><br>每个角色都是基于以上两个核心模块加以逻辑处理来实现自己的功能</p><h3 id="其它相关设计"><a href="#其它相关设计" class="headerlink" title="其它相关设计"></a>其它相关设计</h3><h4 id="Task分发策略"><a href="#Task分发策略" class="headerlink" title="Task分发策略"></a>Task分发策略</h4><p>worker每当被分发task，便权重添加1，处理完则减1<br>分发Task时选择权重最小的节点<br>若权重都一样，则选择第一个节点  </p><h4 id="server主从实现"><a href="#server主从实现" class="headerlink" title="server主从实现"></a>server主从实现</h4><p>使用curator包的LeaderLatch</p><h4 id="zk-path-acl权限管理"><a href="#zk-path-acl权限管理" class="headerlink" title="zk path acl权限管理"></a>zk path acl权限管理</h4><p>使用三个角色，tp_server,tp_worker,tp_app<br>目前没有做细粒度控制，只是tp_server创建的给另外两个角色授权，tp_worker创建的给tp_server授权，tp_app创建的给tp_server授权</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;项目地址：&lt;a href=&quot;https://github.com/super-sean/task-pipeline&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/super-sean/task-pipeline&lt;/a&gt;
      
    
    </summary>
    
      <category term="设计" scheme="https://super-sean.github.io/categories/%E8%AE%BE%E8%AE%A1/"/>
    
    
      <category term="分布式" scheme="https://super-sean.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="zookeeper" scheme="https://super-sean.github.io/tags/zookeeper/"/>
    
      <category term="队列" scheme="https://super-sean.github.io/tags/%E9%98%9F%E5%88%97/"/>
    
  </entry>
  
</feed>
